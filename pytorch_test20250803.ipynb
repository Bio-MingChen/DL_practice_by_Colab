{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyOY4746hRzwZG6AqY3Aqbyo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bio-MingChen/DL_practice_by_Colab/blob/main/pytorch_test20250803.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "Hp_uPMgY0R7G"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "E3P4foY1HvQ1",
        "outputId": "87adac26-b068-4944-b126-85e92670f7d9"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.6.0+cu124'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n"
      ],
      "metadata": {
        "id": "25tBOsgP0pYN"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data[0][0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXkFacDc9RsB",
        "outputId": "98111404-59fa-4517-daf3-eb7a700a010a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_data[0][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXm3vfUT9wo0",
        "outputId": "516f774c-e9d1-4fc4-983f-1b8016570401"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "train_dataloader = DataLoader(training_data,batch_size=batch_size,shuffle=True)\n",
        "test_dataloader = DataLoader(test_data,batch_size=batch_size,shuffle=True)"
      ],
      "metadata": {
        "id": "87x1nvZG9SRL"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for X,y in test_dataloader:\n",
        "  print(f\"Shape of X [N,C,H,W]: {X.shape}\")\n",
        "  print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDpHvLw4-Ptg",
        "outputId": "cca9288b-6b99-4ad1-ba1a-4f5cba839e7a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X [N,C,H,W]: torch.Size([64, 1, 28, 28])\n",
            "Shape of y: torch.Size([64]) torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(train_dataloader))[1].shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RsesEq3J-3PU",
        "outputId": "bfe924d6-1da0-4213-9fed-9345a9075e70"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "labels_map = {\n",
        "    0: \"T-Shirt\",\n",
        "    1: \"Trouser\",\n",
        "    2: \"Pullover\",\n",
        "    3: \"Dress\",\n",
        "    4: \"Coat\",\n",
        "    5: \"Sandal\",\n",
        "    6: \"Shirt\",\n",
        "    7: \"Sneaker\",\n",
        "    8: \"Bag\",\n",
        "    9: \"Ankle Boot\",\n",
        "}\n",
        "img = training_data[0][0]\n",
        "label = training_data[0][1]\n",
        "plt.imshow(img.squeeze(),cmap=\"gray\")\n",
        "plt.title(labels_map[label])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "id": "ubNT-HuM-Y6x",
        "outputId": "c4a08572-f43c-44fe-ce3c-72c0cb8f25f7"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Ankle Boot')"
            ]
          },
          "metadata": {},
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img.squeeze().shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5euiuitA-sz",
        "outputId": "38989308-0d23-481a-f5a1-f7150654c645"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img.squeeze().unsqueeze(0).shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLSqzb9PBEyh",
        "outputId": "601aaf54-9b0f-4324-ca97-6a325a51f3f6"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "åœ¨ Python çš„ `numpy` å’Œ `PyTorch`ï¼ˆä»¥åŠ `TensorFlow`ï¼‰ä¸­ï¼Œ`squeeze()` æ˜¯ä¸€ä¸ªéå¸¸å¸¸ç”¨çš„å‡½æ•°ï¼Œå®ƒçš„ä½œç”¨æ˜¯ï¼š\n",
        "\n",
        "> **ç§»é™¤å½¢çŠ¶ä¸­ä¸º 1 çš„ç»´åº¦ï¼ˆsizeä¸º1çš„ç»´åº¦ï¼‰**\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”§ åŸºæœ¬ç”¨æ³•\n",
        "\n",
        "### NumPy ä¸­ï¼š\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "\n",
        "x = np.array([[[1], [2], [3]]])  # shape: (1, 3, 1)\n",
        "x_squeezed = np.squeeze(x)       # shape: (3,)\n",
        "\n",
        "print(x.shape)        # (1, 3, 1)\n",
        "print(x_squeezed.shape)  # (3,)\n",
        "```\n",
        "\n",
        "### PyTorch ä¸­ï¼š\n",
        "\n",
        "```python\n",
        "import torch\n",
        "\n",
        "x = torch.zeros(1, 3, 1)\n",
        "x_squeezed = x.squeeze()\n",
        "\n",
        "print(x.shape)        # torch.Size([1, 3, 1])\n",
        "print(x_squeezed.shape)  # torch.Size([3])\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ§  ä»€ä¹ˆæ—¶å€™ä¼šç”¨åˆ° `squeeze()`ï¼Ÿ\n",
        "\n",
        "### 1. **å»æ‰å¤šä½™çš„ç»´åº¦æ–¹ä¾¿è®¡ç®—**\n",
        "\n",
        "å¾ˆå¤šæ—¶å€™åŠ è½½æ•°æ®æˆ–æŸäº›æ“ä½œåï¼Œå¼ é‡ä¼šå¤šå‡ºä¸å¿…è¦çš„ `1` ç»´åº¦ï¼Œå¯èƒ½ä¼šå½±å“åç»­çš„è®¡ç®—ï¼Œæ¯”å¦‚ï¼š\n",
        "\n",
        "```python\n",
        "y = model(x)  # y shape: (batch_size, 1)\n",
        "loss = loss_fn(y.squeeze(), target)  # å°† shape (batch_size, 1) -> (batch_size,)\n",
        "```\n",
        "\n",
        "### 2. **åŒ¹é…ç»´åº¦**\n",
        "\n",
        "åœ¨è®¡ç®— loss æˆ–è¿›è¡Œå¼ é‡æ‹¼æ¥ï¼ˆconcatenateï¼‰æ—¶ï¼Œç»´åº¦ä¸ä¸€è‡´ä¼šæŠ¥é”™ï¼Œå¸¸è§çš„åšæ³•å°±æ˜¯ç”¨ `.squeeze()` æˆ– `.unsqueeze()` æ¥è°ƒæ•´ã€‚\n",
        "\n",
        "### 3. **è¾“å‡ºå•ä¸ªå€¼**\n",
        "\n",
        "ä¾‹å¦‚ï¼š\n",
        "\n",
        "```python\n",
        "x = torch.tensor([[[42]]])\n",
        "print(x.squeeze())  # tensor(42)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ§© è¿˜å¯ä»¥æŒ‡å®šè¦å»æ‰çš„ç»´åº¦\n",
        "\n",
        "```python\n",
        "x = torch.randn(1, 3, 1)\n",
        "x_squeeze_dim0 = x.squeeze(0)  # å»æ‰ç¬¬0ç»´\n",
        "x_squeeze_dim2 = x.squeeze(2)  # å»æ‰ç¬¬2ç»´\n",
        "```\n",
        "\n",
        "âš ï¸ å¦‚æœæŒ‡å®šçš„ç»´åº¦ä¸ä¸º1ï¼Œä¼šæŠ¥é”™ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸš« æ³¨æ„äº‹é¡¹\n",
        "\n",
        "* åªä¼šå»æ‰**ç»´åº¦æ˜¯1**çš„éƒ¨åˆ†ï¼›\n",
        "* `.squeeze()` æ˜¯ä¸æ”¹å˜åŸå¼ é‡çš„ï¼Œéœ€è¦èµ‹å€¼æˆ–ä½¿ç”¨ inplace ç‰ˆæœ¬ï¼ˆå¦‚ `x.squeeze_()`ï¼‰ï¼›\n",
        "* å¯èƒ½ä¼šä¸å°å¿ƒæŠŠ batch ç»´åº¦ï¼ˆç»´åº¦ä¸º 1ï¼‰æŒ¤æ‰ï¼Œå¯¼è‡´åç»­æ¨¡å‹å¤„ç†å‡ºé”™ï¼Œæ‰€ä»¥è¦å°å¿ƒåœ¨ä»€ä¹ˆæ—¶å€™ç”¨ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… æ€»ç»“ä¸€å¥è¯ï¼š\n",
        "\n",
        "> `squeeze()` å°±æ˜¯åœ¨ä½ ä¸æƒ³è¦å¤šä½™çš„ 1 ç»´æ—¶ï¼ŒæŠŠå®ƒâ€œæŒ¤æ‰â€ï¼Œå¸¸ç”¨äºæ¨¡å‹è¾“å‡ºã€reshapeã€æ•°æ®å¯¹é½ç­‰åœºæ™¯ã€‚\n",
        "\n",
        "å¦‚æœä½ æœ‰æŸæ®µä»£ç æƒ³ç¡®è®¤æ˜¯å¦éœ€è¦ `.squeeze()`ï¼Œå¯ä»¥å‘ç»™æˆ‘ï¼Œæˆ‘æ¥å¸®ä½ åˆ¤æ–­ã€‚\n"
      ],
      "metadata": {
        "id": "wIBEG44oBl7e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rm6y6-MUJGyE",
        "outputId": "c5e1b4cd-3b3c-40b2-ab07-e013e92695ba"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "28*28"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4zWH5nUKWSE",
        "outputId": "a35fce07-cfff-4024-8599-5a6bd953b145"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "784"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.linear_relu_stack = nn.Sequential(\n",
        "        nn.Linear(28*28, 512),\n",
        "        nn.BatchNorm1d(512),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.2),\n",
        "\n",
        "        nn.Linear(512,512),\n",
        "        nn.BatchNorm1d(512),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.2),\n",
        "\n",
        "        nn.Linear(512,10)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.flatten(x)\n",
        "    logits = self.linear_relu_stack(x)\n",
        "    return logits\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cr9W8BQsJ1YI",
        "outputId": "55ad8ad1-eac0-4f30-c14c-3e8d3a8d98c2"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): Dropout(p=0.2, inplace=False)\n",
            "    (4): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): ReLU()\n",
            "    (7): Dropout(p=0.2, inplace=False)\n",
            "    (8): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "na050sSLMX0i"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "| å±‚             | ä½œç”¨                             |\n",
        "| ------------- | ------------------------------ |\n",
        "| `Linear`      | å…¨è¿æ¥å±‚ï¼Œäº§ç”Ÿçº¿æ€§å˜æ¢                    |\n",
        "| `BatchNorm1d` | å¯¹çº¿æ€§è¾“å‡ºåšæ ‡å‡†åŒ–ï¼Œ**ç¨³å®šè®­ç»ƒè¿‡ç¨‹**ï¼Œå‡è½»å†…éƒ¨åå˜é‡åç§» |\n",
        "| `ReLU`        | éçº¿æ€§æ¿€æ´»ï¼Œç»™æ¨¡å‹å¼•å…¥éçº¿æ€§èƒ½åŠ›               |\n",
        "| `Dropout`     | åœ¨è®­ç»ƒæ—¶éšæœºä¸¢å¼ƒéƒ¨åˆ†æ¿€æ´»å€¼ï¼Œ**é˜²æ­¢è¿‡æ‹Ÿåˆ**        |\n"
      ],
      "metadata": {
        "id": "1x3aN1cVLQay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "å½“ç„¶å¯ä»¥ï¼Œä¸‹é¢æ˜¯ç”¨**é€šä¿—æ˜“æ‡‚çš„æ–¹å¼**è§£é‡Š `BatchNorm1d` çš„ä½œç”¨ï¼š\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ§  ä¸€å¥è¯æ€»ç»“ï¼š\n",
        "\n",
        "> **BatchNorm1d å°±åƒæ˜¯åœ¨æ¯ä¸€å±‚ç¥ç»ç½‘ç»œâ€œåšæ ‡å‡†åŒ–å¤„ç†â€ï¼Œå¸®ä½ æŠŠæ•°æ®â€œæ•´ç†æ•´é½â€ï¼Œè®©ç½‘ç»œæ›´å®¹æ˜“å­¦å¾—å¿«ã€å­¦å¾—ç¨³ã€ä¸å®¹æ˜“å´©ã€‚**\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ§© ä¸ºä»€ä¹ˆè¦ç”¨ BatchNormï¼Ÿ\n",
        "\n",
        "æƒ³è±¡ä½ åœ¨æ•™ä¸€ä¸ªå­¦ç”Ÿï¼ˆç¥ç»ç½‘ç»œï¼‰å­¦ä¹ åšé¢˜ï¼ˆè®­ç»ƒä»»åŠ¡ï¼‰ï¼š\n",
        "\n",
        "* å¦‚æœé¢˜ç›®ï¼ˆè¾“å…¥ï¼‰æ ¼å¼å¾ˆæ··ä¹±ï¼Œæœ‰çš„å¤§æœ‰çš„å°ï¼Œæœ‰çš„å…¨æ˜¯è´Ÿæ•°ï¼Œæœ‰çš„çªç„¶å˜å¤§äº†ï¼›\n",
        "* å­¦ç”Ÿå°±ä¼šå¾ˆéš¾é€‚åº”ï¼Œå­¦ä¹ è¿‡ç¨‹ä¼šå¾ˆä¸ç¨³å®šï¼Œå®¹æ˜“å­¦å´©ã€å­¦æ…¢ã€‚\n",
        "\n",
        "**BatchNorm çš„ä½œç”¨å°±æ˜¯æŠŠè¿™äº›é¢˜ç›®ç»Ÿä¸€æ ¼å¼**ï¼š\n",
        "\n",
        "> è®©æ•°æ®å˜å¾—â€œå¹³å‡å€¼æ˜¯ 0ï¼Œæ ‡å‡†å·®æ˜¯ 1â€ï¼ˆæ ‡å‡†åŒ–ï¼‰\n",
        "\n",
        "è¿™æ ·å­¦ç”Ÿå°±èƒ½**å¿«é€Ÿè¿›å…¥çŠ¶æ€ï¼Œé›†ä¸­ç²¾åŠ›åšé¢˜ï¼ˆå­¦ä¹ ï¼‰**ï¼Œä¸ä¼šå› ä¸ºé¢˜ç›®å½¢å¼å˜åŒ–è€Œâ€œå¿ƒæ€å´©äº†â€ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”§ BatchNorm1d åœ¨å¹²å•¥ï¼Ÿ\n",
        "\n",
        "ä»¥ä¸€å¥ä»£ç ä¸ºä¾‹ï¼š\n",
        "\n",
        "```python\n",
        "nn.BatchNorm1d(512)\n",
        "```\n",
        "\n",
        "è¿™ä¸ªæ„æ€æ˜¯è¯´ï¼šå¯¹æ¯ä¸ª batch é‡Œçš„æ ·æœ¬ï¼Œåœ¨ `512` ç»´åº¦ä¸Šåˆ†åˆ«åšå¦‚ä¸‹æ“ä½œï¼š\n",
        "\n",
        "### æ¯ä¸€ç»´ç‰¹å¾éƒ½ä¼šï¼š\n",
        "\n",
        "1. **è®¡ç®—å½“å‰ batch çš„å‡å€¼å’Œæ–¹å·®**\n",
        "2. **æŠŠè¿™ç»´çš„æ•°æ®æ ‡å‡†åŒ–** â†’ å‡å»å‡å€¼ / é™¤ä»¥æ ‡å‡†å·®\n",
        "3. **å†ä¹˜ä¸€ä¸ªâ€œå¯å­¦ä¹ çš„ç¼©æ”¾å› å­â€ Î³ï¼ŒåŠ ä¸€ä¸ªâ€œåç§»é‡â€ Î²**\n",
        "\n",
        "æœ€ç»ˆè¾“å‡ºçš„æ˜¯ä¸€ä¸ª**æ ‡å‡†åŒ–åè¿˜å¸¦æœ‰ä¸€å®šçµæ´»æ€§**çš„ç‰¹å¾ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ’¡ ä¸¾ä¸ªä¾‹å­æ¥å½¢è±¡ç†è§£ï¼š\n",
        "\n",
        "å‡è®¾ä½ å–‚ç»™ç¥ç»ç½‘ç»œçš„æ•°æ®æ˜¯è¿™æ ·çš„ï¼š\n",
        "\n",
        "```python\n",
        "[[-100, 0, 300],\n",
        " [ -90, 1, 280],\n",
        " [-110, -1, 310]]\n",
        "```\n",
        "\n",
        "è¿™ä¸ªå·®å¼‚éå¸¸å¤§ï¼Œæ¨¡å‹éš¾å­¦ã€‚\n",
        "\n",
        "BatchNorm å°±ä¼šå¸®ä½ æŠŠæ¯ä¸€åˆ—**ç¼©æ”¾å’Œç§»åŠ¨**ï¼Œå˜æˆåƒè¿™æ ·ï¼š\n",
        "\n",
        "```python\n",
        "[[ 0.1, -0.2,  0.5],\n",
        " [-0.1,  0.0,  0.3],\n",
        " [-0.2,  0.2, -0.8]]\n",
        "```\n",
        "\n",
        "ç°åœ¨è¿™äº›å€¼å°±â€œæ•´é½â€å¤šäº†ï¼Œæ¨¡å‹æ›´å®¹æ˜“å¤„ç†ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… ä¼˜ç‚¹æ€»ç»“ï¼š\n",
        "\n",
        "| ä¼˜ç‚¹        | ç±»æ¯”                  |\n",
        "| --------- | ------------------- |\n",
        "| è®­ç»ƒæ›´å¿«      | å­¦ç”Ÿé¢å¯¹ç»Ÿä¸€æ ¼å¼çš„é¢˜ï¼Œåˆ·é¢˜æ•ˆç‡æå‡   |\n",
        "| è®­ç»ƒæ›´ç¨³å®š     | ä¸å®¹æ˜“â€œæ¢¯åº¦çˆ†ç‚¸/æ¶ˆå¤±â€        |\n",
        "| å‡å°‘å¯¹åˆå§‹åŒ–çš„ä¾èµ– | ä¸ç”¨å¤ªæ‹…å¿ƒåˆå§‹æƒé‡é€‰ä¸å¥½        |\n",
        "| æœ‰è½»å¾®æ­£åˆ™åŒ–æ•ˆæœ  | æœ‰ç‚¹åƒ Dropoutï¼Œèƒ½ç¨å¾®é˜²è¿‡æ‹Ÿåˆ |\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ¤” ä¸ºä»€ä¹ˆå« `BatchNorm1d`ï¼Ÿ\n",
        "\n",
        "å› ä¸ºå®ƒæ˜¯åœ¨**æ¯ä¸€ä¸ª batch ä¸Šåšâ€œ1D çš„ç‰¹å¾æ ‡å‡†åŒ–â€**ï¼ˆé€šå¸¸ç”¨äº `Linear` å±‚çš„è¾“å‡ºï¼‰ï¼Œæ‰€ä»¥å« `1d`ã€‚\n",
        "å¦‚æœæ˜¯ `Conv2d` é‚£ç§å›¾åƒæ•°æ®ï¼Œå°±è¦ç”¨ `BatchNorm2d`ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… æ€»ç»“ä¸€å¥é€šä¿—è¯ï¼š\n",
        "\n",
        "> **BatchNorm1d å°±æ˜¯å¸®ä½ çš„ç½‘ç»œâ€œæ•´é¡¿è¾“å…¥ç§©åºâ€ï¼Œæ ‡å‡†åŒ–æ¯ä¸€å±‚çš„æ•°æ®ï¼Œè®©å­¦ä¹ æ›´é«˜æ•ˆã€æ›´ç¨³å®šï¼Œä¸å®¹æ˜“å´©ã€‚**\n",
        "\n",
        "éœ€è¦æˆ‘ç”¨å›¾ç¤ºæˆ–åŠ¨ç”»å½¢å¼è§£é‡Šï¼Œä¹Ÿå¯ä»¥ç”»å›¾ç»™ä½ çœ‹ã€‚\n"
      ],
      "metadata": {
        "id": "wg_K-MtoLq8v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "éå¸¸å¥½ï¼ä½ æåˆ°äº†å‡ ä¸ªæ·±åº¦å­¦ä¹ ä¸­æœ€å…³é”®çš„éƒ¨åˆ†ï¼š**ReLU æ¿€æ´»å‡½æ•°ã€äº¤å‰ç†µæŸå¤±å‡½æ•° CrossEntropyLossï¼Œä»¥åŠ SGD ä¼˜åŒ–å™¨**ã€‚æˆ‘ä¼šä¸€ä¸€ç»™å‡ºå®ƒä»¬çš„**å…¬å¼ã€å›¾åƒå’Œä½œç”¨è§£é‡Š**ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… ä¸€ã€ReLUï¼ˆRectified Linear Unitï¼‰æ¿€æ´»å‡½æ•°\n",
        "\n",
        "### ğŸ”¸ å…¬å¼ï¼š\n",
        "\n",
        "$$\n",
        "\\text{ReLU}(x) = \\max(0, x)\n",
        "$$\n",
        "\n",
        "ä¹Ÿå°±æ˜¯è¯´ï¼š\n",
        "\n",
        "* å¦‚æœ $x > 0$ï¼Œè¾“å‡ºå°±æ˜¯ $x$\n",
        "* å¦‚æœ $x \\leq 0$ï¼Œè¾“å‡ºå°±æ˜¯ 0\n",
        "\n",
        "### ğŸ”¸ å›¾åƒï¼š\n",
        "\n",
        "```python\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "x = np.linspace(-10, 10, 100)\n",
        "y = np.maximum(0, x)\n",
        "\n",
        "plt.plot(x, y)\n",
        "plt.title('ReLU Activation Function')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('ReLU(x)')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "ï¼ˆä½ å¯ä»¥è¿è¡Œä¸Šé¢ä»£ç çœ‹çœ‹å›¾åƒï¼Œä¹Ÿå¯ä»¥æˆ‘å¸®ä½ ç”»å‡ºå›¾æ¥ï¼‰\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”¸ ä½œç”¨ï¼š\n",
        "\n",
        "* å¼•å…¥éçº¿æ€§ï¼Œä½¿ç¥ç»ç½‘ç»œå¯ä»¥å­¦ä¹ å¤æ‚çš„å‡½æ•°ï¼›\n",
        "* è®¡ç®—ç®€å•ï¼Œè®­ç»ƒå¿«é€Ÿï¼›\n",
        "* ä½†å¯èƒ½å‡ºç°â€œç¥ç»å…ƒæ­»äº¡â€é—®é¢˜ï¼ˆReLU è¾“å‡ºé•¿æœŸä¸º0ï¼‰ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… äºŒã€`nn.CrossEntropyLoss()`\n",
        "\n",
        "### ğŸ”¸ ç”¨é€”ï¼š\n",
        "\n",
        "è¿™æ˜¯ **åˆ†ç±»ä»»åŠ¡**ä¸­æœ€å¸¸ç”¨çš„æŸå¤±å‡½æ•°ï¼Œé€‚ç”¨äº `model` çš„è¾“å‡ºæ˜¯ **logits**ï¼ˆæœªç»è¿‡ `softmax` çš„å¾—åˆ†ï¼‰ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”¸ è®¡ç®—è¿‡ç¨‹åˆ†ä¸ºä¸¤æ­¥ï¼ˆPyTorch å†…éƒ¨è‡ªåŠ¨åšçš„ï¼‰ï¼š\n",
        "\n",
        "1. **å…ˆå¯¹ logits åš softmax å¾—åˆ°é¢„æµ‹æ¦‚ç‡ï¼š**\n",
        "\n",
        "$$\n",
        "\\hat{y}_i = \\frac{e^{z_i}}{\\sum_{j} e^{z_j}}\n",
        "$$\n",
        "\n",
        "å…¶ä¸­ï¼š\n",
        "\n",
        "* $z_i$ï¼šæ¨¡å‹è¾“å‡ºçš„ç¬¬ $i$ ç±»çš„ logit\n",
        "* $\\hat{y}_i$ï¼šsoftmax åçš„æ¦‚ç‡\n",
        "\n",
        "2. **å†è®¡ç®—äº¤å‰ç†µæŸå¤±ï¼ˆCross Entropyï¼‰ï¼š**\n",
        "\n",
        "$$\n",
        "\\text{Loss} = -\\sum_{i} y_i \\log(\\hat{y}_i)\n",
        "$$\n",
        "\n",
        "å…¶ä¸­ï¼š\n",
        "\n",
        "* $y_i$ æ˜¯ one-hot æ ‡ç­¾ï¼ˆåªæœ‰ä¸€ä¸ª 1 å…¶ä»–éƒ½æ˜¯ 0ï¼‰\n",
        "* å®é™…è®¡ç®—æ—¶åªä¿ç•™æ­£ç¡®æ ‡ç­¾é‚£ä¸€é¡¹ï¼š$-\\log(\\hat{y}_{\\text{true class}})$\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”¸ ä¸¾ä¸ªä¾‹å­ï¼š\n",
        "\n",
        "å¦‚æœä½ çš„æ¨¡å‹è¾“å‡ºæ˜¯ï¼š\n",
        "\n",
        "```python\n",
        "logits = [2.0, 1.0, 0.1]  # è¡¨ç¤ºä¸‰ä¸ªç±»åˆ«çš„å¾—åˆ†\n",
        "label = 0  # æ­£ç¡®ç±»åˆ«æ˜¯ç¬¬0ç±»\n",
        "```\n",
        "\n",
        "PyTorch è‡ªåŠ¨è®¡ç®—ï¼š\n",
        "\n",
        "```python\n",
        "softmax = [0.659, 0.242, 0.099]\n",
        "loss = -log(0.659) â‰ˆ 0.417\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… ä¸‰ã€`torch.optim.SGD(...)` éšæœºæ¢¯åº¦ä¸‹é™ä¼˜åŒ–å™¨\n",
        "\n",
        "### ğŸ”¸ å…¬å¼ï¼š\n",
        "\n",
        "æ¯ä¸€è½®è¿­ä»£ä¸­ï¼Œæ›´æ–°å‚æ•°çš„å…¬å¼æ˜¯ï¼š\n",
        "\n",
        "$$\n",
        "\\theta = \\theta - \\eta \\cdot \\nabla_{\\theta} \\mathcal{L}\n",
        "$$\n",
        "\n",
        "å…¶ä¸­ï¼š\n",
        "\n",
        "* $\\theta$ï¼šæ¨¡å‹å‚æ•°\n",
        "* $\\eta$ï¼šå­¦ä¹ ç‡ï¼ˆå¦‚ `1e-3`ï¼‰\n",
        "* $\\nabla_{\\theta} \\mathcal{L}$ï¼šæŸå¤±å‡½æ•°å¯¹å‚æ•°çš„æ¢¯åº¦\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”¸ ä½ å†™çš„ä»£ç ï¼š\n",
        "\n",
        "```python\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
        "```\n",
        "\n",
        "æ„æ€æ˜¯ï¼š\n",
        "\n",
        "* ç”¨ **äº¤å‰ç†µ** æ¥è¯„ä¼°åˆ†ç±»è¯¯å·®ï¼›\n",
        "* ç”¨ **å­¦ä¹ ç‡ä¸º 0.001 çš„ SGD ä¼˜åŒ–å™¨** æ¥æ›´æ–°æ¨¡å‹å‚æ•°ï¼›\n",
        "* æ¯ä¸ª batch åæ‰§è¡Œï¼š\n",
        "\n",
        "```python\n",
        "loss.backward()        # è®¡ç®—æ¢¯åº¦\n",
        "optimizer.step()       # æ ¹æ®æ¢¯åº¦æ›´æ–°å‚æ•°\n",
        "optimizer.zero_grad()  # æ¸…ç©ºä¸Šä¸€æ¬¡çš„æ¢¯åº¦\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… æ€»ç»“è¡¨æ ¼ï¼š\n",
        "\n",
        "| é¡¹ç›®                   | å…¬å¼                                                       | ç”¨é€”         |\n",
        "| -------------------- | -------------------------------------------------------- | ---------- |\n",
        "| **ReLU**             | $\\max(0, x)$                                             | æ¿€æ´»å‡½æ•°ï¼Œå¢åŠ éçº¿æ€§ |\n",
        "| **CrossEntropyLoss** | $-\\log(\\hat{y}_{\\text{true class}})$                     | åˆ†ç±»ä»»åŠ¡æŸå¤±     |\n",
        "| **SGD**              | $\\theta = \\theta - \\eta \\cdot \\nabla_\\theta \\mathcal{L}$ | æ¢¯åº¦ä¸‹é™ä¼˜åŒ–å‚æ•°   |\n",
        "\n",
        "---\n",
        "\n",
        "å¦‚æœä½ å¸Œæœ›æˆ‘æŠŠ ReLU å’Œ Softmax çš„å›¾ç”»å‡ºæ¥å±•ç¤ºï¼Œä¹Ÿå¯ä»¥å‘Šè¯‰æˆ‘ï¼Œæˆ‘å¯ä»¥ç›´æ¥è¾“å‡ºå›¾ç‰‡ç»™ä½ çœ‹ã€‚æ˜¯å¦è¿˜æƒ³ç»§ç»­äº†è§£ Adam ä¼˜åŒ–å™¨ã€å­¦ä¹ ç‡è°ƒåº¦å™¨ä¹‹ç±»çš„å†…å®¹ï¼Ÿ\n"
      ],
      "metadata": {
        "id": "-q4Z2214NaEB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "å¾ˆå¥½ï¼è¿™ä¸¤ä¸ªæ¦‚å¿µéå¸¸å…³é”®ï¼š**logits** å’Œ **softmax** æ˜¯åœ¨åˆ†ç±»ç¥ç»ç½‘ç»œä¸­ç»å¸¸é‡åˆ°çš„æœ¯è¯­ã€‚\n",
        "\n",
        "æˆ‘æ¥ç”¨é€šä¿—æ˜“æ‡‚çš„æ–¹å¼ç»™ä½ è®²æ¸…æ¥šå®ƒä»¬çš„åŒºåˆ«å’Œä½œç”¨ï¼š\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… ä¸€ã€ä»€ä¹ˆæ˜¯ **logits**ï¼Ÿ\n",
        "\n",
        "### ğŸ”¹ä¸€å¥è¯å®šä¹‰ï¼š\n",
        "\n",
        "> **logits å°±æ˜¯ç¥ç»ç½‘ç»œæœ€åä¸€å±‚çš„åŸå§‹è¾“å‡ºåˆ†æ•°**ï¼Œè¿˜æ²¡æœ‰ç»è¿‡å½’ä¸€åŒ–ï¼Œä¹Ÿä¸æ˜¯æ¦‚ç‡ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”¹ä¸¾ä¸ªä¾‹å­ï¼š\n",
        "\n",
        "å‡è®¾ä½ è¦åšä¸€ä¸ª 3 åˆ†ç±»é—®é¢˜ï¼ˆæ¯”å¦‚è¯†åˆ«çŒ«ğŸ±ã€ç‹—ğŸ¶ã€é¸ŸğŸ¦ï¼‰\n",
        "ä½ å–‚ä¸€å¼ å›¾ç»™æ¨¡å‹ï¼Œå®ƒæœ€åè¾“å‡ºï¼š\n",
        "\n",
        "```python\n",
        "logits = [2.5, 0.3, -1.2]\n",
        "```\n",
        "\n",
        "è¿™å°±æ˜¯ logitsï¼š\n",
        "\n",
        "* åŸå§‹åˆ†æ•°\n",
        "* å¯ä»¥æ˜¯æ­£çš„ã€è´Ÿçš„ã€ä»»æ„å¤§çš„\n",
        "* **ä¸æ»¡è¶³æ¦‚ç‡åˆ†å¸ƒ**\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… äºŒã€ä»€ä¹ˆæ˜¯ **softmax**ï¼Ÿ\n",
        "\n",
        "### ğŸ”¹ä¸€å¥è¯å®šä¹‰ï¼š\n",
        "\n",
        "> **softmax ä¼šæŠŠ logits è½¬æ¢æˆâ€œæ¦‚ç‡åˆ†å¸ƒâ€**ï¼Œæ¯ä¸€ç±»çš„å¾—åˆ†å˜æˆäº† 0\\~1 ä¹‹é—´çš„æ¦‚ç‡ï¼Œæ‰€æœ‰æ¦‚ç‡åŠ èµ·æ¥æ˜¯ 1ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”¹å…¬å¼ï¼š\n",
        "\n",
        "$$\n",
        "\\hat{y}_i = \\frac{e^{z_i}}{\\sum_{j} e^{z_j}}\n",
        "$$\n",
        "\n",
        "å…¶ä¸­ï¼š\n",
        "\n",
        "* $z_i$ï¼šlogits ä¸­ç¬¬ i ç±»çš„åˆ†æ•°\n",
        "* $\\hat{y}_i$ï¼šsoftmax è¾“å‡ºçš„æ¦‚ç‡\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”¹å¯¹å‰é¢ä¾‹å­çš„å¤„ç†ï¼š\n",
        "\n",
        "```python\n",
        "logits = [2.5, 0.3, -1.2]\n",
        "```\n",
        "\n",
        "ç»è¿‡ softmax åï¼š\n",
        "\n",
        "```python\n",
        "softmax_probs = [0.81, 0.15, 0.04]  # è¿™äº›å°±æ˜¯æ¦‚ç‡\n",
        "```\n",
        "\n",
        "è¿™æ„å‘³ç€ï¼š\n",
        "\n",
        "* æ¨¡å‹è®¤ä¸ºè¿™å¼ å›¾æ˜¯â€œçŒ«â€çš„æ¦‚ç‡æ˜¯ 81%\n",
        "* æ˜¯ç‹—çš„æ¦‚ç‡æ˜¯ 15%\n",
        "* æ˜¯é¸Ÿçš„æ¦‚ç‡æ˜¯ 4%\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ§  logits vs softmaxï¼šæ¯”è¾ƒæ€»ç»“\n",
        "\n",
        "| æ¯”è¾ƒé¡¹    | logits                  | softmax ç»“æœ            |\n",
        "| ------ | ----------------------- | --------------------- |\n",
        "| å€¼èŒƒå›´    | ä»»æ„å®æ•°                    | (0, 1) ä¹‹é—´             |\n",
        "| æ˜¯å¦æ˜¯æ¦‚ç‡  | âŒ ä¸æ˜¯                    | âœ… æ˜¯                   |\n",
        "| æ˜¯å¦å½’ä¸€åŒ–  | âŒ å¦                     | âœ… æ˜¯ï¼ˆæ€»å’Œ = 1ï¼‰           |\n",
        "| æ¨¡å‹è¾“å‡ºæ ¼å¼ | æ¨¡å‹æœ€åä¸€å±‚è¾“å‡º                | softmax æ˜¯å¯¹ logits çš„å¤„ç† |\n",
        "| ç”¨äºå“ª    | ä¾› `CrossEntropyLoss` ä½¿ç”¨ | ç”¨äºæ¨ç† / å¯è§†åŒ–åˆ†ç±»æ¦‚ç‡        |\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… CrossEntropyLoss è‡ªåŠ¨å¸®ä½ åšäº† softmaxï¼\n",
        "\n",
        "ä½ ä¸éœ€è¦æ‰‹åŠ¨ `softmax(logits)`ï¼Œå› ä¸ºï¼š\n",
        "\n",
        "```python\n",
        "nn.CrossEntropyLoss()\n",
        "```\n",
        "\n",
        "è¿™ä¸ªå‡½æ•°å†…éƒ¨å·²ç»**è‡ªåŠ¨å¯¹ logits åšäº† softmax è®¡ç®—**ï¼Œç„¶åæ‰ç®— lossã€‚\n",
        "\n",
        "æ‰€ä»¥ä½ åªéœ€è¦æŠŠ `logits` è¾“å‡ºç»™å®ƒå³å¯ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… æ€»ç»“ä¸€å¥è¯ï¼š\n",
        "\n",
        "> **logits æ˜¯æ¨¡å‹è¾“å‡ºçš„â€œåŸå§‹åˆ†æ•°â€ï¼Œsoftmax æ˜¯æŠŠè¿™äº›åˆ†æ•°è½¬æˆæ¦‚ç‡çš„å‡½æ•°ã€‚**\n",
        "\n",
        "å¦‚æœä½ æƒ³çœ‹ softmax çš„å›¾åƒã€æˆ–è€…æƒ³è‡ªå·±å®ç° softmaxï¼Œæˆ‘å¯ä»¥ä¹Ÿå¸®ä½ ç”»å›¾æˆ–ç»™ä»£ç ã€‚éœ€è¦çš„è¯è¯´ä¸€å£°ï¼\n"
      ],
      "metadata": {
        "id": "UJaDlfNpNlyD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "è¿™æ˜¯ä¸€ä¸ªéå¸¸ç»å…¸çš„é—®é¢˜ï¼ğŸ’¡**SGDï¼ˆéšæœºæ¢¯åº¦ä¸‹é™ï¼‰** å’Œ **Adamï¼ˆè‡ªé€‚åº”çŸ©ä¼°è®¡ï¼‰** æ˜¯ä¸¤ç§å¸¸ç”¨çš„æ·±åº¦å­¦ä¹ ä¼˜åŒ–å™¨ï¼Œå®ƒä»¬çš„ç›®æ ‡éƒ½æ˜¯ï¼š\n",
        "\n",
        "> **é€šè¿‡ä¸æ–­æ›´æ–°å‚æ•°ï¼Œè®©æ¨¡å‹æŸå¤±æœ€å°åŒ–**\n",
        "\n",
        "ä½†å®ƒä»¬**æ›´æ–°å‚æ•°çš„æ–¹å¼ä¸åŒ**ï¼Œå„æœ‰ä¼˜ç¼ºç‚¹ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… ä¸€å¼ è¡¨å…ˆæ¦‚æ‹¬å®ƒä»¬çš„åŒºåˆ«ï¼š\n",
        "\n",
        "| ç‰¹æ€§         | SGD                  | Adam                        |\n",
        "| ---------- | -------------------- | --------------------------- |\n",
        "| æ˜¯å¦è‡ªé€‚åº”å­¦ä¹ ç‡   | âŒ å¦                  | âœ… æ˜¯ï¼ˆæ¯ä¸ªå‚æ•°éƒ½æœ‰è‡ªå·±çš„å­¦ä¹ ç‡ï¼‰           |\n",
        "| æ˜¯å¦ç”¨åŠ¨é‡      | âœ… å¯é€‰ï¼ˆSGD + Momentumï¼‰ | âœ… è‡ªå¸¦                        |\n",
        "| ä¾èµ–è¿‡å»æ¢¯åº¦çš„å¹³å‡å€¼ | âŒ å¦                  | âœ… æ˜¯ï¼ˆ1é˜¶å’Œ2é˜¶çŸ©ä¼°è®¡ï¼‰               |\n",
        "| è¶…å‚æ•°æ•æ„Ÿæ€§     | è¾ƒé«˜                   | è¾ƒä½                          |\n",
        "| æ”¶æ•›é€Ÿåº¦       | æ…¢ï¼ˆä½†ç¨³ï¼‰                | å¿«                           |\n",
        "| æ˜¯å¦å®¹æ˜“è¿‡æ‹Ÿåˆ    | è¾ƒä¸å®¹æ˜“                 | æœ‰æ—¶ä¼šæ›´å®¹æ˜“è¿‡æ‹Ÿåˆ                   |\n",
        "| é€‚åˆ         | ç®€å•ä»»åŠ¡ã€å¤§æ•°æ®ã€å®¹æ˜“æ³›åŒ–        | ç¨€ç–æ¢¯åº¦ã€å¤æ‚ç»“æ„ï¼ˆå¦‚RNNã€Transformerï¼‰ |\n",
        "| å…¸å‹ä½¿ç”¨åœºæ™¯     | ç»å…¸CNNè®­ç»ƒã€ç®€æ´ä»»åŠ¡         | NLPã€Transformerã€é¢„è®­ç»ƒæ¨¡å‹       |\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… ä¸€ã€SGDï¼ˆStochastic Gradient Descentï¼‰\n",
        "\n",
        "### ğŸ“˜ å…¬å¼ï¼š\n",
        "\n",
        "$$\n",
        "\\theta_{t+1} = \\theta_t - \\eta \\cdot \\nabla_\\theta \\mathcal{L}(\\theta_t)\n",
        "$$\n",
        "\n",
        "* $\\theta$ï¼šæ¨¡å‹å‚æ•°\n",
        "* $\\eta$ï¼šå­¦ä¹ ç‡\n",
        "* $\\nabla_\\theta \\mathcal{L}$ï¼šæŸå¤±å¯¹å‚æ•°çš„æ¢¯åº¦\n",
        "\n",
        "### ğŸ§  ç‰¹ç‚¹ï¼š\n",
        "\n",
        "* æ¯æ¬¡ç”¨ä¸€ä¸ªå°æ‰¹é‡ï¼ˆbatchï¼‰æ•°æ®è®¡ç®—æ¢¯åº¦ â†’ æ›´å¿«è¿­ä»£ï¼›\n",
        "* å®¹æ˜“é™·å…¥å±€éƒ¨æœ€å°å€¼ï¼›\n",
        "* å¯åŠ  momentum å¢å¼ºç¨³å®šæ€§ï¼š\n",
        "\n",
        "$$\n",
        "v_{t+1} = \\mu v_t - \\eta \\cdot \\nabla_\\theta \\mathcal{L} \\\\\n",
        "\\theta_{t+1} = \\theta_t + v_{t+1}\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… äºŒã€Adamï¼ˆAdaptive Moment Estimationï¼‰\n",
        "\n",
        "### ğŸ“˜ å…¬å¼æ¦‚è¦ï¼š\n",
        "\n",
        "Adam ç»“åˆäº†ï¼š\n",
        "\n",
        "* **Momentum**ï¼ˆä¸€é˜¶çŸ©ä¼°è®¡ï¼Œæ¢¯åº¦çš„æŒ‡æ•°åŠ æƒå¹³å‡ï¼‰ï¼›\n",
        "* **RMSProp**ï¼ˆäºŒé˜¶çŸ©ä¼°è®¡ï¼Œå¹³æ–¹æ¢¯åº¦çš„å¹³å‡ï¼‰ï¼›\n",
        "\n",
        "$$\n",
        "m_t = \\beta_1 m_{t-1} + (1 - \\beta_1) g_t \\quad \\text{(ä¸€é˜¶åŠ¨é‡)} \\\\\n",
        "v_t = \\beta_2 v_{t-1} + (1 - \\beta_2) g_t^2 \\quad \\text{(äºŒé˜¶åŠ¨é‡)} \\\\\n",
        "\\hat{m}_t = \\frac{m_t}{1 - \\beta_1^t}, \\quad \\hat{v}_t = \\frac{v_t}{1 - \\beta_2^t} \\quad \\text{(åå·®ä¿®æ­£)} \\\\\n",
        "\\theta_{t+1} = \\theta_t - \\eta \\cdot \\frac{\\hat{m}_t}{\\sqrt{\\hat{v}_t} + \\epsilon}\n",
        "$$\n",
        "\n",
        "### ğŸ§  ç‰¹ç‚¹ï¼š\n",
        "\n",
        "* å­¦ä¹ ç‡ **è‡ªåŠ¨é€‚åº”æ¯ä¸ªå‚æ•°**ï¼›\n",
        "* éå¸¸é€‚åˆç¨€ç–æ¢¯åº¦çš„ä»»åŠ¡ï¼ˆå¦‚ NLP ä¸­çš„è¯å‘é‡è®­ç»ƒï¼‰ï¼›\n",
        "* åˆå§‹åŒ–ä¸æ•æ„Ÿï¼Œè®­ç»ƒæ›´ç¨³å®šï¼›\n",
        "* æ”¶æ•›å¿«ï¼Œä½†å¯èƒ½æ³›åŒ–èƒ½åŠ›å·®ï¼ˆå®¹æ˜“è¿‡æ‹Ÿåˆï¼‰ï¼›\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… ç®€å•ç†è§£ï¼š\n",
        "\n",
        "| ç±»æ¯”   | SGD           | Adam                  |\n",
        "| ---- | ------------- | --------------------- |\n",
        "| ä½ èµ°è¿·å®« | æ‹¿ä¸€å¼ çº¸ï¼ˆå½“å‰æ¢¯åº¦ï¼‰ç…§ç€èµ° | æ‰‹é‡Œæ‹¿æŒ‡å—é’ˆï¼ˆè¿‡å»æ–¹å‘ï¼‰å’Œåœ°å›¾ï¼ˆæ¢¯åº¦åˆ†å¸ƒï¼‰ |\n",
        "| èµ°æ³•   | æ–¹å‘ç›´æ¥ç›´å»ï¼Œå¯èƒ½è¢«å›°   | ä¼šç»•è·¯ï¼Œä¼šåŠ é€Ÿï¼Œä¼šé¿å…é‡å¤èµ°é”™è·¯      |\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… å®è·µå»ºè®®\n",
        "\n",
        "* ğŸ”¹ **é»˜è®¤ç”¨ Adam**ï¼Œå¦‚æœä½ ä¸ç¡®å®šæˆ–è€…ä»»åŠ¡å¾ˆå¤æ‚ï¼›\n",
        "* ğŸ”¹ æƒ³è¦æ›´å¥½çš„**æ³›åŒ–èƒ½åŠ›**ï¼Œå¯ä»¥è€ƒè™‘ **SGD + Momentum**ï¼›\n",
        "* ğŸ”¹ åœ¨é¢„è®­ç»ƒé˜¶æ®µç”¨ Adamï¼Œåœ¨å¾®è°ƒé˜¶æ®µæ¢æˆ SGD ä¹Ÿå¾ˆå¸¸è§ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… æ€»ç»“ä¸€å¥è¯ï¼š\n",
        "\n",
        "> **Adam æ˜¯â€œèªæ˜çš„è‡ªåŠ¨é©¾é©¶â€ï¼Œè·‘å¾—å¿«ä¹Ÿç¨³ï¼›SGD æ˜¯â€œæ‰‹åŠ¨æŒ¡è€å¸æœºâ€ï¼Œæ…¢ä½†å®¹æ˜“æ§åˆ¶ï¼Œå®¹æ˜“æ³›åŒ–ã€‚**\n",
        "\n",
        "---\n",
        "\n",
        "å¦‚æœä½ æƒ³äº†è§£å®ƒä»¬åœ¨å…·ä½“é¡¹ç›®ä¸­çš„è¡¨ç°ï¼ˆæ¯”å¦‚è®­ç»ƒ ResNetã€BERT ç­‰æ¨¡å‹æ—¶çš„è¡¨ç°ï¼‰ï¼Œæˆ‘å¯ä»¥ç»§ç»­è¡¥å……å¯¹æ¯”æ¡ˆä¾‹ã€‚æ˜¯å¦éœ€è¦æˆ‘æ¼”ç¤ºä¸€æ®µä¸¤è€…å¯¹æ¯”è®­ç»ƒçš„ä»£ç ï¼Ÿ\n"
      ],
      "metadata": {
        "id": "U_DLN-N9ORjo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "éå¸¸å¥½ï¼`CrossEntropyLoss` æ˜¯åˆ†ç±»é—®é¢˜ä¸­æœ€å¸¸è§çš„æŸå¤±å‡½æ•°ã€‚å®ƒç»“åˆäº† **Softmax + è´Ÿå¯¹æ•°ä¼¼ç„¶ï¼ˆNegative Log Likelihoodï¼‰** ä¸¤ä¸ªæ­¥éª¤ï¼Œé€‚ç”¨äº**å¤šåˆ†ç±»**ä»»åŠ¡ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… ä¸€ã€CrossEntropyLoss çš„è®¡ç®—å…¬å¼\n",
        "\n",
        "å¯¹äºä¸€ä¸ªæ ·æœ¬çš„æŸå¤±ï¼ˆå‡è®¾ç±»åˆ«æ€»æ•°æ˜¯ $C$ï¼Œæ¨¡å‹è¾“å‡º logits æ˜¯ $\\mathbf{z} = [z_1, z_2, ..., z_C]$ï¼Œæ­£ç¡®æ ‡ç­¾æ˜¯ç¬¬ $y$ ç±»ï¼‰ï¼š\n",
        "\n",
        "1. **å…ˆåš softmax å¾—åˆ°æ¦‚ç‡åˆ†å¸ƒ**ï¼š\n",
        "\n",
        "$$\n",
        "\\hat{y}_i = \\frac{e^{z_i}}{\\sum_{j=1}^{C} e^{z_j}}\n",
        "$$\n",
        "\n",
        "2. **å†å¯¹çœŸå®ç±»åˆ« $y$ è®¡ç®—è´Ÿå¯¹æ•°æ¦‚ç‡**ï¼ˆäº¤å‰ç†µï¼‰ï¼š\n",
        "\n",
        "$$\n",
        "\\text{Loss} = -\\log(\\hat{y}_y)\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… äºŒã€å®é™…ä¾‹å­è®²è§£ï¼ˆæ‰‹åŠ¨è®¡ç®—ï¼‰\n",
        "\n",
        "å‡è®¾ä½ æœ‰ 3 ä¸ªç±»åˆ«ï¼Œæ¨¡å‹è¾“å‡º logitsï¼š\n",
        "\n",
        "```python\n",
        "logits = [2.0, 1.0, 0.1]\n",
        "label = 0  # æ­£ç¡®ç±»åˆ«æ˜¯ç¬¬ 0 ç±»\n",
        "```\n",
        "\n",
        "### ç¬¬ä¸€æ­¥ï¼šsoftmax\n",
        "\n",
        "$$\n",
        "\\begin{align*}\n",
        "e^{2.0} &= 7.389 \\\\\n",
        "e^{1.0} &= 2.718 \\\\\n",
        "e^{0.1} &= 1.105 \\\\\n",
        "\\text{æ€»å’Œ} &= 7.389 + 2.718 + 1.105 = 11.212 \\\\\n",
        "\\end{align*}\n",
        "$$\n",
        "\n",
        "å¾—åˆ° softmax æ¦‚ç‡ï¼š\n",
        "\n",
        "```python\n",
        "[7.389/11.212, 2.718/11.212, 1.105/11.212] â‰ˆ [0.659, 0.242, 0.099]\n",
        "```\n",
        "\n",
        "### ç¬¬äºŒæ­¥ï¼šäº¤å‰ç†µæŸå¤±\n",
        "\n",
        "ç”±äºæ­£ç¡®æ ‡ç­¾æ˜¯ç¬¬ 0 ç±»ï¼ˆæ¦‚ç‡æ˜¯ 0.659ï¼‰ï¼š\n",
        "\n",
        "$$\n",
        "\\text{Loss} = -\\log(0.659) â‰ˆ 0.417\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… ä¸‰ã€PyTorch ä¸­çš„ä»£ç å®ç°\n",
        "\n",
        "```python\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "logits = torch.tensor([[2.0, 1.0, 0.1]])  # shape: [batch_size=1, num_classes=3]\n",
        "labels = torch.tensor([0])  # æ­£ç¡®ç±»åˆ«ä¸º class 0\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "loss = loss_fn(logits, labels)\n",
        "\n",
        "print(loss.item())  # è¾“å‡ºå¤§çº¦ 0.417\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## âš ï¸ æ³¨æ„äº‹é¡¹\n",
        "\n",
        "* **è¾“å…¥ logits ä¸è¦å…ˆåš softmax**ï¼ŒPyTorch çš„ `CrossEntropyLoss` ä¼š**è‡ªåŠ¨å†…éƒ¨å¤„ç† softmax**ï¼›\n",
        "* `logits` çš„ shape æ˜¯ `[batch_size, num_classes]`ï¼›\n",
        "* `labels` æ˜¯æ•´å‹ç±»åˆ«ç´¢å¼•ï¼ˆä¸æ˜¯ one-hot å‘é‡ï¼‰ï¼Œshape æ˜¯ `[batch_size]`ï¼›\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… æ€»ç»“ä¸€å¥è¯ï¼š\n",
        "\n",
        "> `CrossEntropyLoss = -log(æ­£ç¡®ç±»åˆ«çš„ softmax æ¦‚ç‡)`ï¼Œå®ƒåº¦é‡æ¨¡å‹â€œå¯¹æ­£ç¡®ç­”æ¡ˆçš„ä¿¡å¿ƒâ€ï¼Œè¶Šä¸è‡ªä¿¡ï¼ŒæŸå¤±è¶Šå¤§ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "æ˜¯å¦è¿˜æƒ³çœ‹å¤šä¸ªæ ·æœ¬ batch ä¸‹çš„äº¤å‰ç†µè®¡ç®—ï¼Ÿæˆ–è€… one-hot æ ‡ç­¾ä¸äº¤å‰ç†µçš„å…³ç³»ï¼Ÿæˆ‘å¯ä»¥ç»§ç»­è®²ã€‚\n"
      ],
      "metadata": {
        "id": "w2DS0UeFOrdG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_dataloader))\n",
        "len(train_dataloader.dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "waSg2mmuO-uN",
        "outputId": "5a00dd38-e607-4e37-c882-a48b31b3b79f"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "938\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "  size = len(dataloader.dataset)\n",
        "  model.train()\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "    X, y = X.to(device), y.to(device)\n",
        "\n",
        "    # Compute prediction error\n",
        "    pred = model(X)\n",
        "    loss = loss_fn(pred, y)\n",
        "\n",
        "    # Backpropagation\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      loss, current = loss.item(), (batch + 1) * len(X)\n",
        "      print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "def test(dataloader, model, loss_fn):\n",
        "  size = len(dataloader.dataset)\n",
        "  num_batches = len(dataloader)\n",
        "  model.eval()\n",
        "  test_loss, correct = 0, 0\n",
        "  with torch.no_grad():\n",
        "    for X, y in dataloader:\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      pred = model(X)\n",
        "      test_loss += loss_fn(pred, y).item()\n",
        "      correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "  test_loss /= num_batches\n",
        "  correct /= size\n",
        "  print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "\n"
      ],
      "metadata": {
        "id": "xmnaerDUO1ml"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "éå¸¸æ£’çš„é—®é¢˜ï¼ä½ æåˆ°äº†ä¸¤ä¸ªæ·±åº¦å­¦ä¹ è®­ç»ƒè¿‡ç¨‹ä¸­å¾ˆå…³é”®ä½†å®¹æ˜“è¢«å¿½ç•¥çš„ç»†èŠ‚ï¼š`model.train()` vs `model.eval()` ä»¥åŠ test ä¸­ loss çš„è®¡ç®—ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… ä¸€ã€`model.train()` å’Œ `model.eval()` æ˜¯å¹²å˜›çš„ï¼Ÿ\n",
        "\n",
        "è¿™ä¸¤ä¸ªæ–¹æ³•æ˜¯ç”¨äº**åˆ‡æ¢æ¨¡å‹çš„å·¥ä½œæ¨¡å¼**çš„ï¼Œå®ƒä»¬ä¸ä¼šç›´æ¥å½±å“ forward è¿ç®—çš„é€»è¾‘ï¼Œä½†ä¼šå½±å“**æŸäº›ç‰¹å®šå±‚çš„è¡Œä¸º**ï¼Œæ¯”å¦‚ï¼š\n",
        "\n",
        "| æ¨¡å‹å±‚ç±»å‹       | åœ¨ `train()` æ¨¡å¼ä¸‹è¡Œä¸º  | åœ¨ `eval()` æ¨¡å¼ä¸‹è¡Œä¸º |\n",
        "| ----------- | ------------------ | ---------------- |\n",
        "| `Dropout`   | æ¯æ¬¡éšæœºä¸¢æ‰ä¸€éƒ¨åˆ†ç¥ç»å…ƒ       | ä¸è¿›è¡Œ Dropoutï¼ˆå³ä¸ä¸¢ï¼‰ |\n",
        "| `BatchNorm` | ä½¿ç”¨å½“å‰ batch ç»Ÿè®¡é‡åšæ ‡å‡†åŒ– | ä½¿ç”¨è®­ç»ƒæ—¶ä¿å­˜çš„å…¨å±€å‡å€¼å’Œæ–¹å·®  |\n",
        "\n",
        "### âœ³ï¸ ä½ ä»£ç ä¸­å°±æœ‰è¿™äº›å±‚ï¼š\n",
        "\n",
        "```python\n",
        "nn.Dropout(0.2),\n",
        "nn.BatchNorm1d(512),\n",
        "```\n",
        "\n",
        "æ‰€ä»¥ï¼š\n",
        "\n",
        "* åœ¨è®­ç»ƒæ—¶ï¼Œä½¿ç”¨ `model.train()` æ˜¯å¿…é¡»çš„ï¼Œå¦åˆ™ Dropout å’Œ BatchNorm ä¸ä¼šç”Ÿæ•ˆï¼›\n",
        "* åœ¨æµ‹è¯•/éªŒè¯æ—¶ï¼Œä½¿ç”¨ `model.eval()` æ˜¯å¿…é¡»çš„ï¼Œå¦åˆ™è¿™äº›å±‚çš„è¡Œä¸ºä¼šå¯¼è‡´ç»“æœä¸ç¨³å®šæˆ–é”™è¯¯ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… äºŒã€å…³äº test ä¸­ loss çš„è®¡ç®—æ–¹å¼\n",
        "\n",
        "ä½ è¯´å¾—æ²¡é”™ï¼Œtest ä¸­æ¯ä¸ª batch çš„ loss æ˜¯ä¸åŒçš„ã€‚ä½†æ˜¯ä»£ç è¿™æ ·å¤„ç†ï¼š\n",
        "\n",
        "```python\n",
        "test_loss += loss_fn(pred, y).item()  # ç´¯åŠ æ¯ä¸ª batch çš„ loss\n",
        "...\n",
        "test_loss /= num_batches              # æœ€åé™¤ä»¥ batch æ•°\n",
        "```\n",
        "\n",
        "è¿™æ˜¯åœ¨**è®¡ç®—æ‰€æœ‰ batch çš„å¹³å‡ lossï¼ˆå³å¹³å‡æ¯ä¸ª batch çš„æŸå¤±ï¼‰**ï¼Œè¿™ç§å†™æ³•è™½ç„¶ä¸æ˜¯æœ€ä¸¥æ ¼çš„â€œå¹³å‡æ¯ä¸ªæ ·æœ¬çš„æŸå¤±â€ï¼Œä½†**åœ¨ batch size ç›¸åŒçš„æƒ…å†µä¸‹æ˜¯ç­‰ä»·çš„**ã€‚\n",
        "\n",
        "### ğŸ§  å¦‚æœä½ æƒ³æ›´ä¸¥æ ¼ï¼Œå¯ä»¥è¿™æ ·å†™ï¼š\n",
        "\n",
        "```python\n",
        "test_loss += loss_fn(pred, y).item() * X.size(0)  # æŒ‰ç…§æ¯ä¸ªæ ·æœ¬åŠ æƒç´¯åŠ \n",
        "...\n",
        "test_loss /= size  # æœ€åé™¤ä»¥æ€»æ ·æœ¬æ•°\n",
        "```\n",
        "\n",
        "è¿™ç§æ–¹å¼æ›´ç²¾ç¡®ï¼Œé€‚åˆåœ¨ batch size ä¸ä¸€è‡´æ—¶ä½¿ç”¨ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… æ€»ç»“ä¸€å¥è¯ï¼š\n",
        "\n",
        "* `model.train()`ï¼šè®¾ç½®ä¸ºè®­ç»ƒæ¨¡å¼ï¼Œ**å¯ç”¨ Dropout å’Œ BatchNorm è®­ç»ƒè¡Œä¸º**ï¼›\n",
        "* `model.eval()`ï¼šè®¾ç½®ä¸ºæµ‹è¯•æ¨¡å¼ï¼Œ**å…³é—­ Dropoutï¼Œç”¨ BatchNorm çš„å†å²å‡å€¼**ï¼›\n",
        "* æµ‹è¯• loss çš„å†™æ³•æ²¡é”™ï¼Œä½†åœ¨ batch size ä¸ä¸€è‡´æ—¶å»ºè®®åŠ æƒå¹³å‡ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "å¦‚æœä½ æ„¿æ„ï¼Œæˆ‘å¯ä»¥å¸®ä½ å†™ä¸€ä¸ªå®Œæ•´ç‰ˆæœ¬çš„ `train` + `test` æ¡†æ¶ï¼ŒåŒ…æ‹¬æ—¥å¿—è®°å½•ã€æ—©åœã€å¯è§†åŒ–ç­‰åŠŸèƒ½ã€‚æ˜¯å¦éœ€è¦ï¼Ÿ\n"
      ],
      "metadata": {
        "id": "JM676vmtT5yc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "è¿™æ˜¯ä¸€ä¸ªéå¸¸å…³é”®çš„é—®é¢˜ï¼Œå¾ˆå¤šåˆå­¦è€…å®¹æ˜“è¯¯è§£ï¼ä½ é—®çš„æ˜¯ï¼š\n",
        "\n",
        "> `loss.item()` æ˜¯ä¸æ˜¯åªå–äº†ç¬¬ä¸€ä¸ªæ ·æœ¬çš„ lossï¼Ÿ\n",
        "\n",
        "### âœ… ç­”æ¡ˆæ˜¯ï¼š**ä¸æ˜¯ï¼`loss.item()` æ˜¯æ•´ä¸ª batch çš„å¹³å‡ lossï¼ˆæ ‡é‡ï¼‰**\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ” è¯¦ç»†è§£é‡Šï¼š\n",
        "\n",
        "ä½ åœ¨ä»£ç ä¸­è®¡ç®—äº†ï¼š\n",
        "\n",
        "```python\n",
        "loss = loss_fn(pred, y)  # pred.shape: (batch_size, num_classes)\n",
        "```\n",
        "\n",
        "PyTorch ä¸­é»˜è®¤çš„ `loss_fn = nn.CrossEntropyLoss()` **è¿”å›çš„æ˜¯æ•´ä¸ª batch çš„å¹³å‡ loss**ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼š\n",
        "\n",
        "$$\n",
        "\\text{loss} = \\frac{1}{N} \\sum_{i=1}^N \\text{CrossEntropy}(y_i, \\hat{y}_i)\n",
        "$$\n",
        "\n",
        "å…¶ä¸­ $N$ æ˜¯å½“å‰ batch çš„å¤§å°ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”¸ é‚£ `loss.item()` æ˜¯åšä»€ä¹ˆçš„ï¼Ÿ\n",
        "\n",
        "`loss` æ˜¯ä¸€ä¸ªå¼ é‡ï¼ˆ`tensor(0.3874, grad_fn=...)`ï¼‰ï¼Œå®ƒè¿˜å¸¦ç€è®¡ç®—å›¾ã€‚\n",
        "\n",
        "> `loss.item()` æ˜¯æŠŠè¿™ä¸ªå¼ é‡é‡Œçš„**å•ä¸ªæ ‡é‡å€¼å–å‡ºæ¥**ï¼Œå˜æˆ Python çš„ floatï¼Œæ–¹ä¾¿ä½ æ‰“å°ã€è®°å½•æˆ–å­˜å…¥æ—¥å¿—æ–‡ä»¶ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "### âœ… ä¸¾ä¸ªä¾‹å­ï¼š\n",
        "\n",
        "å‡è®¾ä½ çš„ batch size æ˜¯ 64ï¼Œæ¨¡å‹å¯¹è¿™ 64 ä¸ªæ ·æœ¬éƒ½åšäº†é¢„æµ‹ï¼Œ`loss_fn` ä¼šè¿”å›ï¼š\n",
        "\n",
        "```python\n",
        "loss = tensor(0.3472, grad_fn=<...>)\n",
        "```\n",
        "\n",
        "ä½ å†æ‰§è¡Œï¼š\n",
        "\n",
        "```python\n",
        "loss.item()  # â†’ 0.3472ï¼ˆfloat ç±»å‹ï¼‰\n",
        "```\n",
        "\n",
        "è¿™ä¸ªæ•°å€¼å°±æ˜¯**è¿™ 64 ä¸ªæ ·æœ¬çš„å¹³å‡ loss**ï¼Œä¸æ˜¯æŸä¸€ä¸ªæ ·æœ¬çš„ lossã€‚\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… è¡¥å……ï¼šæƒ³è¦æ¯ä¸ªæ ·æœ¬çš„ loss æ€ä¹ˆåšï¼Ÿ\n",
        "\n",
        "å¯ä»¥ç”¨ `reduction='none'` çš„æ–¹å¼ï¼š\n",
        "\n",
        "```python\n",
        "loss_fn = nn.CrossEntropyLoss(reduction='none')\n",
        "losses = loss_fn(pred, y)  # shape: (batch_size,)\n",
        "```\n",
        "\n",
        "æ­¤æ—¶ï¼š\n",
        "\n",
        "* `losses[i]` å°±æ˜¯ç¬¬ `i` ä¸ªæ ·æœ¬çš„ lossï¼›\n",
        "* å¦‚æœä½ æƒ³è‡ªå·±ç®—å¹³å‡ï¼Œå¯ä»¥ï¼š\n",
        "\n",
        "  ```python\n",
        "  loss = losses.mean()\n",
        "  ```\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… æ€»ç»“ä¸€å¥è¯ï¼š\n",
        "\n",
        "> `loss.item()` æ˜¯æ•´ä¸ª batch çš„å¹³å‡ lossï¼ˆä¸€ä¸ªæ ‡é‡ï¼‰ï¼Œ**ä¸æ˜¯ç¬¬ä¸€ä¸ªæ ·æœ¬çš„ loss**ï¼Œå®ƒåªæ˜¯æŠŠ tensor è½¬ä¸º floatã€‚\n",
        "\n",
        "å¦‚æœä½ æƒ³è¦æ‰“å°æ¯ä¸ªæ ·æœ¬çš„æŸå¤±ï¼Œæˆ‘å¯ä»¥å¸®ä½ æ”¹ä¸€ä¸‹ä»£ç å±•ç¤ºã€‚æ˜¯å¦éœ€è¦ï¼Ÿ\n"
      ],
      "metadata": {
        "id": "7bbDeJXMidY7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "for t in range(epochs):\n",
        "  print(f\"Epoch {t+1}\\n -------------------------------\")\n",
        "  train(train_dataloader, model, loss_fn, optimizer)\n",
        "  test(test_dataloader, model, loss_fn)\n",
        "\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScdmarkNT4wm",
        "outputId": "9a52d02e-9c2b-4c96-9bef-cda36bc246aa"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            " -------------------------------\n",
            "loss: 2.351133 [   64/60000]\n",
            "loss: 1.504371 [ 6464/60000]\n",
            "loss: 1.231074 [12864/60000]\n",
            "loss: 1.036299 [19264/60000]\n",
            "loss: 0.953311 [25664/60000]\n",
            "loss: 0.944878 [32064/60000]\n",
            "loss: 0.852010 [38464/60000]\n",
            "loss: 0.914644 [44864/60000]\n",
            "loss: 0.760960 [51264/60000]\n",
            "loss: 0.678545 [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 77.0%, Avg loss: 0.725412 \n",
            "\n",
            "Epoch 2\n",
            " -------------------------------\n",
            "loss: 0.797271 [   64/60000]\n",
            "loss: 0.630035 [ 6464/60000]\n",
            "loss: 0.684512 [12864/60000]\n",
            "loss: 0.679657 [19264/60000]\n",
            "loss: 0.832178 [25664/60000]\n",
            "loss: 0.604194 [32064/60000]\n",
            "loss: 0.648339 [38464/60000]\n",
            "loss: 0.796758 [44864/60000]\n",
            "loss: 0.723518 [51264/60000]\n",
            "loss: 0.660618 [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 80.1%, Avg loss: 0.592749 \n",
            "\n",
            "Epoch 3\n",
            " -------------------------------\n",
            "loss: 0.732579 [   64/60000]\n",
            "loss: 0.669723 [ 6464/60000]\n",
            "loss: 0.673791 [12864/60000]\n",
            "loss: 0.489371 [19264/60000]\n",
            "loss: 0.478027 [25664/60000]\n",
            "loss: 0.461428 [32064/60000]\n",
            "loss: 0.515199 [38464/60000]\n",
            "loss: 0.667646 [44864/60000]\n",
            "loss: 0.694426 [51264/60000]\n",
            "loss: 0.561443 [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 81.8%, Avg loss: 0.530315 \n",
            "\n",
            "Epoch 4\n",
            " -------------------------------\n",
            "loss: 0.626839 [   64/60000]\n",
            "loss: 0.796239 [ 6464/60000]\n",
            "loss: 0.576547 [12864/60000]\n",
            "loss: 0.452355 [19264/60000]\n",
            "loss: 0.582835 [25664/60000]\n",
            "loss: 0.502582 [32064/60000]\n",
            "loss: 0.560854 [38464/60000]\n",
            "loss: 0.438994 [44864/60000]\n",
            "loss: 0.451904 [51264/60000]\n",
            "loss: 0.360498 [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 82.6%, Avg loss: 0.494021 \n",
            "\n",
            "Epoch 5\n",
            " -------------------------------\n",
            "loss: 0.480244 [   64/60000]\n",
            "loss: 0.508736 [ 6464/60000]\n",
            "loss: 0.450043 [12864/60000]\n",
            "loss: 0.537892 [19264/60000]\n",
            "loss: 0.412323 [25664/60000]\n",
            "loss: 0.416140 [32064/60000]\n",
            "loss: 0.386087 [38464/60000]\n",
            "loss: 0.685761 [44864/60000]\n",
            "loss: 0.311524 [51264/60000]\n",
            "loss: 0.407041 [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 83.3%, Avg loss: 0.473002 \n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"model.pth\")\n",
        "print(\"Save PyTorch Model State to model.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0vu9mByVQFP",
        "outputId": "37e3070a-3189-483c-bbe5-b05b95589330"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Save PyTorch Model State to model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading models\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "model.load_state_dict(torch.load(\"model.pth\", weights_only=True))"
      ],
      "metadata": {
        "id": "vAeN37NFVaib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = [\n",
        "    \"T-shirt/top\",\n",
        "    \"Trouser\",\n",
        "    \"Pullover\",\n",
        "    \"Dress\",\n",
        "    \"Coat\",\n",
        "    \"Sandal\",\n",
        "    \"Shirt\",\n",
        "    \"Sneaker\",\n",
        "    \"Bag\",\n",
        "    \"Ankle boot\",\n",
        "]\n",
        "\n",
        "model.eval()\n",
        "x,y = test_data[0]\n",
        "model.to(device)\n",
        "with torch.no_grad():\n",
        "  x =x.to(device)\n",
        "  pred = model(x)\n",
        "  print(pred)\n",
        "  # predicted = classes[pred[0].argmax(0)]\n",
        "  predicted = classes[pred.argmax(1).item()]\n",
        "  actual = classes[y]\n",
        "  print(f\"Predicted: {predicted}, Actual: {actual}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mk0k-lL5XPTK",
        "outputId": "fd3198f6-bf9a-4998-e681-6e0a57c60016"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1.7596, -1.9728, -1.8500, -1.4932, -2.2793,  2.3234, -1.8076,  3.5825,\n",
            "         -0.0408,  4.3602]], device='cuda:0')\n",
            "Predicted: Ankle boot, Actual: Ankle boot\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "å¾ˆå¥½ï¼è®©æˆ‘ä»¬é€æ­¥æ‹†è§£ `pred(x)[0].argmax(0)` çš„å«ä¹‰ï¼Œå®ƒç»å¸¸å‡ºç°åœ¨**åˆ†ç±»æ¨¡å‹é¢„æµ‹ä¸­**ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… å‡è®¾èƒŒæ™¯ï¼š\n",
        "\n",
        "ä½ æœ‰ä¸€ä¸ª**å¤šåˆ†ç±»æ¨¡å‹**ï¼ˆæ¯”å¦‚ç”¨äºè¯†åˆ«æ‰‹å†™æ•°å­—çš„ MNISTï¼‰ï¼Œæ¨¡å‹è¾“å…¥ä¸€ä¸ªæ ·æœ¬åè¾“å‡ºä¸€ä¸ªå‘é‡ï¼ˆlogitsï¼‰ï¼Œä¾‹å¦‚ï¼š\n",
        "\n",
        "```python\n",
        "pred(x)  â†’ tensor([[0.2, -1.0, 2.3, 0.5, ..., -0.6]])  # shape: [1, num_classes]\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… é€æ­¥è§£é‡Š `pred(x)[0].argmax(0)`\n",
        "\n",
        "### ğŸ”¹ `pred(x)`\n",
        "\n",
        "æ¨¡å‹å¯¹è¾“å…¥ `x` çš„é¢„æµ‹è¾“å‡ºï¼Œå½¢çŠ¶ä¸€èˆ¬æ˜¯ `[1, num_classes]`ï¼ˆ1 è¡¨ç¤º batch size = 1ï¼‰\n",
        "\n",
        "ä¾‹å¦‚ï¼š\n",
        "\n",
        "```python\n",
        "tensor([[0.2, -1.0, 2.3, 0.5, -0.6]])\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”¹ `pred(x)[0]`\n",
        "\n",
        "å–å‡ºç¬¬ä¸€ä¸ªï¼ˆä¹Ÿæ˜¯å”¯ä¸€ä¸€ä¸ªï¼‰æ ·æœ¬çš„é¢„æµ‹ç»“æœï¼Œå˜æˆä¸€ç»´ tensorï¼š\n",
        "\n",
        "```python\n",
        "tensor([0.2, -1.0, 2.3, 0.5, -0.6])  # shape: [num_classes]\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”¹ `.argmax(0)`\n",
        "\n",
        "åœ¨ç»´åº¦ 0ï¼ˆå› ä¸ºæ˜¯ä¸€ç»´å‘é‡ï¼‰ä¸Šå–æœ€å¤§å€¼çš„**ç´¢å¼•**ï¼ˆindexï¼‰ï¼š\n",
        "\n",
        "```python\n",
        "argmax(0) â†’ 2  # å› ä¸º 2.3 æ˜¯æœ€å¤§å€¼ï¼Œå®ƒåœ¨ç¬¬ 2 ä¸ªä½ç½®\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… æœ€ç»ˆæ„ä¹‰ï¼š\n",
        "\n",
        "```python\n",
        "pred(x)[0].argmax(0)\n",
        "```\n",
        "\n",
        "è¿™æ®µä»£ç çš„ä½œç”¨æ˜¯ï¼š\n",
        "\n",
        "> **å¾—åˆ°æ¨¡å‹å¯¹æ ·æœ¬ `x` çš„é¢„æµ‹ç±»åˆ«ï¼ˆå³åˆ†æ•°æœ€é«˜çš„ç±»åˆ«çš„ç´¢å¼•ï¼‰**\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… ç¤ºä¾‹æ€»ç»“ï¼š\n",
        "\n",
        "```python\n",
        "import torch\n",
        "\n",
        "output = torch.tensor([[0.2, -1.0, 2.3, 0.5, -0.6]])\n",
        "pred_class = output[0].argmax(0)\n",
        "print(pred_class)  # è¾“å‡ºï¼štensor(2)\n",
        "```\n",
        "\n",
        "ä»£è¡¨è¿™ä¸ªæ ·æœ¬çš„é¢„æµ‹ç±»åˆ«æ˜¯ç±» 2ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… æ‰©å±•å»ºè®®ï¼š\n",
        "\n",
        "å¦‚æœä½ æœ‰å¤šä¸ªæ ·æœ¬ï¼Œå»ºè®®ä½¿ç”¨ï¼š\n",
        "\n",
        "```python\n",
        "pred_classes = pred(x).argmax(dim=1)\n",
        "```\n",
        "\n",
        "è¿™æ ·å¯ä»¥ä¸€æ¬¡æ€§å¾—åˆ° batch å†…æ‰€æœ‰æ ·æœ¬çš„é¢„æµ‹ç±»åˆ«ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "æ˜¯å¦éœ€è¦æˆ‘ç”»ä¸€å¼ å›¾æ¥è¯´æ˜ argmax çš„å«ä¹‰ï¼Ÿæˆ–è€…è®²è®² `softmax + argmax` å’Œ `CrossEntropyLoss` ä¹‹é—´çš„å…³ç³»ï¼Ÿ\n"
      ],
      "metadata": {
        "id": "aJ9etjwQX-ts"
      }
    }
  ]
}