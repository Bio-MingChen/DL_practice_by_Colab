{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyODVksC6PWzl8unAWy7O9Qp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bio-MingChen/DL_practice_by_Colab/blob/main/pytorch_test20250803.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "Hp_uPMgY0R7G"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "E3P4foY1HvQ1",
        "outputId": "87adac26-b068-4944-b126-85e92670f7d9"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.6.0+cu124'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n"
      ],
      "metadata": {
        "id": "25tBOsgP0pYN"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data[0][0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXkFacDc9RsB",
        "outputId": "98111404-59fa-4517-daf3-eb7a700a010a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_data[0][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXm3vfUT9wo0",
        "outputId": "516f774c-e9d1-4fc4-983f-1b8016570401"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "train_dataloader = DataLoader(training_data,batch_size=batch_size,shuffle=True)\n",
        "test_dataloader = DataLoader(test_data,batch_size=batch_size,shuffle=True)"
      ],
      "metadata": {
        "id": "87x1nvZG9SRL"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for X,y in test_dataloader:\n",
        "  print(f\"Shape of X [N,C,H,W]: {X.shape}\")\n",
        "  print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDpHvLw4-Ptg",
        "outputId": "cca9288b-6b99-4ad1-ba1a-4f5cba839e7a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X [N,C,H,W]: torch.Size([64, 1, 28, 28])\n",
            "Shape of y: torch.Size([64]) torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(train_dataloader))[1].shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RsesEq3J-3PU",
        "outputId": "bfe924d6-1da0-4213-9fed-9345a9075e70"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "labels_map = {\n",
        "    0: \"T-Shirt\",\n",
        "    1: \"Trouser\",\n",
        "    2: \"Pullover\",\n",
        "    3: \"Dress\",\n",
        "    4: \"Coat\",\n",
        "    5: \"Sandal\",\n",
        "    6: \"Shirt\",\n",
        "    7: \"Sneaker\",\n",
        "    8: \"Bag\",\n",
        "    9: \"Ankle Boot\",\n",
        "}\n",
        "img = training_data[0][0]\n",
        "label = training_data[0][1]\n",
        "plt.imshow(img.squeeze(),cmap=\"gray\")\n",
        "plt.title(labels_map[label])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "id": "ubNT-HuM-Y6x",
        "outputId": "c4a08572-f43c-44fe-ce3c-72c0cb8f25f7"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Ankle Boot')"
            ]
          },
          "metadata": {},
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img.squeeze().shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5euiuitA-sz",
        "outputId": "38989308-0d23-481a-f5a1-f7150654c645"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img.squeeze().unsqueeze(0).shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLSqzb9PBEyh",
        "outputId": "601aaf54-9b0f-4324-ca97-6a325a51f3f6"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "åœ¨ Python çš„ `numpy` å’Œ `PyTorch`ï¼ˆä»¥åŠ `TensorFlow`ï¼‰ä¸­ï¼Œ`squeeze()` æ˜¯ä¸€ä¸ªéå¸¸å¸¸ç”¨çš„å‡½æ•°ï¼Œå®ƒçš„ä½œç”¨æ˜¯ï¼š\n",
        "\n",
        "> **ç§»é™¤å½¢çŠ¶ä¸­ä¸º 1 çš„ç»´åº¦ï¼ˆsizeä¸º1çš„ç»´åº¦ï¼‰**\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”§ åŸºæœ¬ç”¨æ³•\n",
        "\n",
        "### NumPy ä¸­ï¼š\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "\n",
        "x = np.array([[[1], [2], [3]]])  # shape: (1, 3, 1)\n",
        "x_squeezed = np.squeeze(x)       # shape: (3,)\n",
        "\n",
        "print(x.shape)        # (1, 3, 1)\n",
        "print(x_squeezed.shape)  # (3,)\n",
        "```\n",
        "\n",
        "### PyTorch ä¸­ï¼š\n",
        "\n",
        "```python\n",
        "import torch\n",
        "\n",
        "x = torch.zeros(1, 3, 1)\n",
        "x_squeezed = x.squeeze()\n",
        "\n",
        "print(x.shape)        # torch.Size([1, 3, 1])\n",
        "print(x_squeezed.shape)  # torch.Size([3])\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ§  ä»€ä¹ˆæ—¶å€™ä¼šç”¨åˆ° `squeeze()`ï¼Ÿ\n",
        "\n",
        "### 1. **å»æ‰å¤šä½™çš„ç»´åº¦æ–¹ä¾¿è®¡ç®—**\n",
        "\n",
        "å¾ˆå¤šæ—¶å€™åŠ è½½æ•°æ®æˆ–æŸäº›æ“ä½œåï¼Œå¼ é‡ä¼šå¤šå‡ºä¸å¿…è¦çš„ `1` ç»´åº¦ï¼Œå¯èƒ½ä¼šå½±å“åç»­çš„è®¡ç®—ï¼Œæ¯”å¦‚ï¼š\n",
        "\n",
        "```python\n",
        "y = model(x)  # y shape: (batch_size, 1)\n",
        "loss = loss_fn(y.squeeze(), target)  # å°† shape (batch_size, 1) -> (batch_size,)\n",
        "```\n",
        "\n",
        "### 2. **åŒ¹é…ç»´åº¦**\n",
        "\n",
        "åœ¨è®¡ç®— loss æˆ–è¿›è¡Œå¼ é‡æ‹¼æ¥ï¼ˆconcatenateï¼‰æ—¶ï¼Œç»´åº¦ä¸ä¸€è‡´ä¼šæŠ¥é”™ï¼Œå¸¸è§çš„åšæ³•å°±æ˜¯ç”¨ `.squeeze()` æˆ– `.unsqueeze()` æ¥è°ƒæ•´ã€‚\n",
        "\n",
        "### 3. **è¾“å‡ºå•ä¸ªå€¼**\n",
        "\n",
        "ä¾‹å¦‚ï¼š\n",
        "\n",
        "```python\n",
        "x = torch.tensor([[[42]]])\n",
        "print(x.squeeze())  # tensor(42)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ§© è¿˜å¯ä»¥æŒ‡å®šè¦å»æ‰çš„ç»´åº¦\n",
        "\n",
        "```python\n",
        "x = torch.randn(1, 3, 1)\n",
        "x_squeeze_dim0 = x.squeeze(0)  # å»æ‰ç¬¬0ç»´\n",
        "x_squeeze_dim2 = x.squeeze(2)  # å»æ‰ç¬¬2ç»´\n",
        "```\n",
        "\n",
        "âš ï¸ å¦‚æœæŒ‡å®šçš„ç»´åº¦ä¸ä¸º1ï¼Œä¼šæŠ¥é”™ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸš« æ³¨æ„äº‹é¡¹\n",
        "\n",
        "* åªä¼šå»æ‰**ç»´åº¦æ˜¯1**çš„éƒ¨åˆ†ï¼›\n",
        "* `.squeeze()` æ˜¯ä¸æ”¹å˜åŸå¼ é‡çš„ï¼Œéœ€è¦èµ‹å€¼æˆ–ä½¿ç”¨ inplace ç‰ˆæœ¬ï¼ˆå¦‚ `x.squeeze_()`ï¼‰ï¼›\n",
        "* å¯èƒ½ä¼šä¸å°å¿ƒæŠŠ batch ç»´åº¦ï¼ˆç»´åº¦ä¸º 1ï¼‰æŒ¤æ‰ï¼Œå¯¼è‡´åç»­æ¨¡å‹å¤„ç†å‡ºé”™ï¼Œæ‰€ä»¥è¦å°å¿ƒåœ¨ä»€ä¹ˆæ—¶å€™ç”¨ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… æ€»ç»“ä¸€å¥è¯ï¼š\n",
        "\n",
        "> `squeeze()` å°±æ˜¯åœ¨ä½ ä¸æƒ³è¦å¤šä½™çš„ 1 ç»´æ—¶ï¼ŒæŠŠå®ƒâ€œæŒ¤æ‰â€ï¼Œå¸¸ç”¨äºæ¨¡å‹è¾“å‡ºã€reshapeã€æ•°æ®å¯¹é½ç­‰åœºæ™¯ã€‚\n",
        "\n",
        "å¦‚æœä½ æœ‰æŸæ®µä»£ç æƒ³ç¡®è®¤æ˜¯å¦éœ€è¦ `.squeeze()`ï¼Œå¯ä»¥å‘ç»™æˆ‘ï¼Œæˆ‘æ¥å¸®ä½ åˆ¤æ–­ã€‚\n"
      ],
      "metadata": {
        "id": "wIBEG44oBl7e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rm6y6-MUJGyE",
        "outputId": "c5e1b4cd-3b3c-40b2-ab07-e013e92695ba"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "28*28"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4zWH5nUKWSE",
        "outputId": "a35fce07-cfff-4024-8599-5a6bd953b145"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "784"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.linear_relu_stack = nn.Sequential(\n",
        "        nn.Linear(28*28, 512),\n",
        "        nn.BatchNorm1d(512),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.2),\n",
        "\n",
        "        nn.Linear(512,512),\n",
        "        nn.BatchNorm1d(512),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.2),\n",
        "\n",
        "        nn.Linear(512,10)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.flatten(x)\n",
        "    logits = self.linear_relu_stack(x)\n",
        "    return logits\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cr9W8BQsJ1YI",
        "outputId": "55ad8ad1-eac0-4f30-c14c-3e8d3a8d98c2"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): Dropout(p=0.2, inplace=False)\n",
            "    (4): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): ReLU()\n",
            "    (7): Dropout(p=0.2, inplace=False)\n",
            "    (8): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "na050sSLMX0i"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "| å±‚             | ä½œç”¨                             |\n",
        "| ------------- | ------------------------------ |\n",
        "| `Linear`      | å…¨è¿æ¥å±‚ï¼Œäº§ç”Ÿçº¿æ€§å˜æ¢                    |\n",
        "| `BatchNorm1d` | å¯¹çº¿æ€§è¾“å‡ºåšæ ‡å‡†åŒ–ï¼Œ**ç¨³å®šè®­ç»ƒè¿‡ç¨‹**ï¼Œå‡è½»å†…éƒ¨åå˜é‡åç§» |\n",
        "| `ReLU`        | éçº¿æ€§æ¿€æ´»ï¼Œç»™æ¨¡å‹å¼•å…¥éçº¿æ€§èƒ½åŠ›               |\n",
        "| `Dropout`     | åœ¨è®­ç»ƒæ—¶éšæœºä¸¢å¼ƒéƒ¨åˆ†æ¿€æ´»å€¼ï¼Œ**é˜²æ­¢è¿‡æ‹Ÿåˆ**        |\n"
      ],
      "metadata": {
        "id": "1x3aN1cVLQay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "å½“ç„¶å¯ä»¥ï¼Œä¸‹é¢æ˜¯ç”¨**é€šä¿—æ˜“æ‡‚çš„æ–¹å¼**è§£é‡Š `BatchNorm1d` çš„ä½œç”¨ï¼š\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ§  ä¸€å¥è¯æ€»ç»“ï¼š\n",
        "\n",
        "> **BatchNorm1d å°±åƒæ˜¯åœ¨æ¯ä¸€å±‚ç¥ç»ç½‘ç»œâ€œåšæ ‡å‡†åŒ–å¤„ç†â€ï¼Œå¸®ä½ æŠŠæ•°æ®â€œæ•´ç†æ•´é½â€ï¼Œè®©ç½‘ç»œæ›´å®¹æ˜“å­¦å¾—å¿«ã€å­¦å¾—ç¨³ã€ä¸å®¹æ˜“å´©ã€‚**\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ§© ä¸ºä»€ä¹ˆè¦ç”¨ BatchNormï¼Ÿ\n",
        "\n",
        "æƒ³è±¡ä½ åœ¨æ•™ä¸€ä¸ªå­¦ç”Ÿï¼ˆç¥ç»ç½‘ç»œï¼‰å­¦ä¹ åšé¢˜ï¼ˆè®­ç»ƒä»»åŠ¡ï¼‰ï¼š\n",
        "\n",
        "* å¦‚æœé¢˜ç›®ï¼ˆè¾“å…¥ï¼‰æ ¼å¼å¾ˆæ··ä¹±ï¼Œæœ‰çš„å¤§æœ‰çš„å°ï¼Œæœ‰çš„å…¨æ˜¯è´Ÿæ•°ï¼Œæœ‰çš„çªç„¶å˜å¤§äº†ï¼›\n",
        "* å­¦ç”Ÿå°±ä¼šå¾ˆéš¾é€‚åº”ï¼Œå­¦ä¹ è¿‡ç¨‹ä¼šå¾ˆä¸ç¨³å®šï¼Œå®¹æ˜“å­¦å´©ã€å­¦æ…¢ã€‚\n",
        "\n",
        "**BatchNorm çš„ä½œç”¨å°±æ˜¯æŠŠè¿™äº›é¢˜ç›®ç»Ÿä¸€æ ¼å¼**ï¼š\n",
        "\n",
        "> è®©æ•°æ®å˜å¾—â€œå¹³å‡å€¼æ˜¯ 0ï¼Œæ ‡å‡†å·®æ˜¯ 1â€ï¼ˆæ ‡å‡†åŒ–ï¼‰\n",
        "\n",
        "è¿™æ ·å­¦ç”Ÿå°±èƒ½**å¿«é€Ÿè¿›å…¥çŠ¶æ€ï¼Œé›†ä¸­ç²¾åŠ›åšé¢˜ï¼ˆå­¦ä¹ ï¼‰**ï¼Œä¸ä¼šå› ä¸ºé¢˜ç›®å½¢å¼å˜åŒ–è€Œâ€œå¿ƒæ€å´©äº†â€ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”§ BatchNorm1d åœ¨å¹²å•¥ï¼Ÿ\n",
        "\n",
        "ä»¥ä¸€å¥ä»£ç ä¸ºä¾‹ï¼š\n",
        "\n",
        "```python\n",
        "nn.BatchNorm1d(512)\n",
        "```\n",
        "\n",
        "è¿™ä¸ªæ„æ€æ˜¯è¯´ï¼šå¯¹æ¯ä¸ª batch é‡Œçš„æ ·æœ¬ï¼Œåœ¨ `512` ç»´åº¦ä¸Šåˆ†åˆ«åšå¦‚ä¸‹æ“ä½œï¼š\n",
        "\n",
        "### æ¯ä¸€ç»´ç‰¹å¾éƒ½ä¼šï¼š\n",
        "\n",
        "1. **è®¡ç®—å½“å‰ batch çš„å‡å€¼å’Œæ–¹å·®**\n",
        "2. **æŠŠè¿™ç»´çš„æ•°æ®æ ‡å‡†åŒ–** â†’ å‡å»å‡å€¼ / é™¤ä»¥æ ‡å‡†å·®\n",
        "3. **å†ä¹˜ä¸€ä¸ªâ€œå¯å­¦ä¹ çš„ç¼©æ”¾å› å­â€ Î³ï¼ŒåŠ ä¸€ä¸ªâ€œåç§»é‡â€ Î²**\n",
        "\n",
        "æœ€ç»ˆè¾“å‡ºçš„æ˜¯ä¸€ä¸ª**æ ‡å‡†åŒ–åè¿˜å¸¦æœ‰ä¸€å®šçµæ´»æ€§**çš„ç‰¹å¾ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ’¡ ä¸¾ä¸ªä¾‹å­æ¥å½¢è±¡ç†è§£ï¼š\n",
        "\n",
        "å‡è®¾ä½ å–‚ç»™ç¥ç»ç½‘ç»œçš„æ•°æ®æ˜¯è¿™æ ·çš„ï¼š\n",
        "\n",
        "```python\n",
        "[[-100, 0, 300],\n",
        " [ -90, 1, 280],\n",
        " [-110, -1, 310]]\n",
        "```\n",
        "\n",
        "è¿™ä¸ªå·®å¼‚éå¸¸å¤§ï¼Œæ¨¡å‹éš¾å­¦ã€‚\n",
        "\n",
        "BatchNorm å°±ä¼šå¸®ä½ æŠŠæ¯ä¸€åˆ—**ç¼©æ”¾å’Œç§»åŠ¨**ï¼Œå˜æˆåƒè¿™æ ·ï¼š\n",
        "\n",
        "```python\n",
        "[[ 0.1, -0.2,  0.5],\n",
        " [-0.1,  0.0,  0.3],\n",
        " [-0.2,  0.2, -0.8]]\n",
        "```\n",
        "\n",
        "ç°åœ¨è¿™äº›å€¼å°±â€œæ•´é½â€å¤šäº†ï¼Œæ¨¡å‹æ›´å®¹æ˜“å¤„ç†ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… ä¼˜ç‚¹æ€»ç»“ï¼š\n",
        "\n",
        "| ä¼˜ç‚¹        | ç±»æ¯”                  |\n",
        "| --------- | ------------------- |\n",
        "| è®­ç»ƒæ›´å¿«      | å­¦ç”Ÿé¢å¯¹ç»Ÿä¸€æ ¼å¼çš„é¢˜ï¼Œåˆ·é¢˜æ•ˆç‡æå‡   |\n",
        "| è®­ç»ƒæ›´ç¨³å®š     | ä¸å®¹æ˜“â€œæ¢¯åº¦çˆ†ç‚¸/æ¶ˆå¤±â€        |\n",
        "| å‡å°‘å¯¹åˆå§‹åŒ–çš„ä¾èµ– | ä¸ç”¨å¤ªæ‹…å¿ƒåˆå§‹æƒé‡é€‰ä¸å¥½        |\n",
        "| æœ‰è½»å¾®æ­£åˆ™åŒ–æ•ˆæœ  | æœ‰ç‚¹åƒ Dropoutï¼Œèƒ½ç¨å¾®é˜²è¿‡æ‹Ÿåˆ |\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ¤” ä¸ºä»€ä¹ˆå« `BatchNorm1d`ï¼Ÿ\n",
        "\n",
        "å› ä¸ºå®ƒæ˜¯åœ¨**æ¯ä¸€ä¸ª batch ä¸Šåšâ€œ1D çš„ç‰¹å¾æ ‡å‡†åŒ–â€**ï¼ˆé€šå¸¸ç”¨äº `Linear` å±‚çš„è¾“å‡ºï¼‰ï¼Œæ‰€ä»¥å« `1d`ã€‚\n",
        "å¦‚æœæ˜¯ `Conv2d` é‚£ç§å›¾åƒæ•°æ®ï¼Œå°±è¦ç”¨ `BatchNorm2d`ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… æ€»ç»“ä¸€å¥é€šä¿—è¯ï¼š\n",
        "\n",
        "> **BatchNorm1d å°±æ˜¯å¸®ä½ çš„ç½‘ç»œâ€œæ•´é¡¿è¾“å…¥ç§©åºâ€ï¼Œæ ‡å‡†åŒ–æ¯ä¸€å±‚çš„æ•°æ®ï¼Œè®©å­¦ä¹ æ›´é«˜æ•ˆã€æ›´ç¨³å®šï¼Œä¸å®¹æ˜“å´©ã€‚**\n",
        "\n",
        "éœ€è¦æˆ‘ç”¨å›¾ç¤ºæˆ–åŠ¨ç”»å½¢å¼è§£é‡Šï¼Œä¹Ÿå¯ä»¥ç”»å›¾ç»™ä½ çœ‹ã€‚\n"
      ],
      "metadata": {
        "id": "wg_K-MtoLq8v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "éå¸¸å¥½ï¼ä½ æåˆ°äº†å‡ ä¸ªæ·±åº¦å­¦ä¹ ä¸­æœ€å…³é”®çš„éƒ¨åˆ†ï¼š**ReLU æ¿€æ´»å‡½æ•°ã€äº¤å‰ç†µæŸå¤±å‡½æ•° CrossEntropyLossï¼Œä»¥åŠ SGD ä¼˜åŒ–å™¨**ã€‚æˆ‘ä¼šä¸€ä¸€ç»™å‡ºå®ƒä»¬çš„**å…¬å¼ã€å›¾åƒå’Œä½œç”¨è§£é‡Š**ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… ä¸€ã€ReLUï¼ˆRectified Linear Unitï¼‰æ¿€æ´»å‡½æ•°\n",
        "\n",
        "### ğŸ”¸ å…¬å¼ï¼š\n",
        "\n",
        "$$\n",
        "\\text{ReLU}(x) = \\max(0, x)\n",
        "$$\n",
        "\n",
        "ä¹Ÿå°±æ˜¯è¯´ï¼š\n",
        "\n",
        "* å¦‚æœ $x > 0$ï¼Œè¾“å‡ºå°±æ˜¯ $x$\n",
        "* å¦‚æœ $x \\leq 0$ï¼Œè¾“å‡ºå°±æ˜¯ 0\n",
        "\n",
        "### ğŸ”¸ å›¾åƒï¼š\n",
        "\n",
        "```python\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "x = np.linspace(-10, 10, 100)\n",
        "y = np.maximum(0, x)\n",
        "\n",
        "plt.plot(x, y)\n",
        "plt.title('ReLU Activation Function')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('ReLU(x)')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "ï¼ˆä½ å¯ä»¥è¿è¡Œä¸Šé¢ä»£ç çœ‹çœ‹å›¾åƒï¼Œä¹Ÿå¯ä»¥æˆ‘å¸®ä½ ç”»å‡ºå›¾æ¥ï¼‰\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”¸ ä½œç”¨ï¼š\n",
        "\n",
        "* å¼•å…¥éçº¿æ€§ï¼Œä½¿ç¥ç»ç½‘ç»œå¯ä»¥å­¦ä¹ å¤æ‚çš„å‡½æ•°ï¼›\n",
        "* è®¡ç®—ç®€å•ï¼Œè®­ç»ƒå¿«é€Ÿï¼›\n",
        "* ä½†å¯èƒ½å‡ºç°â€œç¥ç»å…ƒæ­»äº¡â€é—®é¢˜ï¼ˆReLU è¾“å‡ºé•¿æœŸä¸º0ï¼‰ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… äºŒã€`nn.CrossEntropyLoss()`\n",
        "\n",
        "### ğŸ”¸ ç”¨é€”ï¼š\n",
        "\n",
        "è¿™æ˜¯ **åˆ†ç±»ä»»åŠ¡**ä¸­æœ€å¸¸ç”¨çš„æŸå¤±å‡½æ•°ï¼Œé€‚ç”¨äº `model` çš„è¾“å‡ºæ˜¯ **logits**ï¼ˆæœªç»è¿‡ `softmax` çš„å¾—åˆ†ï¼‰ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”¸ è®¡ç®—è¿‡ç¨‹åˆ†ä¸ºä¸¤æ­¥ï¼ˆPyTorch å†…éƒ¨è‡ªåŠ¨åšçš„ï¼‰ï¼š\n",
        "\n",
        "1. **å…ˆå¯¹ logits åš softmax å¾—åˆ°é¢„æµ‹æ¦‚ç‡ï¼š**\n",
        "\n",
        "$$\n",
        "\\hat{y}_i = \\frac{e^{z_i}}{\\sum_{j} e^{z_j}}\n",
        "$$\n",
        "\n",
        "å…¶ä¸­ï¼š\n",
        "\n",
        "* $z_i$ï¼šæ¨¡å‹è¾“å‡ºçš„ç¬¬ $i$ ç±»çš„ logit\n",
        "* $\\hat{y}_i$ï¼šsoftmax åçš„æ¦‚ç‡\n",
        "\n",
        "2. **å†è®¡ç®—äº¤å‰ç†µæŸå¤±ï¼ˆCross Entropyï¼‰ï¼š**\n",
        "\n",
        "$$\n",
        "\\text{Loss} = -\\sum_{i} y_i \\log(\\hat{y}_i)\n",
        "$$\n",
        "\n",
        "å…¶ä¸­ï¼š\n",
        "\n",
        "* $y_i$ æ˜¯ one-hot æ ‡ç­¾ï¼ˆåªæœ‰ä¸€ä¸ª 1 å…¶ä»–éƒ½æ˜¯ 0ï¼‰\n",
        "* å®é™…è®¡ç®—æ—¶åªä¿ç•™æ­£ç¡®æ ‡ç­¾é‚£ä¸€é¡¹ï¼š$-\\log(\\hat{y}_{\\text{true class}})$\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”¸ ä¸¾ä¸ªä¾‹å­ï¼š\n",
        "\n",
        "å¦‚æœä½ çš„æ¨¡å‹è¾“å‡ºæ˜¯ï¼š\n",
        "\n",
        "```python\n",
        "logits = [2.0, 1.0, 0.1]  # è¡¨ç¤ºä¸‰ä¸ªç±»åˆ«çš„å¾—åˆ†\n",
        "label = 0  # æ­£ç¡®ç±»åˆ«æ˜¯ç¬¬0ç±»\n",
        "```\n",
        "\n",
        "PyTorch è‡ªåŠ¨è®¡ç®—ï¼š\n",
        "\n",
        "```python\n",
        "softmax = [0.659, 0.242, 0.099]\n",
        "loss = -log(0.659) â‰ˆ 0.417\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… ä¸‰ã€`torch.optim.SGD(...)` éšæœºæ¢¯åº¦ä¸‹é™ä¼˜åŒ–å™¨\n",
        "\n",
        "### ğŸ”¸ å…¬å¼ï¼š\n",
        "\n",
        "æ¯ä¸€è½®è¿­ä»£ä¸­ï¼Œæ›´æ–°å‚æ•°çš„å…¬å¼æ˜¯ï¼š\n",
        "\n",
        "$$\n",
        "\\theta = \\theta - \\eta \\cdot \\nabla_{\\theta} \\mathcal{L}\n",
        "$$\n",
        "\n",
        "å…¶ä¸­ï¼š\n",
        "\n",
        "* $\\theta$ï¼šæ¨¡å‹å‚æ•°\n",
        "* $\\eta$ï¼šå­¦ä¹ ç‡ï¼ˆå¦‚ `1e-3`ï¼‰\n",
        "* $\\nabla_{\\theta} \\mathcal{L}$ï¼šæŸå¤±å‡½æ•°å¯¹å‚æ•°çš„æ¢¯åº¦\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”¸ ä½ å†™çš„ä»£ç ï¼š\n",
        "\n",
        "```python\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
        "```\n",
        "\n",
        "æ„æ€æ˜¯ï¼š\n",
        "\n",
        "* ç”¨ **äº¤å‰ç†µ** æ¥è¯„ä¼°åˆ†ç±»è¯¯å·®ï¼›\n",
        "* ç”¨ **å­¦ä¹ ç‡ä¸º 0.001 çš„ SGD ä¼˜åŒ–å™¨** æ¥æ›´æ–°æ¨¡å‹å‚æ•°ï¼›\n",
        "* æ¯ä¸ª batch åæ‰§è¡Œï¼š\n",
        "\n",
        "```python\n",
        "loss.backward()        # è®¡ç®—æ¢¯åº¦\n",
        "optimizer.step()       # æ ¹æ®æ¢¯åº¦æ›´æ–°å‚æ•°\n",
        "optimizer.zero_grad()  # æ¸…ç©ºä¸Šä¸€æ¬¡çš„æ¢¯åº¦\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… æ€»ç»“è¡¨æ ¼ï¼š\n",
        "\n",
        "| é¡¹ç›®                   | å…¬å¼                                                       | ç”¨é€”         |\n",
        "| -------------------- | -------------------------------------------------------- | ---------- |\n",
        "| **ReLU**             | $\\max(0, x)$                                             | æ¿€æ´»å‡½æ•°ï¼Œå¢åŠ éçº¿æ€§ |\n",
        "| **CrossEntropyLoss** | $-\\log(\\hat{y}_{\\text{true class}})$                     | åˆ†ç±»ä»»åŠ¡æŸå¤±     |\n",
        "| **SGD**              | $\\theta = \\theta - \\eta \\cdot \\nabla_\\theta \\mathcal{L}$ | æ¢¯åº¦ä¸‹é™ä¼˜åŒ–å‚æ•°   |\n",
        "\n",
        "---\n",
        "\n",
        "å¦‚æœä½ å¸Œæœ›æˆ‘æŠŠ ReLU å’Œ Softmax çš„å›¾ç”»å‡ºæ¥å±•ç¤ºï¼Œä¹Ÿå¯ä»¥å‘Šè¯‰æˆ‘ï¼Œæˆ‘å¯ä»¥ç›´æ¥è¾“å‡ºå›¾ç‰‡ç»™ä½ çœ‹ã€‚æ˜¯å¦è¿˜æƒ³ç»§ç»­äº†è§£ Adam ä¼˜åŒ–å™¨ã€å­¦ä¹ ç‡è°ƒåº¦å™¨ä¹‹ç±»çš„å†…å®¹ï¼Ÿ\n"
      ],
      "metadata": {
        "id": "-q4Z2214NaEB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "å¾ˆå¥½ï¼è¿™ä¸¤ä¸ªæ¦‚å¿µéå¸¸å…³é”®ï¼š**logits** å’Œ **softmax** æ˜¯åœ¨åˆ†ç±»ç¥ç»ç½‘ç»œä¸­ç»å¸¸é‡åˆ°çš„æœ¯è¯­ã€‚\n",
        "\n",
        "æˆ‘æ¥ç”¨é€šä¿—æ˜“æ‡‚çš„æ–¹å¼ç»™ä½ è®²æ¸…æ¥šå®ƒä»¬çš„åŒºåˆ«å’Œä½œç”¨ï¼š\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… ä¸€ã€ä»€ä¹ˆæ˜¯ **logits**ï¼Ÿ\n",
        "\n",
        "### ğŸ”¹ä¸€å¥è¯å®šä¹‰ï¼š\n",
        "\n",
        "> **logits å°±æ˜¯ç¥ç»ç½‘ç»œæœ€åä¸€å±‚çš„åŸå§‹è¾“å‡ºåˆ†æ•°**ï¼Œè¿˜æ²¡æœ‰ç»è¿‡å½’ä¸€åŒ–ï¼Œä¹Ÿä¸æ˜¯æ¦‚ç‡ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”¹ä¸¾ä¸ªä¾‹å­ï¼š\n",
        "\n",
        "å‡è®¾ä½ è¦åšä¸€ä¸ª 3 åˆ†ç±»é—®é¢˜ï¼ˆæ¯”å¦‚è¯†åˆ«çŒ«ğŸ±ã€ç‹—ğŸ¶ã€é¸ŸğŸ¦ï¼‰\n",
        "ä½ å–‚ä¸€å¼ å›¾ç»™æ¨¡å‹ï¼Œå®ƒæœ€åè¾“å‡ºï¼š\n",
        "\n",
        "```python\n",
        "logits = [2.5, 0.3, -1.2]\n",
        "```\n",
        "\n",
        "è¿™å°±æ˜¯ logitsï¼š\n",
        "\n",
        "* åŸå§‹åˆ†æ•°\n",
        "* å¯ä»¥æ˜¯æ­£çš„ã€è´Ÿçš„ã€ä»»æ„å¤§çš„\n",
        "* **ä¸æ»¡è¶³æ¦‚ç‡åˆ†å¸ƒ**\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… äºŒã€ä»€ä¹ˆæ˜¯ **softmax**ï¼Ÿ\n",
        "\n",
        "### ğŸ”¹ä¸€å¥è¯å®šä¹‰ï¼š\n",
        "\n",
        "> **softmax ä¼šæŠŠ logits è½¬æ¢æˆâ€œæ¦‚ç‡åˆ†å¸ƒâ€**ï¼Œæ¯ä¸€ç±»çš„å¾—åˆ†å˜æˆäº† 0\\~1 ä¹‹é—´çš„æ¦‚ç‡ï¼Œæ‰€æœ‰æ¦‚ç‡åŠ èµ·æ¥æ˜¯ 1ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”¹å…¬å¼ï¼š\n",
        "\n",
        "$$\n",
        "\\hat{y}_i = \\frac{e^{z_i}}{\\sum_{j} e^{z_j}}\n",
        "$$\n",
        "\n",
        "å…¶ä¸­ï¼š\n",
        "\n",
        "* $z_i$ï¼šlogits ä¸­ç¬¬ i ç±»çš„åˆ†æ•°\n",
        "* $\\hat{y}_i$ï¼šsoftmax è¾“å‡ºçš„æ¦‚ç‡\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”¹å¯¹å‰é¢ä¾‹å­çš„å¤„ç†ï¼š\n",
        "\n",
        "```python\n",
        "logits = [2.5, 0.3, -1.2]\n",
        "```\n",
        "\n",
        "ç»è¿‡ softmax åï¼š\n",
        "\n",
        "```python\n",
        "softmax_probs = [0.81, 0.15, 0.04]  # è¿™äº›å°±æ˜¯æ¦‚ç‡\n",
        "```\n",
        "\n",
        "è¿™æ„å‘³ç€ï¼š\n",
        "\n",
        "* æ¨¡å‹è®¤ä¸ºè¿™å¼ å›¾æ˜¯â€œçŒ«â€çš„æ¦‚ç‡æ˜¯ 81%\n",
        "* æ˜¯ç‹—çš„æ¦‚ç‡æ˜¯ 15%\n",
        "* æ˜¯é¸Ÿçš„æ¦‚ç‡æ˜¯ 4%\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ§  logits vs softmaxï¼šæ¯”è¾ƒæ€»ç»“\n",
        "\n",
        "| æ¯”è¾ƒé¡¹    | logits                  | softmax ç»“æœ            |\n",
        "| ------ | ----------------------- | --------------------- |\n",
        "| å€¼èŒƒå›´    | ä»»æ„å®æ•°                    | (0, 1) ä¹‹é—´             |\n",
        "| æ˜¯å¦æ˜¯æ¦‚ç‡  | âŒ ä¸æ˜¯                    | âœ… æ˜¯                   |\n",
        "| æ˜¯å¦å½’ä¸€åŒ–  | âŒ å¦                     | âœ… æ˜¯ï¼ˆæ€»å’Œ = 1ï¼‰           |\n",
        "| æ¨¡å‹è¾“å‡ºæ ¼å¼ | æ¨¡å‹æœ€åä¸€å±‚è¾“å‡º                | softmax æ˜¯å¯¹ logits çš„å¤„ç† |\n",
        "| ç”¨äºå“ª    | ä¾› `CrossEntropyLoss` ä½¿ç”¨ | ç”¨äºæ¨ç† / å¯è§†åŒ–åˆ†ç±»æ¦‚ç‡        |\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… CrossEntropyLoss è‡ªåŠ¨å¸®ä½ åšäº† softmaxï¼\n",
        "\n",
        "ä½ ä¸éœ€è¦æ‰‹åŠ¨ `softmax(logits)`ï¼Œå› ä¸ºï¼š\n",
        "\n",
        "```python\n",
        "nn.CrossEntropyLoss()\n",
        "```\n",
        "\n",
        "è¿™ä¸ªå‡½æ•°å†…éƒ¨å·²ç»**è‡ªåŠ¨å¯¹ logits åšäº† softmax è®¡ç®—**ï¼Œç„¶åæ‰ç®— lossã€‚\n",
        "\n",
        "æ‰€ä»¥ä½ åªéœ€è¦æŠŠ `logits` è¾“å‡ºç»™å®ƒå³å¯ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… æ€»ç»“ä¸€å¥è¯ï¼š\n",
        "\n",
        "> **logits æ˜¯æ¨¡å‹è¾“å‡ºçš„â€œåŸå§‹åˆ†æ•°â€ï¼Œsoftmax æ˜¯æŠŠè¿™äº›åˆ†æ•°è½¬æˆæ¦‚ç‡çš„å‡½æ•°ã€‚**\n",
        "\n",
        "å¦‚æœä½ æƒ³çœ‹ softmax çš„å›¾åƒã€æˆ–è€…æƒ³è‡ªå·±å®ç° softmaxï¼Œæˆ‘å¯ä»¥ä¹Ÿå¸®ä½ ç”»å›¾æˆ–ç»™ä»£ç ã€‚éœ€è¦çš„è¯è¯´ä¸€å£°ï¼\n"
      ],
      "metadata": {
        "id": "UJaDlfNpNlyD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "è¿™æ˜¯ä¸€ä¸ªéå¸¸ç»å…¸çš„é—®é¢˜ï¼ğŸ’¡**SGDï¼ˆéšæœºæ¢¯åº¦ä¸‹é™ï¼‰** å’Œ **Adamï¼ˆè‡ªé€‚åº”çŸ©ä¼°è®¡ï¼‰** æ˜¯ä¸¤ç§å¸¸ç”¨çš„æ·±åº¦å­¦ä¹ ä¼˜åŒ–å™¨ï¼Œå®ƒä»¬çš„ç›®æ ‡éƒ½æ˜¯ï¼š\n",
        "\n",
        "> **é€šè¿‡ä¸æ–­æ›´æ–°å‚æ•°ï¼Œè®©æ¨¡å‹æŸå¤±æœ€å°åŒ–**\n",
        "\n",
        "ä½†å®ƒä»¬**æ›´æ–°å‚æ•°çš„æ–¹å¼ä¸åŒ**ï¼Œå„æœ‰ä¼˜ç¼ºç‚¹ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… ä¸€å¼ è¡¨å…ˆæ¦‚æ‹¬å®ƒä»¬çš„åŒºåˆ«ï¼š\n",
        "\n",
        "| ç‰¹æ€§         | SGD                  | Adam                        |\n",
        "| ---------- | -------------------- | --------------------------- |\n",
        "| æ˜¯å¦è‡ªé€‚åº”å­¦ä¹ ç‡   | âŒ å¦                  | âœ… æ˜¯ï¼ˆæ¯ä¸ªå‚æ•°éƒ½æœ‰è‡ªå·±çš„å­¦ä¹ ç‡ï¼‰           |\n",
        "| æ˜¯å¦ç”¨åŠ¨é‡      | âœ… å¯é€‰ï¼ˆSGD + Momentumï¼‰ | âœ… è‡ªå¸¦                        |\n",
        "| ä¾èµ–è¿‡å»æ¢¯åº¦çš„å¹³å‡å€¼ | âŒ å¦                  | âœ… æ˜¯ï¼ˆ1é˜¶å’Œ2é˜¶çŸ©ä¼°è®¡ï¼‰               |\n",
        "| è¶…å‚æ•°æ•æ„Ÿæ€§     | è¾ƒé«˜                   | è¾ƒä½                          |\n",
        "| æ”¶æ•›é€Ÿåº¦       | æ…¢ï¼ˆä½†ç¨³ï¼‰                | å¿«                           |\n",
        "| æ˜¯å¦å®¹æ˜“è¿‡æ‹Ÿåˆ    | è¾ƒä¸å®¹æ˜“                 | æœ‰æ—¶ä¼šæ›´å®¹æ˜“è¿‡æ‹Ÿåˆ                   |\n",
        "| é€‚åˆ         | ç®€å•ä»»åŠ¡ã€å¤§æ•°æ®ã€å®¹æ˜“æ³›åŒ–        | ç¨€ç–æ¢¯åº¦ã€å¤æ‚ç»“æ„ï¼ˆå¦‚RNNã€Transformerï¼‰ |\n",
        "| å…¸å‹ä½¿ç”¨åœºæ™¯     | ç»å…¸CNNè®­ç»ƒã€ç®€æ´ä»»åŠ¡         | NLPã€Transformerã€é¢„è®­ç»ƒæ¨¡å‹       |\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… ä¸€ã€SGDï¼ˆStochastic Gradient Descentï¼‰\n",
        "\n",
        "### ğŸ“˜ å…¬å¼ï¼š\n",
        "\n",
        "$$\n",
        "\\theta_{t+1} = \\theta_t - \\eta \\cdot \\nabla_\\theta \\mathcal{L}(\\theta_t)\n",
        "$$\n",
        "\n",
        "* $\\theta$ï¼šæ¨¡å‹å‚æ•°\n",
        "* $\\eta$ï¼šå­¦ä¹ ç‡\n",
        "* $\\nabla_\\theta \\mathcal{L}$ï¼šæŸå¤±å¯¹å‚æ•°çš„æ¢¯åº¦\n",
        "\n",
        "### ğŸ§  ç‰¹ç‚¹ï¼š\n",
        "\n",
        "* æ¯æ¬¡ç”¨ä¸€ä¸ªå°æ‰¹é‡ï¼ˆbatchï¼‰æ•°æ®è®¡ç®—æ¢¯åº¦ â†’ æ›´å¿«è¿­ä»£ï¼›\n",
        "* å®¹æ˜“é™·å…¥å±€éƒ¨æœ€å°å€¼ï¼›\n",
        "* å¯åŠ  momentum å¢å¼ºç¨³å®šæ€§ï¼š\n",
        "\n",
        "$$\n",
        "v_{t+1} = \\mu v_t - \\eta \\cdot \\nabla_\\theta \\mathcal{L} \\\\\n",
        "\\theta_{t+1} = \\theta_t + v_{t+1}\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… äºŒã€Adamï¼ˆAdaptive Moment Estimationï¼‰\n",
        "\n",
        "### ğŸ“˜ å…¬å¼æ¦‚è¦ï¼š\n",
        "\n",
        "Adam ç»“åˆäº†ï¼š\n",
        "\n",
        "* **Momentum**ï¼ˆä¸€é˜¶çŸ©ä¼°è®¡ï¼Œæ¢¯åº¦çš„æŒ‡æ•°åŠ æƒå¹³å‡ï¼‰ï¼›\n",
        "* **RMSProp**ï¼ˆäºŒé˜¶çŸ©ä¼°è®¡ï¼Œå¹³æ–¹æ¢¯åº¦çš„å¹³å‡ï¼‰ï¼›\n",
        "\n",
        "$$\n",
        "m_t = \\beta_1 m_{t-1} + (1 - \\beta_1) g_t \\quad \\text{(ä¸€é˜¶åŠ¨é‡)} \\\\\n",
        "v_t = \\beta_2 v_{t-1} + (1 - \\beta_2) g_t^2 \\quad \\text{(äºŒé˜¶åŠ¨é‡)} \\\\\n",
        "\\hat{m}_t = \\frac{m_t}{1 - \\beta_1^t}, \\quad \\hat{v}_t = \\frac{v_t}{1 - \\beta_2^t} \\quad \\text{(åå·®ä¿®æ­£)} \\\\\n",
        "\\theta_{t+1} = \\theta_t - \\eta \\cdot \\frac{\\hat{m}_t}{\\sqrt{\\hat{v}_t} + \\epsilon}\n",
        "$$\n",
        "\n",
        "### ğŸ§  ç‰¹ç‚¹ï¼š\n",
        "\n",
        "* å­¦ä¹ ç‡ **è‡ªåŠ¨é€‚åº”æ¯ä¸ªå‚æ•°**ï¼›\n",
        "* éå¸¸é€‚åˆç¨€ç–æ¢¯åº¦çš„ä»»åŠ¡ï¼ˆå¦‚ NLP ä¸­çš„è¯å‘é‡è®­ç»ƒï¼‰ï¼›\n",
        "* åˆå§‹åŒ–ä¸æ•æ„Ÿï¼Œè®­ç»ƒæ›´ç¨³å®šï¼›\n",
        "* æ”¶æ•›å¿«ï¼Œä½†å¯èƒ½æ³›åŒ–èƒ½åŠ›å·®ï¼ˆå®¹æ˜“è¿‡æ‹Ÿåˆï¼‰ï¼›\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… ç®€å•ç†è§£ï¼š\n",
        "\n",
        "| ç±»æ¯”   | SGD           | Adam                  |\n",
        "| ---- | ------------- | --------------------- |\n",
        "| ä½ èµ°è¿·å®« | æ‹¿ä¸€å¼ çº¸ï¼ˆå½“å‰æ¢¯åº¦ï¼‰ç…§ç€èµ° | æ‰‹é‡Œæ‹¿æŒ‡å—é’ˆï¼ˆè¿‡å»æ–¹å‘ï¼‰å’Œåœ°å›¾ï¼ˆæ¢¯åº¦åˆ†å¸ƒï¼‰ |\n",
        "| èµ°æ³•   | æ–¹å‘ç›´æ¥ç›´å»ï¼Œå¯èƒ½è¢«å›°   | ä¼šç»•è·¯ï¼Œä¼šåŠ é€Ÿï¼Œä¼šé¿å…é‡å¤èµ°é”™è·¯      |\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… å®è·µå»ºè®®\n",
        "\n",
        "* ğŸ”¹ **é»˜è®¤ç”¨ Adam**ï¼Œå¦‚æœä½ ä¸ç¡®å®šæˆ–è€…ä»»åŠ¡å¾ˆå¤æ‚ï¼›\n",
        "* ğŸ”¹ æƒ³è¦æ›´å¥½çš„**æ³›åŒ–èƒ½åŠ›**ï¼Œå¯ä»¥è€ƒè™‘ **SGD + Momentum**ï¼›\n",
        "* ğŸ”¹ åœ¨é¢„è®­ç»ƒé˜¶æ®µç”¨ Adamï¼Œåœ¨å¾®è°ƒé˜¶æ®µæ¢æˆ SGD ä¹Ÿå¾ˆå¸¸è§ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… æ€»ç»“ä¸€å¥è¯ï¼š\n",
        "\n",
        "> **Adam æ˜¯â€œèªæ˜çš„è‡ªåŠ¨é©¾é©¶â€ï¼Œè·‘å¾—å¿«ä¹Ÿç¨³ï¼›SGD æ˜¯â€œæ‰‹åŠ¨æŒ¡è€å¸æœºâ€ï¼Œæ…¢ä½†å®¹æ˜“æ§åˆ¶ï¼Œå®¹æ˜“æ³›åŒ–ã€‚**\n",
        "\n",
        "---\n",
        "\n",
        "å¦‚æœä½ æƒ³äº†è§£å®ƒä»¬åœ¨å…·ä½“é¡¹ç›®ä¸­çš„è¡¨ç°ï¼ˆæ¯”å¦‚è®­ç»ƒ ResNetã€BERT ç­‰æ¨¡å‹æ—¶çš„è¡¨ç°ï¼‰ï¼Œæˆ‘å¯ä»¥ç»§ç»­è¡¥å……å¯¹æ¯”æ¡ˆä¾‹ã€‚æ˜¯å¦éœ€è¦æˆ‘æ¼”ç¤ºä¸€æ®µä¸¤è€…å¯¹æ¯”è®­ç»ƒçš„ä»£ç ï¼Ÿ\n"
      ],
      "metadata": {
        "id": "U_DLN-N9ORjo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "éå¸¸å¥½ï¼`CrossEntropyLoss` æ˜¯åˆ†ç±»é—®é¢˜ä¸­æœ€å¸¸è§çš„æŸå¤±å‡½æ•°ã€‚å®ƒç»“åˆäº† **Softmax + è´Ÿå¯¹æ•°ä¼¼ç„¶ï¼ˆNegative Log Likelihoodï¼‰** ä¸¤ä¸ªæ­¥éª¤ï¼Œé€‚ç”¨äº**å¤šåˆ†ç±»**ä»»åŠ¡ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… ä¸€ã€CrossEntropyLoss çš„è®¡ç®—å…¬å¼\n",
        "\n",
        "å¯¹äºä¸€ä¸ªæ ·æœ¬çš„æŸå¤±ï¼ˆå‡è®¾ç±»åˆ«æ€»æ•°æ˜¯ $C$ï¼Œæ¨¡å‹è¾“å‡º logits æ˜¯ $\\mathbf{z} = [z_1, z_2, ..., z_C]$ï¼Œæ­£ç¡®æ ‡ç­¾æ˜¯ç¬¬ $y$ ç±»ï¼‰ï¼š\n",
        "\n",
        "1. **å…ˆåš softmax å¾—åˆ°æ¦‚ç‡åˆ†å¸ƒ**ï¼š\n",
        "\n",
        "$$\n",
        "\\hat{y}_i = \\frac{e^{z_i}}{\\sum_{j=1}^{C} e^{z_j}}\n",
        "$$\n",
        "\n",
        "2. **å†å¯¹çœŸå®ç±»åˆ« $y$ è®¡ç®—è´Ÿå¯¹æ•°æ¦‚ç‡**ï¼ˆäº¤å‰ç†µï¼‰ï¼š\n",
        "\n",
        "$$\n",
        "\\text{Loss} = -\\log(\\hat{y}_y)\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… äºŒã€å®é™…ä¾‹å­è®²è§£ï¼ˆæ‰‹åŠ¨è®¡ç®—ï¼‰\n",
        "\n",
        "å‡è®¾ä½ æœ‰ 3 ä¸ªç±»åˆ«ï¼Œæ¨¡å‹è¾“å‡º logitsï¼š\n",
        "\n",
        "```python\n",
        "logits = [2.0, 1.0, 0.1]\n",
        "label = 0  # æ­£ç¡®ç±»åˆ«æ˜¯ç¬¬ 0 ç±»\n",
        "```\n",
        "\n",
        "### ç¬¬ä¸€æ­¥ï¼šsoftmax\n",
        "\n",
        "$$\n",
        "\\begin{align*}\n",
        "e^{2.0} &= 7.389 \\\\\n",
        "e^{1.0} &= 2.718 \\\\\n",
        "e^{0.1} &= 1.105 \\\\\n",
        "\\text{æ€»å’Œ} &= 7.389 + 2.718 + 1.105 = 11.212 \\\\\n",
        "\\end{align*}\n",
        "$$\n",
        "\n",
        "å¾—åˆ° softmax æ¦‚ç‡ï¼š\n",
        "\n",
        "```python\n",
        "[7.389/11.212, 2.718/11.212, 1.105/11.212] â‰ˆ [0.659, 0.242, 0.099]\n",
        "```\n",
        "\n",
        "### ç¬¬äºŒæ­¥ï¼šäº¤å‰ç†µæŸå¤±\n",
        "\n",
        "ç”±äºæ­£ç¡®æ ‡ç­¾æ˜¯ç¬¬ 0 ç±»ï¼ˆæ¦‚ç‡æ˜¯ 0.659ï¼‰ï¼š\n",
        "\n",
        "$$\n",
        "\\text{Loss} = -\\log(0.659) â‰ˆ 0.417\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… ä¸‰ã€PyTorch ä¸­çš„ä»£ç å®ç°\n",
        "\n",
        "```python\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "logits = torch.tensor([[2.0, 1.0, 0.1]])  # shape: [batch_size=1, num_classes=3]\n",
        "labels = torch.tensor([0])  # æ­£ç¡®ç±»åˆ«ä¸º class 0\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "loss = loss_fn(logits, labels)\n",
        "\n",
        "print(loss.item())  # è¾“å‡ºå¤§çº¦ 0.417\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## âš ï¸ æ³¨æ„äº‹é¡¹\n",
        "\n",
        "* **è¾“å…¥ logits ä¸è¦å…ˆåš softmax**ï¼ŒPyTorch çš„ `CrossEntropyLoss` ä¼š**è‡ªåŠ¨å†…éƒ¨å¤„ç† softmax**ï¼›\n",
        "* `logits` çš„ shape æ˜¯ `[batch_size, num_classes]`ï¼›\n",
        "* `labels` æ˜¯æ•´å‹ç±»åˆ«ç´¢å¼•ï¼ˆä¸æ˜¯ one-hot å‘é‡ï¼‰ï¼Œshape æ˜¯ `[batch_size]`ï¼›\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… æ€»ç»“ä¸€å¥è¯ï¼š\n",
        "\n",
        "> `CrossEntropyLoss = -log(æ­£ç¡®ç±»åˆ«çš„ softmax æ¦‚ç‡)`ï¼Œå®ƒåº¦é‡æ¨¡å‹â€œå¯¹æ­£ç¡®ç­”æ¡ˆçš„ä¿¡å¿ƒâ€ï¼Œè¶Šä¸è‡ªä¿¡ï¼ŒæŸå¤±è¶Šå¤§ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "æ˜¯å¦è¿˜æƒ³çœ‹å¤šä¸ªæ ·æœ¬ batch ä¸‹çš„äº¤å‰ç†µè®¡ç®—ï¼Ÿæˆ–è€… one-hot æ ‡ç­¾ä¸äº¤å‰ç†µçš„å…³ç³»ï¼Ÿæˆ‘å¯ä»¥ç»§ç»­è®²ã€‚\n"
      ],
      "metadata": {
        "id": "w2DS0UeFOrdG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_dataloader))\n",
        "len(train_dataloader.dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "waSg2mmuO-uN",
        "outputId": "5a00dd38-e607-4e37-c882-a48b31b3b79f"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "938\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "  size = len(dataloader.dataset)\n",
        "  model.train()\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "    X, y = X.to(device), y.to(device)\n",
        "\n",
        "    # Compute prediction error\n",
        "    pred = model(X)\n",
        "    loss = loss_fn(pred, y)\n",
        "\n",
        "    # Backpropagation\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      loss, current = loss.item(), (batch + 1) * len(X)\n",
        "      print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "def test(dataloader, model, loss_fn):\n",
        "  size = len(dataloader.dataset)\n",
        "  num_batches = len(dataloader)\n",
        "  model.eval()\n",
        "  test_loss, correct = 0, 0\n",
        "  with torch.no_grad():\n",
        "    for X, y in dataloader:\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      pred = model(X)\n",
        "      test_loss += loss_fn(pred, y).item()\n",
        "      correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "  test_loss /= num_batches\n",
        "  correct /= size\n",
        "  print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "\n"
      ],
      "metadata": {
        "id": "xmnaerDUO1ml"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "éå¸¸æ£’çš„é—®é¢˜ï¼ä½ æåˆ°äº†ä¸¤ä¸ªæ·±åº¦å­¦ä¹ è®­ç»ƒè¿‡ç¨‹ä¸­å¾ˆå…³é”®ä½†å®¹æ˜“è¢«å¿½ç•¥çš„ç»†èŠ‚ï¼š`model.train()` vs `model.eval()` ä»¥åŠ test ä¸­ loss çš„è®¡ç®—ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… ä¸€ã€`model.train()` å’Œ `model.eval()` æ˜¯å¹²å˜›çš„ï¼Ÿ\n",
        "\n",
        "è¿™ä¸¤ä¸ªæ–¹æ³•æ˜¯ç”¨äº**åˆ‡æ¢æ¨¡å‹çš„å·¥ä½œæ¨¡å¼**çš„ï¼Œå®ƒä»¬ä¸ä¼šç›´æ¥å½±å“ forward è¿ç®—çš„é€»è¾‘ï¼Œä½†ä¼šå½±å“**æŸäº›ç‰¹å®šå±‚çš„è¡Œä¸º**ï¼Œæ¯”å¦‚ï¼š\n",
        "\n",
        "| æ¨¡å‹å±‚ç±»å‹       | åœ¨ `train()` æ¨¡å¼ä¸‹è¡Œä¸º  | åœ¨ `eval()` æ¨¡å¼ä¸‹è¡Œä¸º |\n",
        "| ----------- | ------------------ | ---------------- |\n",
        "| `Dropout`   | æ¯æ¬¡éšæœºä¸¢æ‰ä¸€éƒ¨åˆ†ç¥ç»å…ƒ       | ä¸è¿›è¡Œ Dropoutï¼ˆå³ä¸ä¸¢ï¼‰ |\n",
        "| `BatchNorm` | ä½¿ç”¨å½“å‰ batch ç»Ÿè®¡é‡åšæ ‡å‡†åŒ– | ä½¿ç”¨è®­ç»ƒæ—¶ä¿å­˜çš„å…¨å±€å‡å€¼å’Œæ–¹å·®  |\n",
        "\n",
        "### âœ³ï¸ ä½ ä»£ç ä¸­å°±æœ‰è¿™äº›å±‚ï¼š\n",
        "\n",
        "```python\n",
        "nn.Dropout(0.2),\n",
        "nn.BatchNorm1d(512),\n",
        "```\n",
        "\n",
        "æ‰€ä»¥ï¼š\n",
        "\n",
        "* åœ¨è®­ç»ƒæ—¶ï¼Œä½¿ç”¨ `model.train()` æ˜¯å¿…é¡»çš„ï¼Œå¦åˆ™ Dropout å’Œ BatchNorm ä¸ä¼šç”Ÿæ•ˆï¼›\n",
        "* åœ¨æµ‹è¯•/éªŒè¯æ—¶ï¼Œä½¿ç”¨ `model.eval()` æ˜¯å¿…é¡»çš„ï¼Œå¦åˆ™è¿™äº›å±‚çš„è¡Œä¸ºä¼šå¯¼è‡´ç»“æœä¸ç¨³å®šæˆ–é”™è¯¯ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… äºŒã€å…³äº test ä¸­ loss çš„è®¡ç®—æ–¹å¼\n",
        "\n",
        "ä½ è¯´å¾—æ²¡é”™ï¼Œtest ä¸­æ¯ä¸ª batch çš„ loss æ˜¯ä¸åŒçš„ã€‚ä½†æ˜¯ä»£ç è¿™æ ·å¤„ç†ï¼š\n",
        "\n",
        "```python\n",
        "test_loss += loss_fn(pred, y).item()  # ç´¯åŠ æ¯ä¸ª batch çš„ loss\n",
        "...\n",
        "test_loss /= num_batches              # æœ€åé™¤ä»¥ batch æ•°\n",
        "```\n",
        "\n",
        "è¿™æ˜¯åœ¨**è®¡ç®—æ‰€æœ‰ batch çš„å¹³å‡ lossï¼ˆå³å¹³å‡æ¯ä¸ª batch çš„æŸå¤±ï¼‰**ï¼Œè¿™ç§å†™æ³•è™½ç„¶ä¸æ˜¯æœ€ä¸¥æ ¼çš„â€œå¹³å‡æ¯ä¸ªæ ·æœ¬çš„æŸå¤±â€ï¼Œä½†**åœ¨ batch size ç›¸åŒçš„æƒ…å†µä¸‹æ˜¯ç­‰ä»·çš„**ã€‚\n",
        "\n",
        "### ğŸ§  å¦‚æœä½ æƒ³æ›´ä¸¥æ ¼ï¼Œå¯ä»¥è¿™æ ·å†™ï¼š\n",
        "\n",
        "```python\n",
        "test_loss += loss_fn(pred, y).item() * X.size(0)  # æŒ‰ç…§æ¯ä¸ªæ ·æœ¬åŠ æƒç´¯åŠ \n",
        "...\n",
        "test_loss /= size  # æœ€åé™¤ä»¥æ€»æ ·æœ¬æ•°\n",
        "```\n",
        "\n",
        "è¿™ç§æ–¹å¼æ›´ç²¾ç¡®ï¼Œé€‚åˆåœ¨ batch size ä¸ä¸€è‡´æ—¶ä½¿ç”¨ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… æ€»ç»“ä¸€å¥è¯ï¼š\n",
        "\n",
        "* `model.train()`ï¼šè®¾ç½®ä¸ºè®­ç»ƒæ¨¡å¼ï¼Œ**å¯ç”¨ Dropout å’Œ BatchNorm è®­ç»ƒè¡Œä¸º**ï¼›\n",
        "* `model.eval()`ï¼šè®¾ç½®ä¸ºæµ‹è¯•æ¨¡å¼ï¼Œ**å…³é—­ Dropoutï¼Œç”¨ BatchNorm çš„å†å²å‡å€¼**ï¼›\n",
        "* æµ‹è¯• loss çš„å†™æ³•æ²¡é”™ï¼Œä½†åœ¨ batch size ä¸ä¸€è‡´æ—¶å»ºè®®åŠ æƒå¹³å‡ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "å¦‚æœä½ æ„¿æ„ï¼Œæˆ‘å¯ä»¥å¸®ä½ å†™ä¸€ä¸ªå®Œæ•´ç‰ˆæœ¬çš„ `train` + `test` æ¡†æ¶ï¼ŒåŒ…æ‹¬æ—¥å¿—è®°å½•ã€æ—©åœã€å¯è§†åŒ–ç­‰åŠŸèƒ½ã€‚æ˜¯å¦éœ€è¦ï¼Ÿ\n"
      ],
      "metadata": {
        "id": "JM676vmtT5yc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "è¿™æ˜¯ä¸€ä¸ªéå¸¸å…³é”®çš„é—®é¢˜ï¼Œå¾ˆå¤šåˆå­¦è€…å®¹æ˜“è¯¯è§£ï¼ä½ é—®çš„æ˜¯ï¼š\n",
        "\n",
        "> `loss.item()` æ˜¯ä¸æ˜¯åªå–äº†ç¬¬ä¸€ä¸ªæ ·æœ¬çš„ lossï¼Ÿ\n",
        "\n",
        "### âœ… ç­”æ¡ˆæ˜¯ï¼š**ä¸æ˜¯ï¼`loss.item()` æ˜¯æ•´ä¸ª batch çš„å¹³å‡ lossï¼ˆæ ‡é‡ï¼‰**\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ” è¯¦ç»†è§£é‡Šï¼š\n",
        "\n",
        "ä½ åœ¨ä»£ç ä¸­è®¡ç®—äº†ï¼š\n",
        "\n",
        "```python\n",
        "loss = loss_fn(pred, y)  # pred.shape: (batch_size, num_classes)\n",
        "```\n",
        "\n",
        "PyTorch ä¸­é»˜è®¤çš„ `loss_fn = nn.CrossEntropyLoss()` **è¿”å›çš„æ˜¯æ•´ä¸ª batch çš„å¹³å‡ loss**ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼š\n",
        "\n",
        "$$\n",
        "\\text{loss} = \\frac{1}{N} \\sum_{i=1}^N \\text{CrossEntropy}(y_i, \\hat{y}_i)\n",
        "$$\n",
        "\n",
        "å…¶ä¸­ $N$ æ˜¯å½“å‰ batch çš„å¤§å°ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”¸ é‚£ `loss.item()` æ˜¯åšä»€ä¹ˆçš„ï¼Ÿ\n",
        "\n",
        "`loss` æ˜¯ä¸€ä¸ªå¼ é‡ï¼ˆ`tensor(0.3874, grad_fn=...)`ï¼‰ï¼Œå®ƒè¿˜å¸¦ç€è®¡ç®—å›¾ã€‚\n",
        "\n",
        "> `loss.item()` æ˜¯æŠŠè¿™ä¸ªå¼ é‡é‡Œçš„**å•ä¸ªæ ‡é‡å€¼å–å‡ºæ¥**ï¼Œå˜æˆ Python çš„ floatï¼Œæ–¹ä¾¿ä½ æ‰“å°ã€è®°å½•æˆ–å­˜å…¥æ—¥å¿—æ–‡ä»¶ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "### âœ… ä¸¾ä¸ªä¾‹å­ï¼š\n",
        "\n",
        "å‡è®¾ä½ çš„ batch size æ˜¯ 64ï¼Œæ¨¡å‹å¯¹è¿™ 64 ä¸ªæ ·æœ¬éƒ½åšäº†é¢„æµ‹ï¼Œ`loss_fn` ä¼šè¿”å›ï¼š\n",
        "\n",
        "```python\n",
        "loss = tensor(0.3472, grad_fn=<...>)\n",
        "```\n",
        "\n",
        "ä½ å†æ‰§è¡Œï¼š\n",
        "\n",
        "```python\n",
        "loss.item()  # â†’ 0.3472ï¼ˆfloat ç±»å‹ï¼‰\n",
        "```\n",
        "\n",
        "è¿™ä¸ªæ•°å€¼å°±æ˜¯**è¿™ 64 ä¸ªæ ·æœ¬çš„å¹³å‡ loss**ï¼Œä¸æ˜¯æŸä¸€ä¸ªæ ·æœ¬çš„ lossã€‚\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… è¡¥å……ï¼šæƒ³è¦æ¯ä¸ªæ ·æœ¬çš„ loss æ€ä¹ˆåšï¼Ÿ\n",
        "\n",
        "å¯ä»¥ç”¨ `reduction='none'` çš„æ–¹å¼ï¼š\n",
        "\n",
        "```python\n",
        "loss_fn = nn.CrossEntropyLoss(reduction='none')\n",
        "losses = loss_fn(pred, y)  # shape: (batch_size,)\n",
        "```\n",
        "\n",
        "æ­¤æ—¶ï¼š\n",
        "\n",
        "* `losses[i]` å°±æ˜¯ç¬¬ `i` ä¸ªæ ·æœ¬çš„ lossï¼›\n",
        "* å¦‚æœä½ æƒ³è‡ªå·±ç®—å¹³å‡ï¼Œå¯ä»¥ï¼š\n",
        "\n",
        "  ```python\n",
        "  loss = losses.mean()\n",
        "  ```\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… æ€»ç»“ä¸€å¥è¯ï¼š\n",
        "\n",
        "> `loss.item()` æ˜¯æ•´ä¸ª batch çš„å¹³å‡ lossï¼ˆä¸€ä¸ªæ ‡é‡ï¼‰ï¼Œ**ä¸æ˜¯ç¬¬ä¸€ä¸ªæ ·æœ¬çš„ loss**ï¼Œå®ƒåªæ˜¯æŠŠ tensor è½¬ä¸º floatã€‚\n",
        "\n",
        "å¦‚æœä½ æƒ³è¦æ‰“å°æ¯ä¸ªæ ·æœ¬çš„æŸå¤±ï¼Œæˆ‘å¯ä»¥å¸®ä½ æ”¹ä¸€ä¸‹ä»£ç å±•ç¤ºã€‚æ˜¯å¦éœ€è¦ï¼Ÿ\n"
      ],
      "metadata": {
        "id": "7bbDeJXMidY7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "for t in range(epochs):\n",
        "  print(f\"Epoch {t+1}\\n -------------------------------\")\n",
        "  train(train_dataloader, model, loss_fn, optimizer)\n",
        "  test(test_dataloader, model, loss_fn)\n",
        "\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScdmarkNT4wm",
        "outputId": "9a52d02e-9c2b-4c96-9bef-cda36bc246aa"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            " -------------------------------\n",
            "loss: 2.351133 [   64/60000]\n",
            "loss: 1.504371 [ 6464/60000]\n",
            "loss: 1.231074 [12864/60000]\n",
            "loss: 1.036299 [19264/60000]\n",
            "loss: 0.953311 [25664/60000]\n",
            "loss: 0.944878 [32064/60000]\n",
            "loss: 0.852010 [38464/60000]\n",
            "loss: 0.914644 [44864/60000]\n",
            "loss: 0.760960 [51264/60000]\n",
            "loss: 0.678545 [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 77.0%, Avg loss: 0.725412 \n",
            "\n",
            "Epoch 2\n",
            " -------------------------------\n",
            "loss: 0.797271 [   64/60000]\n",
            "loss: 0.630035 [ 6464/60000]\n",
            "loss: 0.684512 [12864/60000]\n",
            "loss: 0.679657 [19264/60000]\n",
            "loss: 0.832178 [25664/60000]\n",
            "loss: 0.604194 [32064/60000]\n",
            "loss: 0.648339 [38464/60000]\n",
            "loss: 0.796758 [44864/60000]\n",
            "loss: 0.723518 [51264/60000]\n",
            "loss: 0.660618 [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 80.1%, Avg loss: 0.592749 \n",
            "\n",
            "Epoch 3\n",
            " -------------------------------\n",
            "loss: 0.732579 [   64/60000]\n",
            "loss: 0.669723 [ 6464/60000]\n",
            "loss: 0.673791 [12864/60000]\n",
            "loss: 0.489371 [19264/60000]\n",
            "loss: 0.478027 [25664/60000]\n",
            "loss: 0.461428 [32064/60000]\n",
            "loss: 0.515199 [38464/60000]\n",
            "loss: 0.667646 [44864/60000]\n",
            "loss: 0.694426 [51264/60000]\n",
            "loss: 0.561443 [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 81.8%, Avg loss: 0.530315 \n",
            "\n",
            "Epoch 4\n",
            " -------------------------------\n",
            "loss: 0.626839 [   64/60000]\n",
            "loss: 0.796239 [ 6464/60000]\n",
            "loss: 0.576547 [12864/60000]\n",
            "loss: 0.452355 [19264/60000]\n",
            "loss: 0.582835 [25664/60000]\n",
            "loss: 0.502582 [32064/60000]\n",
            "loss: 0.560854 [38464/60000]\n",
            "loss: 0.438994 [44864/60000]\n",
            "loss: 0.451904 [51264/60000]\n",
            "loss: 0.360498 [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 82.6%, Avg loss: 0.494021 \n",
            "\n",
            "Epoch 5\n",
            " -------------------------------\n",
            "loss: 0.480244 [   64/60000]\n",
            "loss: 0.508736 [ 6464/60000]\n",
            "loss: 0.450043 [12864/60000]\n",
            "loss: 0.537892 [19264/60000]\n",
            "loss: 0.412323 [25664/60000]\n",
            "loss: 0.416140 [32064/60000]\n",
            "loss: 0.386087 [38464/60000]\n",
            "loss: 0.685761 [44864/60000]\n",
            "loss: 0.311524 [51264/60000]\n",
            "loss: 0.407041 [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 83.3%, Avg loss: 0.473002 \n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"model.pth\")\n",
        "print(\"Save PyTorch Model State to model.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0vu9mByVQFP",
        "outputId": "37e3070a-3189-483c-bbe5-b05b95589330"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Save PyTorch Model State to model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading models\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "model.load_state_dict(torch.load(\"model.pth\", weights_only=True))"
      ],
      "metadata": {
        "id": "vAeN37NFVaib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = [\n",
        "    \"T-shirt/top\",\n",
        "    \"Trouser\",\n",
        "    \"Pullover\",\n",
        "    \"Dress\",\n",
        "    \"Coat\",\n",
        "    \"Sandal\",\n",
        "    \"Shirt\",\n",
        "    \"Sneaker\",\n",
        "    \"Bag\",\n",
        "    \"Ankle boot\",\n",
        "]\n",
        "\n",
        "model.eval()\n",
        "x,y = test_data[0]\n",
        "model.to(device)\n",
        "with torch.no_grad():\n",
        "  x =x.to(device)\n",
        "  pred = model(x)\n",
        "  print(pred)\n",
        "  # predicted = classes[pred[0].argmax(0)]\n",
        "  predicted = classes[pred.argmax(1).item()]\n",
        "  actual = classes[y]\n",
        "  print(f\"Predicted: {predicted}, Actual: {actual}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mk0k-lL5XPTK",
        "outputId": "fd3198f6-bf9a-4998-e681-6e0a57c60016"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1.7596, -1.9728, -1.8500, -1.4932, -2.2793,  2.3234, -1.8076,  3.5825,\n",
            "         -0.0408,  4.3602]], device='cuda:0')\n",
            "Predicted: Ankle boot, Actual: Ankle boot\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "å¾ˆå¥½ï¼è®©æˆ‘ä»¬é€æ­¥æ‹†è§£ `pred(x)[0].argmax(0)` çš„å«ä¹‰ï¼Œå®ƒç»å¸¸å‡ºç°åœ¨**åˆ†ç±»æ¨¡å‹é¢„æµ‹ä¸­**ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… å‡è®¾èƒŒæ™¯ï¼š\n",
        "\n",
        "ä½ æœ‰ä¸€ä¸ª**å¤šåˆ†ç±»æ¨¡å‹**ï¼ˆæ¯”å¦‚ç”¨äºè¯†åˆ«æ‰‹å†™æ•°å­—çš„ MNISTï¼‰ï¼Œæ¨¡å‹è¾“å…¥ä¸€ä¸ªæ ·æœ¬åè¾“å‡ºä¸€ä¸ªå‘é‡ï¼ˆlogitsï¼‰ï¼Œä¾‹å¦‚ï¼š\n",
        "\n",
        "```python\n",
        "pred(x)  â†’ tensor([[0.2, -1.0, 2.3, 0.5, ..., -0.6]])  # shape: [1, num_classes]\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… é€æ­¥è§£é‡Š `pred(x)[0].argmax(0)`\n",
        "\n",
        "### ğŸ”¹ `pred(x)`\n",
        "\n",
        "æ¨¡å‹å¯¹è¾“å…¥ `x` çš„é¢„æµ‹è¾“å‡ºï¼Œå½¢çŠ¶ä¸€èˆ¬æ˜¯ `[1, num_classes]`ï¼ˆ1 è¡¨ç¤º batch size = 1ï¼‰\n",
        "\n",
        "ä¾‹å¦‚ï¼š\n",
        "\n",
        "```python\n",
        "tensor([[0.2, -1.0, 2.3, 0.5, -0.6]])\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”¹ `pred(x)[0]`\n",
        "\n",
        "å–å‡ºç¬¬ä¸€ä¸ªï¼ˆä¹Ÿæ˜¯å”¯ä¸€ä¸€ä¸ªï¼‰æ ·æœ¬çš„é¢„æµ‹ç»“æœï¼Œå˜æˆä¸€ç»´ tensorï¼š\n",
        "\n",
        "```python\n",
        "tensor([0.2, -1.0, 2.3, 0.5, -0.6])  # shape: [num_classes]\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”¹ `.argmax(0)`\n",
        "\n",
        "åœ¨ç»´åº¦ 0ï¼ˆå› ä¸ºæ˜¯ä¸€ç»´å‘é‡ï¼‰ä¸Šå–æœ€å¤§å€¼çš„**ç´¢å¼•**ï¼ˆindexï¼‰ï¼š\n",
        "\n",
        "```python\n",
        "argmax(0) â†’ 2  # å› ä¸º 2.3 æ˜¯æœ€å¤§å€¼ï¼Œå®ƒåœ¨ç¬¬ 2 ä¸ªä½ç½®\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… æœ€ç»ˆæ„ä¹‰ï¼š\n",
        "\n",
        "```python\n",
        "pred(x)[0].argmax(0)\n",
        "```\n",
        "\n",
        "è¿™æ®µä»£ç çš„ä½œç”¨æ˜¯ï¼š\n",
        "\n",
        "> **å¾—åˆ°æ¨¡å‹å¯¹æ ·æœ¬ `x` çš„é¢„æµ‹ç±»åˆ«ï¼ˆå³åˆ†æ•°æœ€é«˜çš„ç±»åˆ«çš„ç´¢å¼•ï¼‰**\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… ç¤ºä¾‹æ€»ç»“ï¼š\n",
        "\n",
        "```python\n",
        "import torch\n",
        "\n",
        "output = torch.tensor([[0.2, -1.0, 2.3, 0.5, -0.6]])\n",
        "pred_class = output[0].argmax(0)\n",
        "print(pred_class)  # è¾“å‡ºï¼štensor(2)\n",
        "```\n",
        "\n",
        "ä»£è¡¨è¿™ä¸ªæ ·æœ¬çš„é¢„æµ‹ç±»åˆ«æ˜¯ç±» 2ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… æ‰©å±•å»ºè®®ï¼š\n",
        "\n",
        "å¦‚æœä½ æœ‰å¤šä¸ªæ ·æœ¬ï¼Œå»ºè®®ä½¿ç”¨ï¼š\n",
        "\n",
        "```python\n",
        "pred_classes = pred(x).argmax(dim=1)\n",
        "```\n",
        "\n",
        "è¿™æ ·å¯ä»¥ä¸€æ¬¡æ€§å¾—åˆ° batch å†…æ‰€æœ‰æ ·æœ¬çš„é¢„æµ‹ç±»åˆ«ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "æ˜¯å¦éœ€è¦æˆ‘ç”»ä¸€å¼ å›¾æ¥è¯´æ˜ argmax çš„å«ä¹‰ï¼Ÿæˆ–è€…è®²è®² `softmax + argmax` å’Œ `CrossEntropyLoss` ä¹‹é—´çš„å…³ç³»ï¼Ÿ\n"
      ],
      "metadata": {
        "id": "aJ9etjwQX-ts"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "x = np.linspace(-10, 10, 100)\n",
        "y = np.maximum(0, x)\n",
        "\n",
        "plt.plot(x, y)\n",
        "plt.title('ReLU Activation Function')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('ReLU(x)')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "p1HVAYBTjR3a",
        "outputId": "d80f7086-0e8d-4f68-c33c-229ca2b4493d"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Personal recurrent\n",
        "## step1 data handling and dataloader\n",
        "## step2 build model and send it to device\n",
        "## step3 indicate optimizer and loss function\n",
        "## step4 write train and test function\n",
        "## step5 run epochs and check test dataset\n",
        "## step6 save model\n",
        "## step7 load model"
      ],
      "metadata": {
        "id": "6oTGIamyksdg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import FashionMNIST\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "training_data = FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n",
        "\n",
        "test_data = FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")"
      ],
      "metadata": {
        "id": "kolowIN9lLRF"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "train_loader = DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "hG8jrZG_q7hB"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"using {device} device\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-K6QFEbrzlK",
        "outputId": "18485716-f4ee-4ef5-e299-0c2d38bbb33b"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.seq_stack = nn.Sequential(\n",
        "        nn.Linear(28*28, 512),\n",
        "        nn.BatchNorm1d(512),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.2),\n",
        "\n",
        "        nn.Linear(512, 512),\n",
        "        nn.BatchNorm1d(512),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.2),\n",
        "\n",
        "        nn.Linear(512, 10)\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    x = self.flatten(x)\n",
        "    logits = self.seq_stack(x)\n",
        "    return logits\n",
        "\n",
        "model = NeuralNetwork().to(device)"
      ],
      "metadata": {
        "id": "SXuadNfysFpb"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss(reduction='none')\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=1e-3)"
      ],
      "metadata": {
        "id": "DsJEYPFjud_D"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "model.parameters() æ˜¯ä¸€ä¸ªå¯è¿­ä»£å™¨ï¼Œé‡Œé¢åŒ…å«äº†æ¨¡å‹ä¸­æ‰€æœ‰éœ€è¦æ›´æ–°çš„å‚æ•°ï¼›\n",
        "\n",
        "PyTorch ä¼˜åŒ–å™¨ï¼ˆå¦‚ SGD, Adamï¼‰å¿…é¡»æ˜ç¡®ä½ è¦æ›´æ–°å“ªäº›å‚æ•°ã€‚"
      ],
      "metadata": {
        "id": "ABfVjvo7vlpN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataloader.dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MD1hAzzgvxDy",
        "outputId": "d3768744-47f0-47f3-924c-dd4a81bd09ae"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "  model.train()\n",
        "  total_size = len(dataloader.dataset)\n",
        "  correct = 0\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "    X, y = X.to(device), y.to(device)\n",
        "    pred = model(X)\n",
        "    losses = loss_fn(pred, y)\n",
        "    loss = losses.mean()\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      correct = (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "      acc = correct / X.size(0)\n",
        "      correct = 0\n",
        "      print(f\"batch: {batch} loss: {loss} acc: {acc}\")\n",
        "\n",
        "def test(dataloader, model, loss_fn):\n",
        "  model.eval()\n",
        "  total_size = len(dataloader.dataset)\n",
        "  total_loss = 0\n",
        "  correct = 0\n",
        "  with torch.no_grad():\n",
        "    for X, y in dataloader:\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      pred = model(X)\n",
        "      losses = loss_fn(pred, y)\n",
        "      total_loss += losses.sum().item()\n",
        "      correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "  avg_loss = total_loss / total_size\n",
        "  acc = correct / total_size\n",
        "  print(f\"test loss: {avg_loss:.4f} acc: {acc:.4f}\")\n"
      ],
      "metadata": {
        "id": "2B_IZW6qviOZ"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "éå¸¸å¥½çš„é—®é¢˜ï¼è¿™ä¸‰å¥è¯æ˜¯ **PyTorch ä¸­è®­ç»ƒæ¨¡å‹çš„æ ¸å¿ƒæ­¥éª¤**ï¼Œè´Ÿè´£å®Œæˆã€Œåå‘ä¼ æ’­ + å‚æ•°æ›´æ–° + æ¢¯åº¦æ¸…é›¶ã€ã€‚æˆ‘ä»¬ä¸€æ¡ä¸€æ¡æ¥è§£é‡Šï¼Œæ¯ä¸€å¥éƒ½å¾ˆé‡è¦ï¼š\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ” ä¸Šä¸‹æ–‡ä»£ç ï¼š\n",
        "\n",
        "```python\n",
        "loss.backward()       # â‘  åå‘ä¼ æ’­\n",
        "optimizer.step()      # â‘¡ æ›´æ–°æ¨¡å‹å‚æ•°\n",
        "optimizer.zero_grad() # â‘¢ æ¸…ç©ºæ¢¯åº¦\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… â‘  `loss.backward()`\n",
        "\n",
        "### ğŸ‘‰ æ„æ€ï¼š\n",
        "\n",
        "è®¡ç®—æŸå¤± `loss` å¯¹æ¨¡å‹æ‰€æœ‰å‚æ•°çš„**æ¢¯åº¦ï¼ˆåå¯¼æ•°ï¼‰**ã€‚\n",
        "\n",
        "### ğŸ§  åŸç†ï¼š\n",
        "\n",
        "PyTorch ä½¿ç”¨è‡ªåŠ¨å¾®åˆ†ç³»ç»Ÿï¼ˆautogradï¼‰ï¼Œå½“ä½ è°ƒç”¨ `.backward()` æ—¶ï¼Œå®ƒä¼šè‡ªåŠ¨æ ¹æ®æŸå¤±å‡½æ•°æ²¿ç€æ¨¡å‹åå‘ä¼ æ’­ï¼Œè®¡ç®—æ‰€æœ‰å‚æ•°çš„æ¢¯åº¦ï¼ˆå³å‘Šè¯‰ä½ ï¼šæ¯ä¸ªå‚æ•°è¯¥å¾€å“ªä¸ªæ–¹å‘è°ƒæ•´æ‰èƒ½å‡å°‘ lossï¼‰ã€‚\n",
        "\n",
        "### ğŸ¯ ä½œç”¨ï¼š\n",
        "\n",
        "è¿™ä¸€æ­¥æ„å»ºäº†â€œæ¢¯åº¦ä¿¡æ¯â€ï¼Œä½†**è¿˜æ²¡æ›´æ–°æ¨¡å‹å‚æ•°**ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… â‘¡ `optimizer.step()`\n",
        "\n",
        "### ğŸ‘‰ æ„æ€ï¼š\n",
        "\n",
        "æ ¹æ®åˆšåˆš `.backward()` å¾—åˆ°çš„æ¢¯åº¦ï¼Œ**æ›´æ–°æ¨¡å‹çš„å‚æ•°**ã€‚\n",
        "\n",
        "### ğŸ§  åŸç†ï¼ˆä»¥ Adam æˆ– SGD ä¸ºä¾‹ï¼‰ï¼š\n",
        "\n",
        "æ›´æ–°çš„å…¬å¼å¤§è‡´æ˜¯ï¼š\n",
        "\n",
        "$$\n",
        "\\theta \\leftarrow \\theta - \\eta \\cdot \\nabla_\\theta\n",
        "$$\n",
        "\n",
        "å³æ¯ä¸ªå‚æ•° $\\theta$ ä¼šå¾€å‡å°‘ loss çš„æ–¹å‘ç§»åŠ¨ä¸€å°æ­¥ï¼Œæ­¥é•¿ç”±å­¦ä¹ ç‡ $\\eta$ å†³å®šã€‚\n",
        "\n",
        "### ğŸ¯ ä½œç”¨ï¼š\n",
        "\n",
        "è¿™æ˜¯\\*\\*çœŸæ­£â€œä¼˜åŒ–æ¨¡å‹â€\\*\\*çš„ä¸€æ­¥ï¼Œè®©å®ƒè¡¨ç°å¾—æ›´å¥½ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… â‘¢ `optimizer.zero_grad()`\n",
        "\n",
        "### ğŸ‘‰ æ„æ€ï¼š\n",
        "\n",
        "æŠŠæ‰€æœ‰æ¨¡å‹å‚æ•°çš„æ¢¯åº¦æ¸…ç©ºï¼ˆå½’é›¶ï¼‰ã€‚\n",
        "\n",
        "### ğŸ§  åŸå› ï¼š\n",
        "\n",
        "* PyTorch ä¸­æ¢¯åº¦æ˜¯ **ç´¯åŠ çš„**ï¼ˆé»˜è®¤ä¸æ˜¯è¦†ç›–ï¼Œè€Œæ˜¯ +=ï¼‰ï¼›\n",
        "* å¦‚æœä½ ä¸æ¸…é›¶ï¼Œä¸‹ä¸€è½®è®­ç»ƒçš„æ¢¯åº¦ä¼šå åŠ åœ¨ä¹‹å‰çš„æ¢¯åº¦ä¸Šï¼Œå¯¼è‡´é”™è¯¯çš„æ›´æ–°ã€‚\n",
        "\n",
        "```python\n",
        "# é”™è¯¯ç¤ºä¾‹ï¼ˆæ²¡æœ‰ zero_gradï¼‰ï¼š\n",
        "loss.backward()  # ç¬¬ä¸€æ¬¡\n",
        "loss.backward()  # ç¬¬äºŒæ¬¡ï¼šæ¢¯åº¦å åŠ ä¸Šå»äº† âŒ\n",
        "```\n",
        "\n",
        "### ğŸ¯ ä½œç”¨ï¼š\n",
        "\n",
        "**ç¡®ä¿æ¯ä¸ª batch éƒ½æ˜¯â€œå¹²å‡€åœ°â€é‡æ–°è®¡ç®—æ¢¯åº¦ã€‚**\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… æ€»ç»“ä¸€å¥è¯è®°å¿†ï¼š\n",
        "\n",
        "> `loss.backward()` æ˜¯**ç®—æ¢¯åº¦**ï¼Œ`optimizer.step()` æ˜¯**ç”¨æ¢¯åº¦æ”¹å‚æ•°**ï¼Œ`optimizer.zero_grad()` æ˜¯**æ¸…ç©ºæ¢¯åº¦å‡†å¤‡ä¸‹æ¬¡**ã€‚\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ“˜ ä¸€ä¸ªå®Œæ•´çš„å…¸å‹è®­ç»ƒå¾ªç¯ï¼š\n",
        "\n",
        "```python\n",
        "for X, y in dataloader:\n",
        "    X, y = X.to(device), y.to(device)\n",
        "\n",
        "    pred = model(X)\n",
        "    loss = loss_fn(pred, y)\n",
        "\n",
        "    loss.backward()        # â‘  è®¡ç®—æ¢¯åº¦\n",
        "    optimizer.step()       # â‘¡ ç”¨æ¢¯åº¦æ›´æ–°å‚æ•°\n",
        "    optimizer.zero_grad()  # â‘¢ æ¸…é™¤æ¢¯åº¦\n",
        "```\n",
        "\n",
        "è¿™ä¸‰æ­¥é¡ºåºä¸èƒ½é”™ï¼Œå¿…é¡»æ˜¯ **å…ˆ backward â†’ å† step â†’ æœ€å zero\\_grad**ã€‚\n",
        "\n",
        "æ˜¯å¦è¿˜æƒ³äº†è§£â€œä¸ºä»€ä¹ˆæ¢¯åº¦ä¼šç´¯åŠ â€èƒŒåçš„å®ç°ç»†èŠ‚ï¼Ÿæˆ‘å¯ä»¥æ·±å…¥è®² autograd çš„å†…éƒ¨é€»è¾‘ã€‚\n"
      ],
      "metadata": {
        "id": "y1MqFxfnx7cZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "for t in range(epochs):\n",
        "  print(f\"Epoch {t+1} \\n==========================\")\n",
        "  train(train_loader, model, loss_fn, optimizer)\n",
        "  test(test_loader, model, loss_fn)\n",
        "\n",
        "print(\"Done\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4B5fqL459I0",
        "outputId": "924fb5c8-4197-4448-efaa-14b0591fa8e4"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 \n",
            "==========================\n",
            "batch: 0 loss: 2.3986711502075195 acc: 0.125\n",
            "batch: 100 loss: 0.5554952621459961 acc: 0.84375\n",
            "batch: 200 loss: 0.4497145712375641 acc: 0.828125\n",
            "batch: 300 loss: 0.4333111047744751 acc: 0.875\n",
            "batch: 400 loss: 0.655768096446991 acc: 0.78125\n",
            "batch: 500 loss: 0.7607214450836182 acc: 0.796875\n",
            "batch: 600 loss: 0.6213424801826477 acc: 0.734375\n",
            "batch: 700 loss: 0.4395221173763275 acc: 0.890625\n",
            "batch: 800 loss: 0.442857563495636 acc: 0.828125\n",
            "batch: 900 loss: 0.2911531329154968 acc: 0.90625\n",
            "test loss: 0.4085 acc: 0.8519\n",
            "Epoch 2 \n",
            "==========================\n",
            "batch: 0 loss: 0.2838748097419739 acc: 0.90625\n",
            "batch: 100 loss: 0.23040398955345154 acc: 0.921875\n",
            "batch: 200 loss: 0.5953943729400635 acc: 0.8125\n",
            "batch: 300 loss: 0.21695426106452942 acc: 0.921875\n",
            "batch: 400 loss: 0.2825273275375366 acc: 0.90625\n",
            "batch: 500 loss: 0.4035579562187195 acc: 0.90625\n",
            "batch: 600 loss: 0.28308600187301636 acc: 0.875\n",
            "batch: 700 loss: 0.4439104497432709 acc: 0.859375\n",
            "batch: 800 loss: 0.3554537296295166 acc: 0.921875\n",
            "batch: 900 loss: 0.22876888513565063 acc: 0.9375\n",
            "test loss: 0.3504 acc: 0.8667\n",
            "Epoch 3 \n",
            "==========================\n",
            "batch: 0 loss: 0.32972678542137146 acc: 0.890625\n",
            "batch: 100 loss: 0.3642224371433258 acc: 0.90625\n",
            "batch: 200 loss: 0.5384726524353027 acc: 0.78125\n",
            "batch: 300 loss: 0.2735554575920105 acc: 0.921875\n",
            "batch: 400 loss: 0.35663890838623047 acc: 0.828125\n",
            "batch: 500 loss: 0.25327596068382263 acc: 0.890625\n",
            "batch: 600 loss: 0.3341113328933716 acc: 0.859375\n",
            "batch: 700 loss: 0.3973519802093506 acc: 0.859375\n",
            "batch: 800 loss: 0.30268579721450806 acc: 0.84375\n",
            "batch: 900 loss: 0.22895869612693787 acc: 0.953125\n",
            "test loss: 0.3456 acc: 0.8735\n",
            "Epoch 4 \n",
            "==========================\n",
            "batch: 0 loss: 0.37282681465148926 acc: 0.859375\n",
            "batch: 100 loss: 0.22534510493278503 acc: 0.921875\n",
            "batch: 200 loss: 0.39371564984321594 acc: 0.8125\n",
            "batch: 300 loss: 0.2888581156730652 acc: 0.859375\n",
            "batch: 400 loss: 0.36106398701667786 acc: 0.875\n",
            "batch: 500 loss: 0.18392601609230042 acc: 0.921875\n",
            "batch: 600 loss: 0.22925736010074615 acc: 0.9375\n",
            "batch: 700 loss: 0.1638525426387787 acc: 0.9375\n",
            "batch: 800 loss: 0.27553531527519226 acc: 0.921875\n",
            "batch: 900 loss: 0.28482988476753235 acc: 0.90625\n",
            "test loss: 0.3397 acc: 0.8773\n",
            "Epoch 5 \n",
            "==========================\n",
            "batch: 0 loss: 0.2887543737888336 acc: 0.890625\n",
            "batch: 100 loss: 0.5048924088478088 acc: 0.8125\n",
            "batch: 200 loss: 0.28686046600341797 acc: 0.859375\n",
            "batch: 300 loss: 0.3296695351600647 acc: 0.828125\n",
            "batch: 400 loss: 0.1402270495891571 acc: 0.953125\n",
            "batch: 500 loss: 0.30086854100227356 acc: 0.921875\n",
            "batch: 600 loss: 0.3652258515357971 acc: 0.828125\n",
            "batch: 700 loss: 0.24889135360717773 acc: 0.890625\n",
            "batch: 800 loss: 0.2855384349822998 acc: 0.890625\n",
            "batch: 900 loss: 0.39734095335006714 acc: 0.859375\n",
            "test loss: 0.3413 acc: 0.8716\n",
            "Epoch 6 \n",
            "==========================\n",
            "batch: 0 loss: 0.29055914282798767 acc: 0.859375\n",
            "batch: 100 loss: 0.2647686004638672 acc: 0.9375\n",
            "batch: 200 loss: 0.20634472370147705 acc: 0.9375\n",
            "batch: 300 loss: 0.24468079209327698 acc: 0.921875\n",
            "batch: 400 loss: 0.22255751490592957 acc: 0.9375\n",
            "batch: 500 loss: 0.3101370334625244 acc: 0.890625\n",
            "batch: 600 loss: 0.24188297986984253 acc: 0.890625\n",
            "batch: 700 loss: 0.1422227919101715 acc: 0.984375\n",
            "batch: 800 loss: 0.3150993585586548 acc: 0.859375\n",
            "batch: 900 loss: 0.31475234031677246 acc: 0.890625\n",
            "test loss: 0.3176 acc: 0.8891\n",
            "Epoch 7 \n",
            "==========================\n",
            "batch: 0 loss: 0.3230876922607422 acc: 0.875\n",
            "batch: 100 loss: 0.09051802009344101 acc: 1.0\n",
            "batch: 200 loss: 0.29579704999923706 acc: 0.90625\n",
            "batch: 300 loss: 0.26650184392929077 acc: 0.921875\n",
            "batch: 400 loss: 0.33306315541267395 acc: 0.875\n",
            "batch: 500 loss: 0.3243328630924225 acc: 0.875\n",
            "batch: 600 loss: 0.13174793124198914 acc: 0.953125\n",
            "batch: 700 loss: 0.18873339891433716 acc: 0.921875\n",
            "batch: 800 loss: 0.2631567716598511 acc: 0.890625\n",
            "batch: 900 loss: 0.22636711597442627 acc: 0.90625\n",
            "test loss: 0.3480 acc: 0.8744\n",
            "Epoch 8 \n",
            "==========================\n",
            "batch: 0 loss: 0.28817039728164673 acc: 0.859375\n",
            "batch: 100 loss: 0.26062893867492676 acc: 0.921875\n",
            "batch: 200 loss: 0.20472049713134766 acc: 0.921875\n",
            "batch: 300 loss: 0.34617850184440613 acc: 0.8125\n",
            "batch: 400 loss: 0.2831009030342102 acc: 0.921875\n",
            "batch: 500 loss: 0.24628812074661255 acc: 0.90625\n",
            "batch: 600 loss: 0.32128798961639404 acc: 0.84375\n",
            "batch: 700 loss: 0.22029659152030945 acc: 0.890625\n",
            "batch: 800 loss: 0.33958902955055237 acc: 0.875\n",
            "batch: 900 loss: 0.13760927319526672 acc: 0.953125\n",
            "test loss: 0.3244 acc: 0.8886\n",
            "Epoch 9 \n",
            "==========================\n",
            "batch: 0 loss: 0.25701674818992615 acc: 0.875\n",
            "batch: 100 loss: 0.18450577557086945 acc: 0.875\n",
            "batch: 200 loss: 0.21807610988616943 acc: 0.921875\n",
            "batch: 300 loss: 0.18855024874210358 acc: 0.921875\n",
            "batch: 400 loss: 0.21809479594230652 acc: 0.921875\n",
            "batch: 500 loss: 0.20274117588996887 acc: 0.9375\n",
            "batch: 600 loss: 0.15202388167381287 acc: 0.9375\n",
            "batch: 700 loss: 0.22185777127742767 acc: 0.890625\n",
            "batch: 800 loss: 0.31268760561943054 acc: 0.90625\n",
            "batch: 900 loss: 0.22929446399211884 acc: 0.921875\n",
            "test loss: 0.3265 acc: 0.8852\n",
            "Epoch 10 \n",
            "==========================\n",
            "batch: 0 loss: 0.20761500298976898 acc: 0.890625\n",
            "batch: 100 loss: 0.17233121395111084 acc: 0.9375\n",
            "batch: 200 loss: 0.2597338557243347 acc: 0.921875\n",
            "batch: 300 loss: 0.22364240884780884 acc: 0.953125\n",
            "batch: 400 loss: 0.21830600500106812 acc: 0.9375\n",
            "batch: 500 loss: 0.15750184655189514 acc: 0.9375\n",
            "batch: 600 loss: 0.3331056237220764 acc: 0.859375\n",
            "batch: 700 loss: 0.16708287596702576 acc: 0.90625\n",
            "batch: 800 loss: 0.26742538809776306 acc: 0.921875\n",
            "batch: 900 loss: 0.10223798453807831 acc: 0.9375\n",
            "test loss: 0.3084 acc: 0.8918\n",
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(),\"model_state\")\n",
        "print(\"model parameters save to model_state\")b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNpcanTy9VyY",
        "outputId": "b888dadd-1bda-4f59-f8e5-cb666a44612f"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model parameters save to model_state\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "new_model = NeuralNetwork()\n",
        "new_model.load_state_dict(torch.load(\"model_state\"))\n",
        "new_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tksArEiA-AZd",
        "outputId": "331b1518-a951-4a8a-f331-d747f1eac5ce"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NeuralNetwork(\n",
              "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (seq_stack): Sequential(\n",
              "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
              "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): Dropout(p=0.2, inplace=False)\n",
              "    (4): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (6): ReLU()\n",
              "    (7): Dropout(p=0.2, inplace=False)\n",
              "    (8): Linear(in_features=512, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    }
  ]
}