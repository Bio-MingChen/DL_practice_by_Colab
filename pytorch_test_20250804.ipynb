{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyPQD+HTgHfns+R4YJnLAHe9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bio-MingChen/DL_practice_by_Colab/blob/main/pytorch_test_20250804.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n-ImAKNS0xEl"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "from torchvision.datasets import FashionMNIST\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.optim import Adam"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "| GPU 类型                       | 架构           | 显存            | FP16 性能           | 适合任务           | 相对性能评分      |\n",
        "| ---------------------------- | ------------ | ------------- | ----------------- | -------------- | ----------- |\n",
        "| **A100 GPU**                 | Ampere       | 40GB（Colab常配） | 非常强（\\~312 TFLOPs） | 超大模型，训练+推理都快   | ⭐⭐⭐⭐⭐       |\n",
        "| **L4 GPU**                   | Ada Lovelace | 24GB          | 中等（\\~30 TFLOPs）   | 推理、轻量训练、视频处理   | ⭐⭐⭐⭐        |\n",
        "| **T4 GPU**                   | Turing       | 16GB          | 较弱（\\~8.1 TFLOPs）  | 推理、微调中小模型      | ⭐⭐          |\n",
        "| **CPU**                      | -            | -             | 慢得多               | 调试、无 GPU 需求时使用 | ⭐           |\n",
        "| **TPU v2-8 / v5e-1 / v6e-1** | 各代 TPU       | -             | 高度并行              | 专用于 TF 模型训练    | ⭐⭐⭐⭐（仅限 TF） |\n",
        "\n",
        "\n",
        "| 用途                                   | 推荐硬件                      |\n",
        "| ------------------------------------ | ------------------------- |\n",
        "| 训练大模型（如 transformer、Diffusion、VAE 等） | ✅ **A100 GPU**（最佳）        |\n",
        "| 微调 BERT/ResNet 等模型                   | ✅ **L4 GPU** 或 T4 GPU（够用） |\n",
        "| 深度学习推理 / 小模型部署                       | ✅ **T4 GPU**（节省资源）        |\n",
        "| 纯 numpy/pandas/CPU 推理                | ✅ CPU 就够                  |\n",
        "| TensorFlow 专属大规模训练                   | ✅ TPU（仅 TF，不支持 PyTorch）   |\n"
      ],
      "metadata": {
        "id": "yOIEkrs66crs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-TqxjKpA4Ada",
        "outputId": "5f96c3c4-eaef-4dff-a30e-cacf6fb79222"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "x = np.linspace(-10,10,100)\n",
        "y = np.maximum(0,x)\n",
        "fig, ax = plt.subplots(1,1,figsize=(8,5))\n",
        "ax.plot(x,y)\n",
        "ax.set(title=\"ReLU curve\",xlabel=\"x\", ylabel=\"y\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        },
        "id": "_05DHlyq4K0w",
        "outputId": "58906d63-404e-456d-8a20-b7de054956ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Text(0.5, 1.0, 'ReLU curve'), Text(0.5, 0, 'x'), Text(0, 0.5, 'y')]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "| 想要做的事情       | 应该用什么                                           |\n",
        "| ------------ | ----------------------------------------------- |\n",
        "| 生成等间距的值（含终点） | `np.linspace(start, stop, num)`                 |\n",
        "| 生成等间距（不含终点）  | `np.linspace(start, stop, num, endpoint=False)` |\n",
        "| 知道每个点之间距离    | `np.linspace(..., retstep=True)`                |\n"
      ],
      "metadata": {
        "id": "mWgX18Cv6zyk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`plt.subplots()` 是 `matplotlib.pyplot` 中非常重要、推荐使用的一个函数，用于**创建图形（Figure）和坐标轴（Axes）对象**，是“面向对象”风格绘图的基础。\n",
        "\n",
        "---\n",
        "\n",
        "## 🧠 一句话解释：\n",
        "\n",
        "> `plt.subplots()` 返回 `(fig, ax)`，即一个 **画布** 和一个或多个 **子图坐标轴**，方便你在上面画图并灵活控制布局。\n",
        "\n",
        "---\n",
        "\n",
        "## ✅ 基本用法示例：\n",
        "\n",
        "```python\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "x = np.linspace(-10, 10, 100)\n",
        "y = np.maximum(0, x)\n",
        "\n",
        "fig, ax = plt.subplots()  # 创建画布和子图\n",
        "ax.plot(x, y)             # 在子图上绘图\n",
        "ax.set(title=\"ReLU\", xlabel=\"x\", ylabel=\"y\")\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 📦 函数签名：\n",
        "\n",
        "```python\n",
        "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(w, h), sharex=False, sharey=False)\n",
        "```\n",
        "\n",
        "| 参数名             | 含义           |\n",
        "| --------------- | ------------ |\n",
        "| `nrows`         | 子图的行数        |\n",
        "| `ncols`         | 子图的列数        |\n",
        "| `figsize`       | 整个图的尺寸，单位是英寸 |\n",
        "| `sharex/sharey` | 是否共享坐标轴      |\n",
        "\n",
        "---\n",
        "\n",
        "## 🧩 多子图示例：\n",
        "\n",
        "```python\n",
        "fig, axs = plt.subplots(2, 2, figsize=(8, 6))  # 创建2行2列共4个子图\n",
        "axs[0, 0].plot(x, y)\n",
        "axs[0, 0].set_title(\"Top left\")\n",
        "# 你还可以设置 axs[0,1], axs[1,0], axs[1,1] 等\n",
        "```\n",
        "\n",
        "⚠️ 当 `nrows*ncols > 1` 时，返回的是一个 **Axes数组（类似矩阵）**。\n",
        "\n",
        "---\n",
        "\n",
        "## 🔄 与 `plt.plot()` 有什么区别？\n",
        "\n",
        "| 特点    | `plt.plot()` 风格 | `plt.subplots()` 风格 |\n",
        "| ----- | --------------- | ------------------- |\n",
        "| 代码风格  | 面向过程            | 面向对象                |\n",
        "| 控制灵活性 | 低               | 高（适合子图、多图、嵌套布局）     |\n",
        "| 推荐程度  | 初学者可用           | 正式绘图推荐 ✅            |\n",
        "\n",
        "---\n",
        "\n",
        "## ✅ 总结：\n",
        "\n",
        "| 你想做的事情        | 是否用 `plt.subplots()` |\n",
        "| ------------- | -------------------- |\n",
        "| 简单快速画图        | ❌ 可用 `plt.plot()`    |\n",
        "| 需要多个子图        | ✅ 强烈推荐               |\n",
        "| 控制子图标题、轴标签、比例 | ✅                    |\n",
        "| 更专业的图表设计      | ✅ 必须掌握               |\n",
        "\n",
        "---\n",
        "\n",
        "如果你需要我帮你画一个例子，比如 2x2 子图的布局，或对比 ReLU / Sigmoid / Tanh 等函数图像，我可以马上帮你画。\n"
      ],
      "metadata": {
        "id": "G-mhfkDC55V3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = FashionMNIST(root=\"data\",train=True, download=True, transform=ToTensor())\n",
        "test_data = FashionMNIST(root=\"data\",train=False, download=True, transform=ToTensor())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "418NdIXA65mo",
        "outputId": "9fa1faad-d395-4fe3-bd13-4b034913a744"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:02<00:00, 10.1MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 168kB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:01<00:00, 3.21MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 14.0MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "train_dataloader = DataLoader(training_data, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=True)\n",
        "print(f\" batch number of train_dataloader: {len(train_dataloader)}\\n size of traindataloader: {len(train_dataloader.dataset)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OK17qXi88MM9",
        "outputId": "c3ead6a8-d60e-4fb1-b150-ecec9077afd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " batch number of train_dataloader: 938\n",
            " size of traindataloader: 60000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.net = nn.Sequential(\n",
        "        nn.Linear(28*28, 512),\n",
        "        nn.BatchNorm1d(512),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.2),\n",
        "\n",
        "        nn.Linear(512, 512),\n",
        "        nn.BatchNorm1d(512),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.2),\n",
        "\n",
        "        nn.Linear(512, 512),\n",
        "        nn.BatchNorm1d(512),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.2),\n",
        "\n",
        "        nn.Linear(512, 10)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.flatten(x)\n",
        "    logits = self.net(x)\n",
        "    return logits\n",
        "\n",
        "model = NeuralNetwork()\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "XwGj_BDs8yeS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = Adam(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "v04lDsbl9skJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "  model.train()\n",
        "  size = len(dataloader.dataset)\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "    X, y = X.to(device), y.to(device)\n",
        "    pred = model(X)\n",
        "    loss = loss_fn(pred, y)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if batch % 100 == 99:\n",
        "      loss, current = loss.item(), batch * len(X)\n",
        "      print(f\"loss {loss:.4f} [{current}/{size}]\")\n",
        "\n",
        "def test(dataloader, model, loss_fn):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    correct = 0\n",
        "    total_loss = 0\n",
        "    size = len(dataloader.dataset)\n",
        "    batches = len(dataloader)\n",
        "    for X, y in dataloader:\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      pred = model(X)\n",
        "      loss = loss_fn(pred, y)\n",
        "      total_loss += loss.item()\n",
        "      correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "  avg_loss = total_loss / batches\n",
        "  acc = correct / size\n",
        "  print(f\"Test data: Avg loss: {avg_loss:.4f}, Accuracy: {acc:.4f}\")"
      ],
      "metadata": {
        "id": "ewB1edWB952J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "\n",
        "for t in range(epochs):\n",
        "  print(f\"Epoch {t}\\n =============================\")\n",
        "  train(train_dataloader, model, loss_fn, optimizer)\n",
        "  test(test_dataloader, model, loss_fn)\n",
        "\n",
        "print(\"Done\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRfAsmjYAniT",
        "outputId": "6cac35ad-8efa-4d9b-b168-364c742779af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0\n",
            " =============================\n",
            "loss 0.2258 [6336/60000]\n",
            "loss 0.2155 [12736/60000]\n",
            "loss 0.2612 [19136/60000]\n",
            "loss 0.1472 [25536/60000]\n",
            "loss 0.2529 [31936/60000]\n",
            "loss 0.1450 [38336/60000]\n",
            "loss 0.0987 [44736/60000]\n",
            "loss 0.1262 [51136/60000]\n",
            "loss 0.3504 [57536/60000]\n",
            "Test data: Avg loss: 0.3011, Accuracy: 0.9022\n",
            "Epoch 1\n",
            " =============================\n",
            "loss 0.2523 [6336/60000]\n",
            "loss 0.0943 [12736/60000]\n",
            "loss 0.1954 [19136/60000]\n",
            "loss 0.0997 [25536/60000]\n",
            "loss 0.1561 [31936/60000]\n",
            "loss 0.2020 [38336/60000]\n",
            "loss 0.1873 [44736/60000]\n",
            "loss 0.1885 [51136/60000]\n",
            "loss 0.1718 [57536/60000]\n",
            "Test data: Avg loss: 0.3258, Accuracy: 0.8908\n",
            "Epoch 2\n",
            " =============================\n",
            "loss 0.1814 [6336/60000]\n",
            "loss 0.2804 [12736/60000]\n",
            "loss 0.1600 [19136/60000]\n",
            "loss 0.2809 [25536/60000]\n",
            "loss 0.1652 [31936/60000]\n",
            "loss 0.2136 [38336/60000]\n",
            "loss 0.1913 [44736/60000]\n",
            "loss 0.2071 [51136/60000]\n",
            "loss 0.0634 [57536/60000]\n",
            "Test data: Avg loss: 0.3055, Accuracy: 0.8973\n",
            "Epoch 3\n",
            " =============================\n",
            "loss 0.1787 [6336/60000]\n",
            "loss 0.1560 [12736/60000]\n",
            "loss 0.1251 [19136/60000]\n",
            "loss 0.1659 [25536/60000]\n",
            "loss 0.1687 [31936/60000]\n",
            "loss 0.1542 [38336/60000]\n",
            "loss 0.1924 [44736/60000]\n",
            "loss 0.1448 [51136/60000]\n",
            "loss 0.3249 [57536/60000]\n",
            "Test data: Avg loss: 0.3265, Accuracy: 0.8940\n",
            "Epoch 4\n",
            " =============================\n",
            "loss 0.1374 [6336/60000]\n",
            "loss 0.1981 [12736/60000]\n",
            "loss 0.2287 [19136/60000]\n",
            "loss 0.0944 [25536/60000]\n",
            "loss 0.0985 [31936/60000]\n",
            "loss 0.1523 [38336/60000]\n",
            "loss 0.0815 [44736/60000]\n",
            "loss 0.1489 [51136/60000]\n",
            "loss 0.1773 [57536/60000]\n",
            "Test data: Avg loss: 0.3167, Accuracy: 0.8988\n",
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"FashionMNIST_fnn.pt\")"
      ],
      "metadata": {
        "id": "cOr-wJ-XEnlI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cp_model = NeuralNetwork()\n",
        "cp_model.load_state_dict(torch.load(\"FashionMNIST_fnn.pt\"))\n",
        "cp_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgLsQ3YpEsiI",
        "outputId": "21de8554-3529-451e-8f16-a581249f2421"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NeuralNetwork(\n",
              "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (net): Sequential(\n",
              "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
              "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): Dropout(p=0.2, inplace=False)\n",
              "    (4): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (6): ReLU()\n",
              "    (7): Dropout(p=0.2, inplace=False)\n",
              "    (8): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (9): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (10): ReLU()\n",
              "    (11): Dropout(p=0.2, inplace=False)\n",
              "    (12): Linear(in_features=512, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "这是个非常常见又非常重要的问题，下面我从结构、功能和使用建议三个角度来解释：\n",
        "\n",
        "---\n",
        "\n",
        "## 🧱 一句话区分：\n",
        "\n",
        "| 模块                          | 作用                                      |\n",
        "| --------------------------- | --------------------------------------- |\n",
        "| `torch.nn`                  | 面向对象的「模块化神经网络层」，比如 `nn.ReLU()` 是一个**类** |\n",
        "| `torch.nn.functional` (`F`) | 面向函数的「无状态计算操作」，比如 `F.relu(x)` 是一个**函数** |\n",
        "\n",
        "---\n",
        "\n",
        "## 🔍 举例对比：ReLU 的两种写法\n",
        "\n",
        "### ✅ 使用 `nn.ReLU`（模块方式）\n",
        "\n",
        "```python\n",
        "import torch.nn as nn\n",
        "\n",
        "relu_layer = nn.ReLU()\n",
        "output = relu_layer(x)\n",
        "```\n",
        "\n",
        "* 推荐用于 `nn.Sequential` 或 `nn.Module` 中注册为层。\n",
        "* 可以保存到模型结构中。\n",
        "\n",
        "---\n",
        "\n",
        "### ✅ 使用 `F.relu`（函数方式）\n",
        "\n",
        "```python\n",
        "import torch.nn.functional as F\n",
        "\n",
        "output = F.relu(x)\n",
        "```\n",
        "\n",
        "* 更灵活，通常在 `forward()` 函数内部临时调用。\n",
        "* **不会出现在模型结构中**（不能保存为一层）。\n",
        "\n",
        "---\n",
        "\n",
        "## 🔄 更全面的区别：\n",
        "\n",
        "| 对比项   | `nn.ReLU()`                     | `F.relu(x)`    |\n",
        "| ----- | ------------------------------- | -------------- |\n",
        "| 是否是类  | ✅ 是一个类                          | ❌ 是函数          |\n",
        "| 是否有状态 | ✅ 有可能有（如 `Dropout(p)`）          | ❌ 无状态          |\n",
        "| 用法    | `relu = nn.ReLU()` 然后 `relu(x)` | 直接 `F.relu(x)` |\n",
        "| 适合场景  | 作为模型的一部分                        | 轻量/灵活操作        |\n",
        "| 模型保存  | 会被保存进模型                         | 不会保存为模型结构      |\n",
        "\n",
        "---\n",
        "\n",
        "## 📌 示例：构建网络时的区别\n",
        "\n",
        "### ✅ 推荐方式（注册模块）：\n",
        "\n",
        "```python\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(10, 5)\n",
        "        self.relu = nn.ReLU()   # 注册了 ReLU 模块\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear(x)\n",
        "        x = self.relu(x)\n",
        "        return x\n",
        "```\n",
        "\n",
        "### ❗ 也可以这样写（函数方式）：\n",
        "\n",
        "```python\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(10, 5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear(x)\n",
        "        x = F.relu(x)  # 不注册，直接使用\n",
        "        return x\n",
        "```\n",
        "\n",
        "两种方式都能用，区别主要在是否**可追踪/可保存为模块结构**。\n",
        "\n",
        "---\n",
        "\n",
        "## ✅ 总结建议：\n",
        "\n",
        "| 你要做的事                        | 推荐方式                |\n",
        "| ---------------------------- | ------------------- |\n",
        "| 需要在 `__init__` 注册网络结构、保存模型结构 | ✅ 用 `nn.ReLU()`     |\n",
        "| 在 `forward()` 内快速应用函数，不用注册   | ✅ 用 `F.relu(x)`     |\n",
        "| 不确定是否需要保存为模块                 | 建议用 `nn.ReLU()` 更统一 |\n",
        "\n",
        "---\n",
        "\n",
        "需要我给出更多类似 `Dropout`、`Softmax`、`Conv2d` 的对比也可以继续讲。\n"
      ],
      "metadata": {
        "id": "Pd-jyCE8ETtW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.accelerator.current_accelerator()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4s-EH-wC8h2",
        "outputId": "5da4aa15-60a6-46ee-d346-892eaf0d946d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "这段代码是一个 **基于 PyTorch 的 MNIST 手写数字识别训练示例**。你提到的几个关键概念包括 `Adadelta`, `StepLR`, `transforms.Compose`, `train_kwargs` 等，下面我逐一进行详细解释。\n",
        "\n",
        "---\n",
        "\n",
        "## 🧠 1. `Adadelta` 优化器\n",
        "\n",
        "```python\n",
        "optimizer = optim.Adadelta(model.parameters(), lr=args.lr)\n",
        "```\n",
        "\n",
        "### 📌 是什么？\n",
        "\n",
        "* `Adadelta` 是一种**自适应学习率优化器**，它不需要手动设置全局的学习率衰减 schedule。\n",
        "* 相比传统 SGD，它会根据历史梯度动态调整每个参数的学习率。\n",
        "\n",
        "### 🔧 特点：\n",
        "\n",
        "* 优点：鲁棒性高，对初始学习率不敏感。\n",
        "* 适合用于训练简单模型（比如这个 CNN）时快速收敛。\n",
        "\n",
        "---\n",
        "\n",
        "## 🧠 2. `StepLR` 学习率调度器\n",
        "\n",
        "```python\n",
        "scheduler = StepLR(optimizer, step_size=1, gamma=args.gamma)\n",
        "```\n",
        "\n",
        "### 📌 是什么？\n",
        "\n",
        "* `StepLR` 是一种**学习率调度器（scheduler）**，用于**每隔若干 epoch 自动降低学习率**。\n",
        "\n",
        "### 🧮 工作原理：\n",
        "\n",
        "* 初始学习率为 `args.lr`\n",
        "* 每 `step_size` 个 epoch，学习率变为原来的 `gamma` 倍\n",
        "  例如：\n",
        "\n",
        "  ```\n",
        "  epoch 1: lr = 1.0\n",
        "  epoch 2: lr = 1.0 × gamma\n",
        "  epoch 3: lr = 1.0 × gamma²\n",
        "  ```\n",
        "\n",
        "---\n",
        "\n",
        "## 🧠 3. `transforms.Compose`\n",
        "\n",
        "```python\n",
        "transform=transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "```\n",
        "\n",
        "### 📌 是什么？\n",
        "\n",
        "* `Compose` 是 `torchvision.transforms` 里的一个工具函数，用于**把多个数据预处理操作串联起来执行**。\n",
        "\n",
        "### 🔧 在这里做了什么：\n",
        "\n",
        "1. `transforms.ToTensor()`\n",
        "   把 `PIL Image` 或 `numpy array` 转换为 `Tensor`，并自动把像素值从 \\[0, 255] 缩放到 \\[0, 1]。\n",
        "2. `transforms.Normalize((0.1307,), (0.3081,))`\n",
        "   标准化数据：减去均值再除以标准差，使得每张图片的分布更稳定，有利于模型训练。\n",
        "\n",
        "---\n",
        "\n",
        "## 🧠 4. `train_kwargs` 和 `test_kwargs`\n",
        "\n",
        "```python\n",
        "train_kwargs = {'batch_size': args.batch_size}\n",
        "test_kwargs = {'batch_size': args.test_batch_size}\n",
        "```\n",
        "\n",
        "### 📌 是什么？\n",
        "\n",
        "* `train_kwargs` 和 `test_kwargs` 是两个字典，用于传递参数给 `DataLoader`。\n",
        "\n",
        "### 🧩 在开启加速时：\n",
        "\n",
        "```python\n",
        "accel_kwargs = {\n",
        "    'num_workers': 1,\n",
        "    'persistent_workers': True,\n",
        "    'pin_memory': True,\n",
        "    'shuffle': True\n",
        "}\n",
        "```\n",
        "\n",
        "这些参数是为了加速数据加载：\n",
        "\n",
        "| 参数                   | 含义                                   |\n",
        "| -------------------- | ------------------------------------ |\n",
        "| `num_workers`        | 开启多少个线程并行加载数据（>0 加速）                 |\n",
        "| `persistent_workers` | epoch 间保留工作线程，避免频繁销毁                 |\n",
        "| `pin_memory`         | 将数据加载到 CUDA 的 page-locked memory（更快） |\n",
        "| `shuffle`            | 每个 epoch 重新打乱数据                      |\n",
        "\n",
        "最终：\n",
        "\n",
        "```python\n",
        "train_loader = DataLoader(dataset1, **train_kwargs)\n",
        "```\n",
        "\n",
        "等价于：\n",
        "\n",
        "```python\n",
        "DataLoader(dataset1, batch_size=64, num_workers=1, pin_memory=True, shuffle=True)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 🧪 额外知识点补充：\n",
        "\n",
        "| 名称                               | 说明                                |\n",
        "| -------------------------------- | --------------------------------- |\n",
        "| `F.relu()`                       | 激活函数，输出为 `max(0, x)`              |\n",
        "| `F.nll_loss()`                   | 负对数似然损失函数（常和 `log_softmax` 一起用）   |\n",
        "| `model.train()` / `model.eval()` | 训练 / 推理模式的切换（控制 dropout 和 BN 层行为） |\n",
        "| `torch.flatten(x, 1)`            | 扁平化除 batch 维外的所有维度                |\n",
        "| `output.argmax(dim=1)`           | 获取预测结果中概率最大的类索引                   |\n",
        "\n",
        "---\n",
        "\n",
        "## ✅ 总结建议\n",
        "\n",
        "| 名词                   | 建议理解方式                |\n",
        "| -------------------- | --------------------- |\n",
        "| `Adadelta`           | 一种不用手动调整学习率的优化器       |\n",
        "| `StepLR`             | 每隔一定 epoch 衰减学习率      |\n",
        "| `transforms.Compose` | 串联预处理操作，如归一化/转 tensor |\n",
        "| `train_kwargs`       | 用于设置数据加载器的细节参数        |\n",
        "\n",
        "---\n",
        "\n",
        "如果你想更深入理解这些优化器的数学原理，或者想知道什么时候该换成 `Adam`, `SGD`、怎么设置 `gamma` 和 `step_size`，也可以继续问我。还可以帮你画出 `StepLR` 的学习率变化图。\n"
      ],
      "metadata": {
        "id": "WtxUXuO-H7vo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "这句代码：\n",
        "\n",
        "```python\n",
        "images = images.view(batch_samples, -1)\n",
        "```\n",
        "\n",
        "是 PyTorch 中的一个张量重塑操作。它的作用是：\n",
        "\n",
        "> **将多维图像张量展平成二维矩阵**，其中每一行代表一张图像，便于计算均值或标准差等统计量。\n",
        "\n",
        "---\n",
        "\n",
        "## 🧠 一步步解释：\n",
        "\n",
        "假设 `images` 是一个包含 `batch_samples` 张图像的 4 维张量，形状是：\n",
        "\n",
        "```\n",
        "images.shape = (batch_size, channels, height, width)\n",
        "```\n",
        "\n",
        "比如 MNIST 图像是灰度图，那么：\n",
        "\n",
        "```\n",
        "images.shape = (64, 1, 28, 28)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 📌 `.view(batch_samples, -1)` 的含义：\n",
        "\n",
        "* `view()` 是 PyTorch 的 reshape 操作（等价于 `reshape()`）。\n",
        "* `-1` 表示自动推断这个维度的大小。\n",
        "* 所以 `images.view(batch_samples, -1)` 会变成：\n",
        "\n",
        "```\n",
        "images.shape = (64, 784)\n",
        "```\n",
        "\n",
        "即每张图像被展平为一个长度为 784 的向量（因为 28×28=784）。\n",
        "\n",
        "---\n",
        "\n",
        "## 🧪 举个例子：\n",
        "\n",
        "```python\n",
        "import torch\n",
        "\n",
        "images = torch.randn(64, 1, 28, 28)  # 模拟一个 MNIST batch\n",
        "images = images.view(64, -1)         # 变成 (64, 784)\n",
        "print(images.shape)\n",
        "```\n",
        "\n",
        "输出：\n",
        "\n",
        "```\n",
        "torch.Size([64, 784])\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## ✅ 为什么要展平？\n",
        "\n",
        "因为你要对图像像素做统计，例如：\n",
        "\n",
        "```python\n",
        "images.mean(1)  # 每张图的平均像素值\n",
        "images.std(1)   # 每张图的标准差\n",
        "```\n",
        "\n",
        "必须先把每张图展平成一行才能这么做。\n",
        "\n",
        "---\n",
        "\n",
        "## 🔄 总结：\n",
        "\n",
        "| 表达式                      | 含义                   |\n",
        "| ------------------------ | -------------------- |\n",
        "| `x.view(a, -1)`          | 重塑张量为 `a` 行，自动推断列数   |\n",
        "| `images.view(batch, -1)` | 把每张图展开为一维向量（展平）      |\n",
        "| 用途                       | 图像处理、特征统计、输入线性层前的变换等 |\n",
        "\n",
        "---\n",
        "\n",
        "如你还有对 `.reshape()` vs `.view()` 的区别、什么时候不能用 `.view()` 等问题，也可以继续问。\n"
      ],
      "metadata": {
        "id": "Wa8QLnOJK45q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN model\n",
        "# https://github.com/pytorch/examples/blob/main/mnist/main.py"
      ],
      "metadata": {
        "id": "Ne7F17jhH8-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.optim.lr_scheduler import StepLR"
      ],
      "metadata": {
        "id": "dB3hBK3DLGB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
        "    self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
        "    self.dropout1 = nn.Dropout(0.25)\n",
        "    self.dropout2 = nn.Dropout(0.5)\n",
        "    self.fc1 = nn.Linear(9216, 128)\n",
        "    self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.conv1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.conv2(x)\n",
        "    x = F.relu(x)\n",
        "    x = F.max_pool2d(x, 2)\n",
        "    x = self.dropout1(x)\n",
        "    x = self.fc1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.dropout2(x)\n",
        "    x = self.fc2(x)\n",
        "    output = F.log_softmax(x, dim=1)\n",
        "    return output"
      ],
      "metadata": {
        "id": "bDmaymbYLbnZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "你这段代码定义了一个用于 **MNIST 手写数字识别** 的卷积神经网络（CNN），结构比较经典。我们来从**结构、关键函数原理和损失函数的使用**三方面详细讲解。\n",
        "\n",
        "---\n",
        "\n",
        "## 🧱 一、模型结构解读（Net 类）\n",
        "\n",
        "```python\n",
        "class Net(nn.Module):\n",
        "```\n",
        "\n",
        "### 🔧 模块说明：\n",
        "\n",
        "| 层名                   | 类型                        | 功能             | 输出形状（输入 1×28×28） |\n",
        "| -------------------- | ------------------------- | -------------- | ---------------- |\n",
        "| `conv1`              | `nn.Conv2d(1, 32, 3, 1)`  | 3×3卷积，stride=1 | (32, 26, 26)     |\n",
        "| `conv2`              | `nn.Conv2d(32, 64, 3, 1)` | 3×3卷积          | (64, 24, 24)     |\n",
        "| `F.max_pool2d(x, 2)` | 2×2最大池化                   | 降低尺寸           | (64, 12, 12)     |\n",
        "| `dropout1`           | `nn.Dropout(0.25)`        | 随机丢弃25%        |                  |\n",
        "| `fc1`                | `nn.Linear(9216, 128)`    | 全连接，输入需展平      | 128              |\n",
        "| `dropout2`           | `nn.Dropout(0.5)`         | 再丢弃50%         |                  |\n",
        "| `fc2`                | `nn.Linear(128, 10)`      | 输出10个类别        |                  |\n",
        "| `F.log_softmax`      | log 概率输出                  | 用于分类           |                  |\n",
        "\n",
        "---\n",
        "\n",
        "## 🔍 二、关键函数解释\n",
        "\n",
        "### ✅ `F.max_pool2d(x, 2)` 是干嘛的？\n",
        "\n",
        "* **最大池化操作**：在 2×2 的窗口内取最大值。\n",
        "* 作用是：\n",
        "\n",
        "  * 减小尺寸（减少计算量）\n",
        "  * 增强平移不变性\n",
        "  * 提取更鲁棒的特征\n",
        "\n",
        "例子：\n",
        "\n",
        "```python\n",
        "# 原始 x.shape = (64, 24, 24)\n",
        "x = F.max_pool2d(x, 2)\n",
        "# 变为 (64, 12, 12)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### ✅ `F.log_softmax(x, dim=1)` 为什么要用？\n",
        "\n",
        "* 这是 **log(softmax)**，用于多分类任务。\n",
        "* 它输出的是每个类别的**对数概率**。\n",
        "* 更重要的是：**它和 `F.nll_loss()` 搭配使用**，比直接 `softmax + log` 更数值稳定（避免 underflow）。\n",
        "\n",
        "```python\n",
        "output = F.log_softmax(x, dim=1)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 🎯 三、为什么用 `F.nll_loss()` 而不是 `nn.CrossEntropyLoss()`？\n",
        "\n",
        "### ✅ 两者本质上功能一样，都是分类任务的损失函数。\n",
        "\n",
        "| 损失函数                             | 输入                   | 要求                                         |\n",
        "| -------------------------------- | -------------------- | ------------------------------------------ |\n",
        "| `F.nll_loss(log_probs, targets)` | **log\\_softmax 的结果** | 你必须自己先手动 `log_softmax()`                   |\n",
        "| `nn.CrossEntropyLoss()`          | logits（未 softmax）    | 它\\*\\*内部自动做了 `log_softmax()` + `nll_loss()` |\n",
        "\n",
        "### ❓ 那为什么这里用 `F.nll_loss()` 呢？\n",
        "\n",
        "主要是为了 **显式控制 log\\_softmax 的输出**，方便我们查看 log 概率分布，或用于调试/可视化。\n",
        "\n",
        "如果你不需要看中间输出，也可以写得更简洁：\n",
        "\n",
        "```python\n",
        "# 更简洁替代方案\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "logits = model(x)\n",
        "loss = loss_fn(logits, target)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## ✅ 总结表格\n",
        "\n",
        "| 部分                        | 原理                            | 作用                   |\n",
        "| ------------------------- | ----------------------------- | -------------------- |\n",
        "| `F.max_pool2d(x, 2)`      | 2×2窗口取最大值                     | 降低尺寸，提取主要特征          |\n",
        "| `F.log_softmax(x, dim=1)` | 对每个样本进行 log(softmax)          | 生成 log 概率            |\n",
        "| `F.nll_loss()`            | negative log likelihood       | 与 `log_softmax` 搭配使用 |\n",
        "| `nn.CrossEntropyLoss()`   | 自动 = `log_softmax + nll_loss` | 用 logits 直接输进去就行     |\n",
        "\n",
        "---\n",
        "\n",
        "## 🚫 你的代码中有个小拼写错误：\n",
        "\n",
        "```python\n",
        "self.droput1(x)  # ❌ 应该是 dropout1\n",
        "```\n",
        "\n",
        "改成：\n",
        "\n",
        "```python\n",
        "x = self.dropout1(x)\n",
        "```\n",
        "\n",
        "还有下面那个也是拼错了。\n",
        "\n",
        "---\n",
        "\n",
        "如果你想我画一下这个网络的结构图（包括张量尺寸变化），或者改成支持 CIFAR10 的版本，也可以告诉我～\n"
      ],
      "metadata": {
        "id": "9zDHmCj0TG4X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "你问得非常有前瞻性，而且这个问题的答案实际上要看你是**做实验研究、产品部署、课程作业、还是学习目的**。我帮你从实际场景出发，判断你**是否还需要自己写 CNN 网络结构**。\n",
        "\n",
        "---\n",
        "\n",
        "## ✅ 一、如果你是为了「应用和实验」，是否需要手写 CNN？\n",
        "\n",
        "| 场景             | 是否需要自己写 CNN                                           |\n",
        "| -------------- | ----------------------------------------------------- |\n",
        "| ✅ 想快速获得高精度结果   | ❌ 不需要，直接用 ResNet、UNet、ViT 等                           |\n",
        "| ✅ 做图像分类、分割、检测等 | ❌ 不需要，直接用 torchvision / segmentation\\_models\\_pytorch |\n",
        "| ✅ 想迁移学习        | ❌ 用预训练模型更高效                                           |\n",
        "| ✅ 想试对比实验       | ✅ 可微调已有模型结构                                           |\n",
        "| ✅ 想探索新结构       | ✅ 自己写模型、组合模块                                          |\n",
        "\n",
        "> 🧠 **结论**：现代深度学习，90% 的任务都**直接调用已有模型（ResNet、UNet、Swin、EfficientNet）**，而不是从零写 CNN！\n",
        "\n",
        "---\n",
        "\n",
        "## 🧱 二、典型现成模型的使用方式\n",
        "\n",
        "### ▶ ResNet（分类）：\n",
        "\n",
        "```python\n",
        "from torchvision.models import resnet18\n",
        "\n",
        "model = resnet18(pretrained=True)\n",
        "model.fc = nn.Linear(512, num_classes)  # 替换最后一层以适配你的任务\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### ▶ UNet（语义分割）：\n",
        "\n",
        "```python\n",
        "from segmentation_models_pytorch import Unet\n",
        "\n",
        "model = Unet(\n",
        "    encoder_name=\"resnet34\",        # 编码器主干\n",
        "    encoder_weights=\"imagenet\",     # 是否加载预训练权重\n",
        "    in_channels=3,\n",
        "    classes=1                       # 输出类别数\n",
        ")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 📌 三、但什么时候还是建议你写自己的 CNN？\n",
        "\n",
        "| 目的                         | 是否建议手写 CNN                |\n",
        "| -------------------------- | ------------------------- |\n",
        "| ✅ 学习 CNN 架构的构造思路           | ✅ 强烈建议                    |\n",
        "| ✅ 对比 `有无残差`、`BatchNorm` 效果 | ✅ 建议自己写基础结构               |\n",
        "| ✅ 搭建小模型用于嵌入式               | ✅ 自己写更灵活                  |\n",
        "| ❌ 商业部署 or kaggle 比赛        | ❌ 调库更快，ResNet family 几乎无敌 |\n",
        "\n",
        "---\n",
        "\n",
        "## ✅ 总结\n",
        "\n",
        "| 你要做的事情         | 是否需要手写 CNN                           |\n",
        "| -------------- | ------------------------------------ |\n",
        "| 你想部署一个高效图像分类模型 | ❌ 直接用 ResNet or EfficientNet         |\n",
        "| 你想做医学图像分割      | ❌ UNet + 预训练 backbone 是首选            |\n",
        "| 你在写课程报告或论文     | ✅ 至少得写一个 baseline CNN 做对比            |\n",
        "| 你是刚开始学 PyTorch | ✅ 手写 CNN 能加深理解 Conv/Pool/Flatten 等流程 |\n",
        "\n",
        "---\n",
        "\n",
        "## 🎁 建议学习路径（实战导向）\n",
        "\n",
        "1. ✅ 手写一个简单 CNN 模型（LeNet / VGG-like）\n",
        "2. ✅ 理解并实现残差连接（ResNet Block）\n",
        "3. ✅ 学会使用 `torchvision.models` 和 `segmentation_models_pytorch`\n",
        "4. ✅ 能替换 output 层、微调、冻结层\n",
        "5. ✅ 掌握迁移学习、fine-tuning、pretrained 模型加载\n",
        "\n",
        "---\n",
        "\n",
        "如果你告诉我你的任务类型（如图像分类 / 医学分割 / 多标签预测），我可以给你推荐一个具体的预训练模型并帮你写微调代码。是否需要？\n"
      ],
      "metadata": {
        "id": "ZIPxa4dpn1ap"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "好！你提到的用字母方阵解释卷积非常直观，我们就**基于刚刚的 `5×5` 输入图像**，用具体字符 + 卷积核滑动示例说明为什么：\n",
        "\n",
        "> ✅ **`padding=1` 就能让输出保持和输入一样大**\n",
        "\n",
        "---\n",
        "\n",
        "## 🎯 1. 原始图像（无 padding）\n",
        "\n",
        "先看这张原始的 5×5 图像：\n",
        "\n",
        "```\n",
        "a b c d e  \n",
        "f g h i j  \n",
        "k l m n o  \n",
        "p q r s t  \n",
        "u v w x y  \n",
        "```\n",
        "\n",
        "### 使用 `3×3` 卷积核 + `stride=1` + `padding=0`\n",
        "\n",
        "* 卷积核只能完整放在 `a~m~o~y` 这片中间区域滑动\n",
        "* 因为最外一圈**无法成为卷积核中心**\n",
        "* 所以输出变为 `3×3`\n",
        "\n",
        "输出的位置对比如下（中间可以放卷积核）：\n",
        "\n",
        "```\n",
        "[ - - - - - ]\n",
        "[ - a b c - ]\n",
        "[ - d e f - ]\n",
        "[ - g h i - ]\n",
        "[ - - - - - ]\n",
        "```\n",
        "\n",
        "只有以 `a~i` 为中心的 9 个位置生成输出值。\n",
        "\n",
        "---\n",
        "\n",
        "## ✅ 2. 加上 `padding=1` 后的图像变成：\n",
        "\n",
        "四周补上一圈 0，变成 `7×7`：\n",
        "\n",
        "```\n",
        "0 0 0 0 0 0 0  \n",
        "0 a b c d e 0  \n",
        "0 f g h i j 0  \n",
        "0 k l m n o 0  \n",
        "0 p q r s t 0  \n",
        "0 u v w x y 0  \n",
        "0 0 0 0 0 0 0  \n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 💡 卷积核滑动方式现在可以：\n",
        "\n",
        "* 第一次覆盖的位置是：\n",
        "\n",
        "```\n",
        "0 0 0  \n",
        "0 a b  \n",
        "0 f g\n",
        "```\n",
        "\n",
        "* 第二次：\n",
        "\n",
        "```\n",
        "0 0 0  \n",
        "a b c  \n",
        "f g h\n",
        "```\n",
        "\n",
        "* ...\n",
        "* 最后一次可以到：\n",
        "\n",
        "```\n",
        "w x y  \n",
        "0 0 0  \n",
        "0 0 0\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### ✅ 这时你会发现：\n",
        "\n",
        "* 卷积核的中心可以移动到原图的每一个像素点\n",
        "* 原图每个像素都可以成为卷积中心点\n",
        "* 输出正好是 `5×5`，与输入大小一致\n",
        "\n",
        "---\n",
        "\n",
        "## 🔢 用公式验证一下：\n",
        "\n",
        "公式：\n",
        "\n",
        "$$\n",
        "\\text{Output\\_size} = \\left\\lfloor \\frac{(\\text{Input} + 2 × \\text{padding} - \\text{kernel})}{\\text{stride}} \\right\\rfloor + 1\n",
        "$$\n",
        "\n",
        "代入参数：\n",
        "\n",
        "* Input = 5\n",
        "* Kernel = 3\n",
        "* Padding = 1\n",
        "* Stride = 1\n",
        "\n",
        "$$\n",
        "\\text{Output} = \\frac{5 + 2×1 - 3}{1} + 1 = 5\n",
        "$$\n",
        "\n",
        "✅ 输出就是 5！\n",
        "\n",
        "---\n",
        "\n",
        "## ✅ 总结一句话：\n",
        "\n",
        "> 加 `padding=1` 就是为了补一圈 0，让边缘像素也能参与卷积核中心的位置，**从而避免边缘信息被“吃掉”**。\n",
        "\n",
        "这也是为什么在很多深度学习网络（如 ResNet、UNet）中，常用：\n",
        "\n",
        "```python\n",
        "nn.Conv2d(..., kernel_size=3, padding=1)\n",
        "```\n",
        "\n",
        "来保证尺寸不变。\n",
        "\n",
        "---\n",
        "\n",
        "如果你想我再扩展演示一下 `padding=2` 或者不同 `stride` 的情况，我可以继续用字符图演示 👇要试试吗？\n",
        "你的理解方向是对的，但我们现在来**系统、精确地说明一下 padding 与卷积核大小的关系**，确保你之后能灵活处理各种情况（`3x3`、`5x5`、`4x4` 等）。\n",
        "\n",
        "---\n",
        "\n",
        "## ✅ 一、最常见的目的：**保持输入输出尺寸相同**\n",
        "\n",
        "也就是所谓的 `\"same\"` padding（虽然 PyTorch 不直接支持字符串 `\"same\"`，但你可以手动设置 padding 值）。\n",
        "\n",
        "### 🎯 目标公式：\n",
        "\n",
        "如果你想要：\n",
        "\n",
        "$$\n",
        "\\text{Output Size} = \\text{Input Size}\n",
        "$$\n",
        "\n",
        "那就需要设置合适的 `padding` 值，满足：\n",
        "\n",
        "$$\n",
        "\\text{padding} = \\left\\lfloor \\frac{\\text{kernel\\_size} - 1}{2} \\right\\rfloor\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "## 📌 二、具体例子说明\n",
        "\n",
        "| Kernel Size | 需要的 Padding                 | 原因说明            |\n",
        "| ----------- | --------------------------- | --------------- |\n",
        "| `3×3`       | `padding=1`                 | 每边吃掉1像素，补回1像素   |\n",
        "| `5×5`       | `padding=2`                 | 每边吃掉2像素，补2像素    |\n",
        "| `7×7`       | `padding=3`                 | 以此类推            |\n",
        "| `4×4`       | ❗ **不对称！** `padding=1 or 2` | 输出大小不能完全等于输入大小了 |\n",
        "\n",
        "---\n",
        "\n",
        "## 🚨 三、重点来了：**`kernel_size=偶数` 时无法完全保持尺寸**\n",
        "\n",
        "当 `kernel_size` 是偶数，比如 `4×4`：\n",
        "\n",
        "* 想要让输入输出完全相等是不可能的（因为卷积核中心在两个像素之间）\n",
        "* 你必须选择 **非对称 padding**（很少用），或接受尺寸会缩小一点\n",
        "\n",
        "### 所以：\n",
        "\n",
        "| Kernel Size  | 是否推荐   | 原因                |\n",
        "| ------------ | ------ | ----------------- |\n",
        "| `3×3`, `5×5` | ✅ 推荐   | 对称 padding，输出尺寸可控 |\n",
        "| `4×4`, `6×6` | ⚠️ 不推荐 | 中心对不准，输出大小难控制     |\n",
        "\n",
        "---\n",
        "\n",
        "## ✅ 四、你说的 “`kernel_size=4` 需要 padding=2 吗？”\n",
        "\n",
        "### 不完全对！\n",
        "\n",
        "* `padding=2` 会导致：\n",
        "\n",
        "  $$\n",
        "  \\text{Output Size} = \\left\\lfloor \\frac{Input + 2×2 - 4}{1} \\right\\rfloor + 1 = Input + 1\n",
        "  $$\n",
        "* 也就是说，**输出比输入大 1 个像素**\n",
        "\n",
        "---\n",
        "\n",
        "## ✅ 五、实际建议（总结）\n",
        "\n",
        "| 你想要什么    | 建议的参数                            |\n",
        "| -------- | -------------------------------- |\n",
        "| 保持输出尺寸不变 | 使用奇数大小的卷积核（`3`, `5`）+ 对称 padding |\n",
        "| 能接受尺寸变小  | 使用任意 kernel，大多数框架会自动适配           |\n",
        "| 想要尺寸缩小   | 设 `stride > 1` 或不加 padding       |\n",
        "\n",
        "---\n",
        "\n",
        "### 🚀 小技巧（PyTorch 经典卷积保持尺寸）：\n",
        "\n",
        "```python\n",
        "nn.Conv2d(in_channels=..., out_channels=..., kernel_size=3, padding=1)\n",
        "```\n",
        "\n",
        "是最常用的套路，适用于大多数 CNN 架构（如 ResNet、VGG）。\n",
        "\n",
        "---\n",
        "\n",
        "如果你想我写一个函数，输入 kernel\\_size，输出建议 padding 和输出尺寸，我可以帮你写一个 PyTorch 小工具！是否需要？\n"
      ],
      "metadata": {
        "id": "O1VNlcs38rJZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "太好了！以下是我们今天围绕 CNN（卷积神经网络）相关内容的学习**总结清单**，分为几个模块方便你回顾：\n",
        "\n",
        "---\n",
        "\n",
        "## 🧠 一、基本概念理解\n",
        "\n",
        "* **卷积层 (`nn.Conv2d`)**\n",
        "\n",
        "  * 参数：`in_channels`, `out_channels`, `kernel_size`, `stride`, `padding`\n",
        "  * 卷积核数量 = `out_channels`\n",
        "  * 每个卷积核滑动方式相同，提取不同特征\n",
        "\n",
        "* **ReLU 激活 (`F.relu` 或 `nn.ReLU`)**\n",
        "\n",
        "  * 常用于非线性变换，置零负值\n",
        "\n",
        "* **池化层**\n",
        "\n",
        "  * `F.max_pool2d(x, 2)`：每 `2×2` 区域取最大值，常用于降维\n",
        "  * `AvgPool`：取平均值\n",
        "  * `GlobalAvgPool`：把每个通道压成一个数（最终分类常用）\n",
        "\n",
        "* **Flatten**\n",
        "\n",
        "  * 将 `Conv` 输出的 `4D tensor` 展平成 `2D`，用于接 `Linear`\n",
        "\n",
        "* **线性层 (`nn.Linear`)**\n",
        "\n",
        "  * 全连接层，用于最终分类/回归任务\n",
        "\n",
        "* **Dropout**\n",
        "\n",
        "  * 用于防止过拟合，训练阶段随机“丢弃”神经元\n",
        "\n",
        "---\n",
        "\n",
        "## 🔧 二、卷积层细节设置\n",
        "\n",
        "* **输出尺寸计算公式**：\n",
        "\n",
        "  $$\n",
        "  \\text{Output} = \\left\\lfloor \\frac{\\text{Input} + 2 \\times \\text{padding} - \\text{kernel}}{\\text{stride}} \\right\\rfloor + 1\n",
        "  $$\n",
        "\n",
        "* **保持尺寸不变的条件（same padding）**：\n",
        "\n",
        "  $$\n",
        "  \\text{padding} = \\left\\lfloor \\frac{\\text{kernel\\_size} - 1}{2} \\right\\rfloor\n",
        "  $$\n",
        "\n",
        "  👉 只对奇数 `kernel_size` 完美适用，如 `3×3`\n",
        "\n",
        "* **stride=2**：可以达到与 pooling 类似的降采样效果\n",
        "  👉 类似 `MaxPool2d(2)`，但可一起学习特征\n",
        "\n",
        "---\n",
        "\n",
        "## 🧱 三、经典 CNN 架构模块\n",
        "\n",
        "* **基础 CNN 示例**\n",
        "\n",
        "  * Conv → ReLU → Conv → ReLU → Pool → FC → FC\n",
        "  * 多个 conv 层后常用 pooling 降维\n",
        "\n",
        "* **使用 `nn.Sequential`**\n",
        "\n",
        "  * 对于串行模块简洁\n",
        "  * 不适用于残差连接、复杂分支结构\n",
        "\n",
        "* **残差连接（ResNet）**\n",
        "\n",
        "  * shortcut (`identity`)：跳过某些卷积层\n",
        "  * 优点：防止梯度消失，可训练更深模型\n",
        "\n",
        "---\n",
        "\n",
        "## 📦 四、模型与训练相关技巧\n",
        "\n",
        "* **Loss 选择**\n",
        "\n",
        "  * `F.log_softmax + F.nll_loss` ≈ `nn.CrossEntropyLoss`\n",
        "  * log\\_softmax 分开写更灵活（如搭配 KL 散度）\n",
        "\n",
        "* **优化器**\n",
        "\n",
        "  * `optim.Adadelta`：自适应优化方法，适合不调学习率\n",
        "  * 还有 SGD、Adam、RMSProp 等选择\n",
        "\n",
        "* **学习率调度器**\n",
        "\n",
        "  * `StepLR(optimizer, step_size=1, gamma=0.7)`\n",
        "  * 每 `step_size` 个 epoch 学习率衰减到 `gamma` 倍\n",
        "\n",
        "* **transforms.Compose**\n",
        "\n",
        "  * 数据预处理组合工具，例如 Normalize、ToTensor\n",
        "\n",
        "* **Normalize 的作用**\n",
        "\n",
        "  * 均值、方差归一化（加快收敛）\n",
        "  * 对于 MNIST：\n",
        "\n",
        "    ```python\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "    ```\n",
        "\n",
        "---\n",
        "\n",
        "## 📌 五、结构设计原则（经验）\n",
        "\n",
        "* 通常：\n",
        "\n",
        "  * 卷积核大小 `3×3`，padding=1 保持尺寸\n",
        "  * 通道数 `32→64→128→...` 逐渐加深\n",
        "  * 每 2 个 conv 层后用一次 pooling（或 stride=2）\n",
        "  * FC 层建议先 flatten，再用 `nn.Linear`\n",
        "  * Dropout 放在线性层之间避免过拟合\n",
        "\n",
        "* 不推荐：\n",
        "\n",
        "  * 使用偶数大小的 kernel（如 `4×4`, `6×6`），padding难控制\n",
        "  * 一开始就用大 kernel 或 stride，易损失空间细节\n",
        "\n",
        "---\n",
        "\n",
        "如果你需要我基于这些内容做一个 **思维导图** 或者写一个注释丰富的 PyTorch CNN 模板，我也可以帮你生成。要试试看吗？\n"
      ],
      "metadata": {
        "id": "D6Ldfz7kEn1K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "非常好，我们现在来添加一部分新的内容：\n",
        "\n",
        "---\n",
        "\n",
        "## 🧠 六、如何直接使用 **ResNet / U-Net** 处理不同任务\n",
        "\n",
        "深度学习中，**ResNet 和 U-Net 是两个最经典的 CNN 架构**，分别广泛用于：\n",
        "\n",
        "| 网络         | 常见任务 | 框架支持                                       |\n",
        "| ---------- | ---- | ------------------------------------------ |\n",
        "| **ResNet** | 图像分类 | torchvision                                |\n",
        "| **U-Net**  | 图像分割 | segmentation\\_models\\_pytorch、monai、custom |\n",
        "\n",
        "下面我们从 **使用方法** 和 **代码示例** 两个维度分别讲清楚：\n",
        "\n",
        "---\n",
        "\n",
        "### ✅ 6.1 使用 ResNet（图像分类）\n",
        "\n",
        "#### 🔧 任务类型\n",
        "\n",
        "* **输入**：图像（`C×H×W`，如 `3×224×224`）\n",
        "* **输出**：类别概率（例如 10 类）\n",
        "\n",
        "#### 🔨 加载预训练模型\n",
        "\n",
        "```python\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "\n",
        "# 加载 ResNet18，预训练权重\n",
        "resnet = models.resnet18(pretrained=True)\n",
        "\n",
        "# 替换最后一层以适配你自己的分类任务（如10类）\n",
        "resnet.fc = nn.Linear(resnet.fc.in_features, 10)\n",
        "```\n",
        "\n",
        "#### 💡 使用建议：\n",
        "\n",
        "* 输入图像需归一化：\n",
        "\n",
        "```python\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],  # ImageNet均值\n",
        "                         [0.229, 0.224, 0.225])  # ImageNet方差\n",
        "])\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### ✅ 6.2 使用 U-Net（图像分割）\n",
        "\n",
        "#### 🔧 任务类型\n",
        "\n",
        "* **输入**：图像（如医学图像、卫星图像）\n",
        "* **输出**：每像素预测类别（即 segmentation mask）\n",
        "\n",
        "#### 🚀 快速上手：使用 `segmentation_models_pytorch`\n",
        "\n",
        "```bash\n",
        "pip install segmentation-models-pytorch\n",
        "```\n",
        "\n",
        "#### 🧩 代码示例：\n",
        "\n",
        "```python\n",
        "import segmentation_models_pytorch as smp\n",
        "\n",
        "# 创建一个UNet，用resnet34作为backbone\n",
        "model = smp.Unet(\n",
        "    encoder_name=\"resnet34\",        # 预训练backbone\n",
        "    encoder_weights=\"imagenet\",     # 加载ImageNet权重\n",
        "    in_channels=3,                  # 输入图像通道数\n",
        "    classes=1,                      # 输出通道数（如二分类可设为1）\n",
        ")\n",
        "```\n",
        "\n",
        "#### 🧠 损失函数 + 后处理建议：\n",
        "\n",
        "```python\n",
        "# 二分类任务\n",
        "loss = nn.BCEWithLogitsLoss()  # 注意未加 sigmoid\n",
        "output = torch.sigmoid(model(x))  # 后处理再加 sigmoid\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 🧪 应用任务对比总结：\n",
        "\n",
        "| 模型     | 应用任务  | 输出形式            | 常用损失函数                            |\n",
        "| ------ | ----- | --------------- | --------------------------------- |\n",
        "| ResNet | 图像分类  | `B×num_classes` | `CrossEntropyLoss`                |\n",
        "| U-Net  | 像素级分割 | `B×1×H×W`       | `BCEWithLogitsLoss` or `DiceLoss` |\n",
        "\n",
        "---\n",
        "\n",
        "## 🔁 七、进阶技巧（迁移学习）\n",
        "\n",
        "* ResNet/U-Net 通常会用预训练权重，可以大大提升精度和收敛速度。\n",
        "* 若任务不同，建议**只微调最后几层**或**冻结 encoder 层**。\n",
        "\n",
        "```python\n",
        "# 冻结前面层（微调）\n",
        "for param in model.encoder.parameters():\n",
        "    param.requires_grad = False\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 📦 附赠：你可以尝试的代码任务\n",
        "\n",
        "| 任务         | 工具                       | 输入图像    | 输出      |\n",
        "| ---------- | ------------------------ | ------- | ------- |\n",
        "| CIFAR10 分类 | ResNet18                 | 32×32   | 类别      |\n",
        "| 胸片肺部分割     | UNet (ResNet34 backbone) | 512×512 | 分割 mask |\n",
        "\n",
        "---\n",
        "\n",
        "如你有具体数据集或任务（如医学图像、卫星图像等），我可以帮你生成适配的模型加载与训练代码。\n",
        "\n",
        "要不要我帮你写一个 **使用 ResNet 或 U-Net 的完整项目模板**（含训练、评估、可视化）？\n"
      ],
      "metadata": {
        "id": "YN_Ykx2AE6kx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "很好，`pretrained=True` 是使用深度学习模型时一个**非常重要的参数**，下面是它的详细解释：\n",
        "\n",
        "---\n",
        "\n",
        "## 🔍 `pretrained=True` 是什么意思？\n",
        "\n",
        "它的意思是：\n",
        "\n",
        "> 加载 **已经在大型数据集（如 ImageNet）上训练好的权重参数**。\n",
        "\n",
        "---\n",
        "\n",
        "## ✅ 举个例子说明\n",
        "\n",
        "当你写：\n",
        "\n",
        "```python\n",
        "resnet = models.resnet18(pretrained=True)\n",
        "```\n",
        "\n",
        "实际上 PyTorch 会做两件事：\n",
        "\n",
        "1. **构建 ResNet18 的网络结构**；\n",
        "2. **自动加载在 ImageNet 上训练好的权重参数**（即预训练参数）。\n",
        "\n",
        "这样你就拥有了一个**已经学会了如何提取图像特征的模型**，而不需要从头开始训练！\n",
        "\n",
        "---\n",
        "\n",
        "## 🤔 为什么要使用 `pretrained=True`？\n",
        "\n",
        "| 优点       | 说明                       |\n",
        "| -------- | ------------------------ |\n",
        "| ✅ 节省训练时间 | 不用从零开始训练模型               |\n",
        "| ✅ 提升性能   | 预训练模型已学到低级图像特征（边缘、颜色、纹理） |\n",
        "| ✅ 准确率更高  | 尤其在小样本任务中效果更好            |\n",
        "| ✅ 适合迁移学习 | 可微调最后几层，快速适配新任务          |\n",
        "\n",
        "---\n",
        "\n",
        "## ❓那什么时候不写 `pretrained=True`？\n",
        "\n",
        "你可以用：\n",
        "\n",
        "```python\n",
        "resnet = models.resnet18(pretrained=False)\n",
        "```\n",
        "\n",
        "这会：\n",
        "\n",
        "* 只初始化模型结构；\n",
        "* 所有参数是随机初始化；\n",
        "* 通常用于你想**自己从头训练**模型的场景（不推荐初学者使用）。\n",
        "\n",
        "---\n",
        "\n",
        "## 🧠 适用于哪些模型？\n",
        "\n",
        "几乎所有常见的模型都有预训练参数：\n",
        "\n",
        "```python\n",
        "models.resnet18(pretrained=True)\n",
        "models.vgg16(pretrained=True)\n",
        "models.mobilenet_v2(pretrained=True)\n",
        "models.densenet121(pretrained=True)\n",
        "...\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 🧪 小技巧：微调预训练模型\n",
        "\n",
        "你可以先加载 `pretrained=True`，然后只训练最后的几层：\n",
        "\n",
        "```python\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False  # 冻结全部参数\n",
        "\n",
        "model.fc = nn.Linear(model.fc.in_features, 10)  # 替换最后一层\n",
        "```\n",
        "\n",
        "只训练 `fc` 层，效果通常就不错。\n",
        "\n",
        "---\n",
        "\n",
        "如果你希望我提供一个带预训练模型、数据处理、训练流程的 **完整 PyTorch 模板**，我可以马上写一个给你。是否需要？\n"
      ],
      "metadata": {
        "id": "Jil-ipM2FKzD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "你问得非常好！下面我将从**任务类型、输入输出形式、原理机制**三个角度，完整地解释：\n",
        "\n",
        "---\n",
        "\n",
        "## 🧠 一、什么任务需要 U-Net？\n",
        "\n",
        "U-Net 专门用于 **图像分割（Image Segmentation）** 任务。\n",
        "\n",
        "### ✅ 图像分割的定义：\n",
        "\n",
        "> 给定一张图像，对 **每个像素** 进行分类（例如属于“猫”、“狗”、“背景”……）\n",
        "\n",
        "### 📌 典型任务包括：\n",
        "\n",
        "| 应用领域 | 输入图像     | 输出 mask（每像素分类） |\n",
        "| ---- | -------- | -------------- |\n",
        "| 医学影像 | CT、MRI 图 | 肿瘤 / 器官 / 病变区域 |\n",
        "| 遥感图像 | 卫星图      | 道路 / 建筑 / 河流区域 |\n",
        "| 自动驾驶 | 街景图像     | 车道线、行人、车辆区域    |\n",
        "| 工业质检 | 产品照片     | 缺陷区域分割         |\n",
        "\n",
        "---\n",
        "\n",
        "## 🔢 二、U-Net 的输入输出长什么样？\n",
        "\n",
        "### ✅ 输入（通常是图像）：\n",
        "\n",
        "形状为：`(B, C, H, W)`\n",
        "\n",
        "* `B`：batch size\n",
        "* `C`：通道数（1灰度图或3彩色图）\n",
        "* `H×W`：图像尺寸\n",
        "\n",
        "例如输入：\n",
        "\n",
        "```python\n",
        "(4, 1, 128, 128)  # batch=4，单通道，128×128大小\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### ✅ 输出（每像素的分类概率）：\n",
        "\n",
        "输出也是图像大小，只是通道变成 **类别数（classes）**\n",
        "\n",
        "* 二分类：输出 `(B, 1, H, W)`，每像素一个概率（通常用 `sigmoid`）\n",
        "* 多分类：输出 `(B, N_classes, H, W)`，每像素一个 softmax 结果\n",
        "\n",
        "---\n",
        "\n",
        "## 🔍 三、它为什么能实现图像分割？\n",
        "\n",
        "U-Net 的关键在于它结合了两个过程：\n",
        "\n",
        "---\n",
        "\n",
        "### 1. 编码器（下采样）：\n",
        "\n",
        "```text\n",
        "图像 → 卷积 + 池化 → 提取高级语义（如“这里是个圆形”）\n",
        "```\n",
        "\n",
        "* 层层下采样，减少空间尺寸，增加感受野\n",
        "* 能学到“这是什么”的语义信息（比如这是一个“肿瘤”）\n",
        "\n",
        "---\n",
        "\n",
        "### 2. 解码器（上采样）：\n",
        "\n",
        "```text\n",
        "语义特征 → 上采样 → 还原图像空间尺寸\n",
        "```\n",
        "\n",
        "* 将压缩后的特征“还原”到原图大小\n",
        "* 每个像素重新预测一个类别\n",
        "\n",
        "---\n",
        "\n",
        "### 3. 跳跃连接（Skip Connection）：\n",
        "\n",
        "```text\n",
        "编码器的低层特征 + 解码器特征 进行拼接\n",
        "```\n",
        "\n",
        "它的好处：\n",
        "\n",
        "* 编码器低层保留了图像**边缘、细节、纹理**\n",
        "* 解码器引入这些信息，**增强边缘感知能力**\n",
        "* 能同时理解“局部细节”和“全局语义”\n",
        "\n",
        "---\n",
        "\n",
        "## 🎯 四、U-Net 能分割图像的 **核心原理**\n",
        "\n",
        "> 它通过「编码器提取语义」+「解码器恢复空间结构」+「跳跃连接保留细节」，让每个像素都被语义感知、空间对齐，进而完成精准分割。\n",
        "\n",
        "---\n",
        "\n",
        "## ✅ 五、总结一句话：\n",
        "\n",
        "> **如果你的任务是“要知道图像中每一个像素属于什么类别”，就适合用 U-Net。**\n",
        "\n",
        "---\n",
        "\n",
        "## 🚀 如果你还想进一步实践：\n",
        "\n",
        "我可以帮你：\n",
        "\n",
        "* 用 PyTorch 实现 U-Net 分割小目标数据（如肿瘤）；\n",
        "* 可视化预测效果；\n",
        "* 使用预训练 backbone（如 ResNet）来提升精度；\n",
        "\n",
        "是否需要一个训练与预测的完整模板？我可以立刻生成。\n"
      ],
      "metadata": {
        "id": "OlH1-JTKGPHW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "9zDG4x7qLcFj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}